<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>18 Performance Testing</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --secondary: #8b5cf6;
            --bg-main: #0f172a;
            --bg-card: #1e293b;
            --bg-code: #0f172a;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --border: #334155;
            --accent: #06b6d4;
            --success: #10b981;
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body { 
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.7; 
            color: var(--text-primary); 
            background: var(--bg-main);
        }
        
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px; 
        }
        
        .home-btn { 
            position: fixed; 
            top: 20px; 
            right: 20px; 
            background: var(--accent);
            color: white; 
            width: 50px;
            height: 50px;
            border-radius: 50%;
            text-decoration: none; 
            z-index: 1000;
            box-shadow: 0 4px 20px rgba(6, 182, 212, 0.4);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            font-size: 24px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .home-btn:hover { 
            background: #0891b2;
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(6, 182, 212, 0.5);
        }
        
        .breadcrumb { 
            background: var(--bg-card);
            padding: 12px 0; 
            margin-bottom: 24px; 
            font-size: 14px;
            border-radius: 8px;
            border: 1px solid var(--border);
        }
        
        .breadcrumb a { 
            color: var(--accent);
            text-decoration: none;
            transition: color 0.2s;
        }
        
        .breadcrumb a:hover { 
            color: var(--primary);
            text-decoration: underline;
        }
        
        .content { 
            background: var(--bg-card);
            padding: 3rem; 
            border-radius: 16px; 
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            border: 1px solid var(--border);
        }
        
        .file-list { 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); 
            gap: 1.5rem; 
            margin: 2rem 0; 
        }
        
        .file-item { 
            padding: 1.5rem; 
            border: 1px solid var(--border);
            border-radius: 12px; 
            background: var(--bg-main);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }
        
        .file-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, var(--primary), var(--secondary));
            opacity: 0;
            transition: opacity 0.3s;
        }
        
        .file-item:hover { 
            transform: translateY(-4px); 
            box-shadow: 0 8px 30px rgba(99, 102, 241, 0.3);
            border-color: var(--primary);
        }
        
        .file-item:hover::before {
            opacity: 1;
        }
        
        .file-item a { 
            color: var(--text-primary);
            text-decoration: none; 
            font-weight: 600; 
            display: block;
            font-size: 1.1rem;
        }
        
        .file-item a:hover { 
            color: var(--primary);
        }
        
        .file-type { 
            font-size: 13px; 
            color: var(--text-secondary);
            margin-top: 8px; 
            font-weight: 500;
        }
        
        /* Code Blocks */
        pre { 
            background: var(--bg-code);
            padding: 1.5rem; 
            border-radius: 12px; 
            overflow-x: auto;
            border: 1px solid var(--border);
            margin: 1.5rem 0;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
            position: relative;
        }
        
        pre code { 
            background: none;
            padding: 0;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        /* Copy Button */
        .copy-btn {
            position: absolute;
            top: 8px;
            right: 8px;
            background: var(--primary);
            color: white;
            border: none;
            padding: 6px 12px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 12px;
            font-weight: 600;
            transition: all 0.2s;
            opacity: 0.7;
            z-index: 10;
        }
        
        .copy-btn:hover {
            opacity: 1;
            background: var(--primary-dark);
            transform: translateY(-1px);
        }
        
        .copy-btn.copied {
            background: var(--success);
        }
        
        pre:hover .copy-btn {
            opacity: 1;
        }
        
        /* Inline Code */
        code { 
            background: var(--bg-code);
            color: #8b5cf6;
            padding: 3px 8px; 
            border-radius: 6px; 
            font-size: 1.1em;
            font-family: 'Fira Code', 'Consolas', monospace;
            border: 1px solid var(--border);
        }
        
        /* Headings */
        h1, h2, h3, h4, h5, h6 { 
            color: var(--text-primary);
            margin: 2rem 0 1rem 0;
            font-weight: 700;
            letter-spacing: -0.5px;
        }
        
        h1 { 
            font-size: 2.5rem;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text;
            border-bottom: 3px solid var(--primary);
            padding-bottom: 12px;
            margin-bottom: 1.5rem;
        }
        
        h2 { 
            font-size: 2rem;
            color: var(--primary);
            border-bottom: 2px solid var(--border);
            padding-bottom: 8px;
        }
        
        h3 { 
            font-size: 1.5rem;
            color: var(--accent);
        }
        
        /* Links */
        a { 
            color: var(--accent);
            transition: color 0.2s;
        }
        
        a:hover { 
            color: var(--primary);
        }
        
        /* Paragraphs */
        p {
            margin: 1rem 0;
            color: var(--text-secondary);
        }
        
        /* Lists */
        ul, ol {
            margin: 1rem 0;
            padding-left: 2rem;
            color: var(--text-secondary);
        }
        
        li {
            margin: 0.5rem 0;
        }
        
        /* Tables */
        table { 
            border-collapse: collapse;
            width: 100%;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        }
        
        th, td { 
            border: 1px solid var(--border);
            padding: 12px 16px;
            text-align: left;
        }
        
        th { 
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            font-weight: 600;
        }
        
        tr:hover {
            background: var(--bg-card);
        }
        
        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--primary);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 0 8px 8px 0;
            color: var(--text-secondary);
            font-style: italic;
        }
        
        /* Horizontal Rule */
        hr {
            border: none;
            border-top: 2px solid var(--border);
            margin: 2rem 0;
        }
        
        .footer { 
            text-align: center; 
            padding: 2rem; 
            color: var(--text-secondary);
            border-top: 1px solid var(--border);
            margin-top: 3rem; 
            font-size: 14px;
        }
        
        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 12px;
            height: 12px;
        }
        
        ::-webkit-scrollbar-track {
            background: var(--bg-main);
        }
        
        ::-webkit-scrollbar-thumb {
            background: var(--border);
            border-radius: 6px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: var(--primary);
        }
        
        @media (max-width: 768px) {
            .container { padding: 10px; }
            .file-list { grid-template-columns: 1fr; }
            .content { padding: 1.5rem; }
            h1 { font-size: 2rem; }
            h2 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>
    <a href="../index.html" class="home-btn">üè†</a>
    <div class="container">
        <div class="breadcrumb">
            <div style="padding: 0 20px;">
                <a href="../index.html">üè† Home</a> <span style="color: #64748b;">/</span> <a href="index.html">06 Mastery and Beyond</a>
            </div>
        </div>
        <div class="content">
            <h1 id="chapter-18-performance-testing">Chapter 18: Performance Testing</h1>
<h2 id="when-performance-testing-matters">When Performance Testing Matters</h2>
<p>Performance testing in the context of pytest serves two distinct purposes: ensuring your <strong>code</strong> performs acceptably, and ensuring your <strong>test suite</strong> runs efficiently. This chapter focuses on both aspects, starting with understanding when performance testing becomes critical.</p>
<h2 id="the-two-faces-of-performance-testing">The Two Faces of Performance Testing</h2>
<h3 id="testing-code-performance">Testing Code Performance</h3>
<p>You need to verify that your production code meets performance requirements:</p>
<ul>
<li><strong>API endpoints</strong> must respond within acceptable latency bounds</li>
<li><strong>Data processing pipelines</strong> must handle expected data volumes</li>
<li><strong>Algorithms</strong> must scale appropriately with input size</li>
<li><strong>Database queries</strong> must execute within time budgets</li>
</ul>
<h3 id="testing-test-suite-performance">Testing Test Suite Performance</h3>
<p>You need to ensure your test suite remains fast enough to support rapid development:</p>
<ul>
<li><strong>Slow tests</strong> discourage running the full suite locally</li>
<li><strong>CI/CD pipelines</strong> become bottlenecks when tests take too long</li>
<li><strong>Developer productivity</strong> suffers when feedback loops extend beyond seconds</li>
<li><strong>Test parallelization</strong> becomes necessary but adds complexity</li>
</ul>
<h2 id="when-to-invest-in-performance-testing">When to Invest in Performance Testing</h2>
<h3 id="signals-that-performance-testing-is-needed">Signals That Performance Testing Is Needed</h3>
<p><strong>For production code</strong>:
- Users report slow response times
- System monitoring shows degrading performance trends
- New features introduce algorithmic complexity
- Data volumes are growing significantly
- Service Level Agreements (SLAs) define performance requirements</p>
<p><strong>For test suites</strong>:
- Developers avoid running the full test suite locally
- CI/CD builds take longer than 10-15 minutes
- Test execution time grows faster than codebase size
- Flaky tests appear due to timing assumptions
- Parallel test execution becomes necessary</p>
<h3 id="when-performance-testing-is-premature">When Performance Testing Is Premature</h3>
<p><strong>Don't performance test when</strong>:
- The feature doesn't exist yet (test correctness first)
- Performance requirements are undefined
- The code path is rarely executed
- Optimization would complicate code without measurable benefit
- The bottleneck is external (network, database, third-party API)</p>
<h2 id="the-reference-scenario-a-data-processing-pipeline">The Reference Scenario: A Data Processing Pipeline</h2>
<p>Throughout this chapter, we'll work with a realistic data processing system that exhibits common performance characteristics. This will be our anchor example for exploring performance testing techniques.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># data_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DataProcessor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Processes customer transaction data for analytics.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cache_enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_enabled</span> <span class="o">=</span> <span class="n">cache_enabled</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_risk_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transaction</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate fraud risk score for a transaction.</span>
<span class="sd">        Computationally expensive: involves multiple hash operations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_enabled</span><span class="p">:</span>
            <span class="n">cache_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_key</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>

        <span class="c1"># Simulate expensive computation</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">transaction</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Multiple hash iterations (simulating ML model inference)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
            <span class="n">hash_obj</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data</span><span class="si">}{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">hash_obj</span><span class="o">.</span><span class="n">digest</span><span class="p">())</span> <span class="o">/</span> <span class="mi">1000000</span>

        <span class="n">score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">score</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># Normalize to 0-1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_enabled</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>

        <span class="k">return</span> <span class="n">score</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_cache_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transaction</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate cache key from transaction.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">transaction</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">()</span>
        <span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">process_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transactions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process a batch of transactions, adding risk scores.&quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">transaction</span> <span class="ow">in</span> <span class="n">transactions</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">transaction</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">result</span><span class="p">[</span><span class="s1">&#39;risk_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">process_batch_parallel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transactions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process batch with simulated parallelization.</span>
<span class="sd">        In reality, this would use multiprocessing or threading.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Simplified: just process in chunks to simulate parallel behavior</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span> <span class="o">//</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">transactions</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">transactions</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">chunk_size</span><span class="p">]</span>
            <span class="n">chunk_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">chunk_results</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

<p>This <code>DataProcessor</code> class exhibits several performance characteristics we'll explore:</p>
<ol>
<li><strong>Computationally expensive operations</strong> (hash calculations)</li>
<li><strong>Caching mechanisms</strong> that affect performance</li>
<li><strong>Batch processing</strong> with different strategies</li>
<li><strong>Scalability concerns</strong> as data volume increases</li>
</ol>
<h2 id="initial-correctness-tests">Initial Correctness Tests</h2>
<p>Before performance testing, we establish correctness with basic functional tests:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_risk_score_range</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Risk scores should be between 0 and 1.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_processing_preserves_data</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch processing should preserve original transaction data.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">50.0</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Store A&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C1&#39;</span><span class="p">},</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">150.0</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Store B&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C2&#39;</span><span class="p">},</span>
    <span class="p">]</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">original</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">transactions</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">original</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;merchant&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">original</span><span class="p">[</span><span class="s1">&#39;merchant&#39;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="s1">&#39;risk_score&#39;</span> <span class="ow">in</span> <span class="n">result</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_cache_returns_consistent_scores</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Same transaction should return same score when cached.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C1&#39;</span><span class="p">}</span>

    <span class="n">score1</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">score2</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">score1</span> <span class="o">==</span> <span class="n">score2</span>
</code></pre></div>

<p>These tests verify correctness but tell us nothing about performance. Running them:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_risk_score_range PASSED
test_data_processor.py::test_batch_processing_preserves_data PASSED
test_data_processor.py::test_cache_returns_consistent_scores PASSED

======================== 3 passed in 0.45s =========================
</code></pre></div>

<p>The tests pass, but we have no visibility into:
- How long each operation takes
- Whether caching actually improves performance
- How performance scales with batch size
- Whether the parallel version is actually faster</p>
<p><strong>This is where performance testing begins.</strong></p>
<h2 id="decision-framework-when-to-add-performance-tests">Decision Framework: When to Add Performance Tests</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Add Performance Tests?</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>New CRUD endpoint</td>
<td>No</td>
<td>Standard operations, external bottlenecks</td>
</tr>
<tr>
<td>Complex algorithm</td>
<td>Yes</td>
<td>Computational complexity matters</td>
</tr>
<tr>
<td>Data processing pipeline</td>
<td>Yes</td>
<td>Volume scaling is critical</td>
</tr>
<tr>
<td>Cached operations</td>
<td>Yes</td>
<td>Need to verify cache effectiveness</td>
</tr>
<tr>
<td>I/O-bound operations</td>
<td>Maybe</td>
<td>Depends on SLA requirements</td>
</tr>
<tr>
<td>Rarely-used admin features</td>
<td>No</td>
<td>Optimization not worth complexity</td>
</tr>
</tbody>
</table>
<p>In the following sections, we'll add performance testing to our <code>DataProcessor</code>, progressing from simple timing measurements to sophisticated benchmarking and profiling.</p>
<h2 id="measuring-test-execution-time">Measuring Test Execution Time</h2>
<p>The simplest form of performance testing is measuring how long operations take. Pytest provides built-in mechanisms for this, and we can also add custom timing to our tests.</p>
<h2 id="iteration-1-basic-timing-with-pytests-duration-reporting">Iteration 1: Basic Timing with Pytest's Duration Reporting</h2>
<p>Pytest can show test durations without any code changes. Let's see what our current tests reveal:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py<span class="w"> </span>-v<span class="w"> </span>--durations<span class="o">=</span><span class="m">0</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_risk_score_range PASSED
test_data_processor.py::test_batch_processing_preserves_data PASSED
test_data_processor.py::test_cache_returns_consistent_scores PASSED

======================== slowest test durations ========================
0.15s call     test_data_processor.py::test_batch_processing_preserves_data
0.08s call     test_data_processor.py::test_cache_returns_consistent_scores
0.07s call     test_data_processor.py::test_risk_score_range
0.00s teardown test_data_processor.py::test_cache_returns_consistent_scores
0.00s setup    test_data_processor.py::test_cache_returns_consistent_scores
...
======================== 3 passed in 0.45s =========================
</code></pre></div>

<h3 id="diagnostic-analysis-reading-duration-reports">Diagnostic Analysis: Reading Duration Reports</h3>
<p><strong>The <code>--durations=0</code> flag</strong> shows timing for all test phases (setup, call, teardown).</p>
<p><strong>What this tells us</strong>:
1. <code>test_batch_processing_preserves_data</code> is the slowest at 0.15s
2. The "call" phase is where time is spent (not setup/teardown)
3. Processing 2 transactions takes 0.15s, suggesting ~0.075s per transaction</p>
<p><strong>Current limitation</strong>: We can see which tests are slow, but we can't:
- Assert that performance meets requirements
- Compare performance across different implementations
- Track performance regressions over time
- Measure specific operations within a test</p>
<h2 id="iteration-2-adding-explicit-performance-assertions">Iteration 2: Adding Explicit Performance Assertions</h2>
<p>Let's add a test that explicitly verifies performance requirements:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor.py (additions)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_single_transaction_performance</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single transaction should process in under 100ms.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>  <span class="c1"># Correctness</span>
    <span class="k">assert</span> <span class="n">duration</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Processing took </span><span class="si">{</span><span class="n">duration</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s, expected &lt; 0.1s&quot;</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py::test_single_transaction_performance<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_single_transaction_performance PASSED

======================== 1 passed in 0.08s =========================
</code></pre></div>

<p>The test passes. But let's see what happens when we disable caching:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_single_transaction_performance_no_cache</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single transaction without cache should still meet performance target.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="k">assert</span> <span class="n">duration</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Processing took </span><span class="si">{</span><span class="n">duration</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s, expected &lt; 0.1s&quot;</span>
</code></pre></div>

<p>Running this:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py::test_single_transaction_performance_no_cache<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_single_transaction_performance_no_cache PASSED

======================== 1 passed in 0.08s =========================
</code></pre></div>

<p>Still passes. Both cached and uncached versions meet the 100ms requirement for a single transaction.</p>
<h2 id="iteration-3-testing-batch-performance-scaling">Iteration 3: Testing Batch Performance Scaling</h2>
<p>Now let's test how performance scales with batch size:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_batch_performance_scaling</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch processing should scale linearly with size.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>

    <span class="c1"># Create test transactions</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">make_transactions</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
                <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="c1"># Test small batch</span>
    <span class="n">small_batch</span> <span class="o">=</span> <span class="n">make_transactions</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">small_batch</span><span class="p">)</span>
    <span class="n">small_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Test large batch</span>
    <span class="n">large_batch</span> <span class="o">=</span> <span class="n">make_transactions</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">large_batch</span><span class="p">)</span>
    <span class="n">large_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Should scale roughly linearly (within 20% tolerance)</span>
    <span class="n">expected_duration</span> <span class="o">=</span> <span class="n">small_duration</span> <span class="o">*</span> <span class="mi">10</span>
    <span class="n">tolerance</span> <span class="o">=</span> <span class="n">expected_duration</span> <span class="o">*</span> <span class="mf">0.2</span>

    <span class="k">assert</span> <span class="nb">abs</span><span class="p">(</span><span class="n">large_duration</span> <span class="o">-</span> <span class="n">expected_duration</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Large batch took </span><span class="si">{</span><span class="n">large_duration</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s, expected ~</span><span class="si">{</span><span class="n">expected_duration</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s&quot;</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py::test_batch_performance_scaling<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_batch_performance_scaling FAILED

================================ FAILURES =================================
________________________ test_batch_performance_scaling ___________________

    def test_batch_performance_scaling():
        &quot;&quot;&quot;Batch processing should scale linearly with size.&quot;&quot;&quot;
        processor = DataProcessor()

        # Create test transactions
        def make_transactions(count):
            return [
                {
                    &#39;amount&#39;: 100.0 + i,
                    &#39;merchant&#39;: f&#39;Store {i}&#39;,
                    &#39;customer_id&#39;: f&#39;C{i}&#39;
                }
                for i in range(count)
            ]

        # Test small batch
        small_batch = make_transactions(10)
        start = time.perf_counter()
        processor.process_batch(small_batch)
        small_duration = time.perf_counter() - start

        # Test large batch
        large_batch = make_transactions(100)
        start = time.perf_counter()
        processor.process_batch(large_batch)
        large_duration = time.perf_counter() - start

        # Should scale roughly linearly (within 20% tolerance)
        expected_duration = small_duration <span class="gs">* 10</span>
<span class="gs">        tolerance = expected_duration *</span> 0.2

<span class="k">&gt; </span><span class="ge">      assert abs(large_duration - expected_duration) &lt; tolerance, \</span>
            f&quot;Large batch took {large_duration:.3f}s, expected ~{expected_duration:.3f}s&quot;
E       AssertionError: Large batch took 0.723s, expected ~0.750s
E       assert 0.027 &lt; 0.150

test_data_processor.py:89: AssertionError
======================== 1 failed in 1.52s =========================
</code></pre></div>

<h3 id="diagnostic-analysis-understanding-the-timing-failure">Diagnostic Analysis: Understanding the Timing Failure</h3>
<p><strong>The assertion failure</strong>:</p>
<div class="codehilite"><pre><span></span><code>Large batch took 0.723s, expected ~0.750s
assert 0.027 &lt; 0.150
</code></pre></div>

<p><strong>What this tells us</strong>:
1. The large batch actually took <strong>less</strong> time than expected (0.723s vs 0.750s)
2. The difference (0.027s) is less than our tolerance (0.150s)
3. <strong>The test logic is inverted</strong> - we're asserting the difference is less than tolerance, which it is</p>
<p><strong>Root cause</strong>: The test passes the assertion but fails because we wrote the assertion backwards. The actual performance is <strong>better</strong> than linear scaling, likely due to caching effects.</p>
<p>Let's fix the test to properly validate linear scaling:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_batch_performance_scaling_fixed</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch processing should scale linearly with size.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">make_transactions</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
                <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="c1"># Test small batch</span>
    <span class="n">small_batch</span> <span class="o">=</span> <span class="n">make_transactions</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">small_batch</span><span class="p">)</span>
    <span class="n">small_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Test large batch</span>
    <span class="n">large_batch</span> <span class="o">=</span> <span class="n">make_transactions</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">large_batch</span><span class="p">)</span>
    <span class="n">large_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Calculate per-item time</span>
    <span class="n">small_per_item</span> <span class="o">=</span> <span class="n">small_duration</span> <span class="o">/</span> <span class="mi">10</span>
    <span class="n">large_per_item</span> <span class="o">=</span> <span class="n">large_duration</span> <span class="o">/</span> <span class="mi">100</span>

    <span class="c1"># Per-item time should be similar (within 50% due to caching effects)</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">large_per_item</span> <span class="o">/</span> <span class="n">small_per_item</span>
    <span class="k">assert</span> <span class="mf">0.5</span> <span class="o">&lt;=</span> <span class="n">ratio</span> <span class="o">&lt;=</span> <span class="mf">1.5</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Per-item time changed by </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x (small: </span><span class="si">{</span><span class="n">small_per_item</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">s, large: </span><span class="si">{</span><span class="n">large_per_item</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">s)&quot;</span>
</code></pre></div>

<p>Running the fixed test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py::test_batch_performance_scaling_fixed<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_batch_performance_scaling_fixed PASSED

======================== 1 passed in 1.48s =========================
</code></pre></div>

<p>Now the test passes and correctly validates that per-item processing time remains consistent.</p>
<h2 id="iteration-4-testing-cache-effectiveness">Iteration 4: Testing Cache Effectiveness</h2>
<p>Let's verify that caching actually improves performance:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_cache_improves_performance</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Caching should significantly improve repeated calculations.&quot;&quot;&quot;</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Test with cache</span>
    <span class="n">processor_cached</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">processor_cached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">cached_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Test without cache</span>
    <span class="n">processor_uncached</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">processor_uncached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">uncached_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Cached version should be at least 5x faster</span>
    <span class="n">speedup</span> <span class="o">=</span> <span class="n">uncached_duration</span> <span class="o">/</span> <span class="n">cached_duration</span>
    <span class="k">assert</span> <span class="n">speedup</span> <span class="o">&gt;=</span> <span class="mf">5.0</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Cache speedup was only </span><span class="si">{</span><span class="n">speedup</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x, expected &gt;= 5x&quot;</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py::test_cache_improves_performance<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor.py::test_cache_improves_performance PASSED

======================== 1 passed in 0.82s =========================
</code></pre></div>

<p>The test passes, confirming that caching provides significant performance improvement.</p>
<h2 id="current-limitations-of-manual-timing">Current Limitations of Manual Timing</h2>
<p>Our manual timing approach works but has several problems:</p>
<ol>
<li><strong>Timing variability</strong>: System load affects measurements</li>
<li><strong>Warmup effects</strong>: First run may be slower due to Python's JIT</li>
<li><strong>Statistical significance</strong>: Single measurements don't account for variance</li>
<li><strong>Comparison complexity</strong>: Hard to compare multiple implementations</li>
<li><strong>Regression tracking</strong>: No automatic detection of performance degradation</li>
</ol>
<p><strong>What we need</strong>: A robust benchmarking framework that handles statistical analysis, warmup, and comparison automatically.</p>
<p>This is where <code>pytest-benchmark</code> comes in, which we'll explore in the next section.</p>
<h2 id="summary-manual-timing-techniques">Summary: Manual Timing Techniques</h2>
<table>
<thead>
<tr>
<th>Technique</th>
<th>Use Case</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--durations</code> flag</td>
<td>Identify slow tests</td>
<td>No assertions, no comparison</td>
</tr>
<tr>
<td><code>time.perf_counter()</code></td>
<td>Simple performance assertions</td>
<td>No statistical analysis</td>
</tr>
<tr>
<td>Ratio comparisons</td>
<td>Verify relative performance</td>
<td>Sensitive to system load</td>
</tr>
<tr>
<td>Repeated measurements</td>
<td>Test cache effectiveness</td>
<td>Manual statistical analysis</td>
</tr>
</tbody>
</table>
<p><strong>Key takeaway</strong>: Manual timing is useful for basic performance assertions, but sophisticated performance testing requires specialized tools.</p>
<h2 id="pytest-benchmark-for-reliable-benchmarks">pytest-benchmark for Reliable Benchmarks</h2>
<p><code>pytest-benchmark</code> is a pytest plugin that provides statistically rigorous performance testing. It handles warmup, multiple iterations, statistical analysis, and comparison of results across runs.</p>
<h2 id="installing-pytest-benchmark">Installing pytest-benchmark</h2>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>pytest-benchmark
</code></pre></div>

<h2 id="iteration-1-basic-benchmark-with-the-benchmark-fixture">Iteration 1: Basic Benchmark with the benchmark Fixture</h2>
<p>The <code>benchmark</code> fixture is automatically available once pytest-benchmark is installed. Let's convert our manual timing test to use it:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_benchmark.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_single_transaction</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark single transaction processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="c1"># benchmark() runs the function multiple times and collects statistics</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>

    <span class="c1"># We can still assert on the result</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
</code></pre></div>

<p>Running this benchmark:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_benchmark.py::test_benchmark_single_transaction<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c">test_data_processor_benchmark</span><span class="nt">.</span><span class="c">py::test_benchmark_single_transaction PASSED</span>

<span class="nb">--------------------------</span><span class="c"> benchmark: 1 tests </span><span class="nb">--------------------------</span>
<span class="c">Name (time in ms)                          Min      Max     Mean  StdDev  Median     IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">-------------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_single_transaction      71</span><span class="nt">.</span><span class="c">2341  75</span><span class="nt">.</span><span class="c">8901  72</span><span class="nt">.</span><span class="c">4512  1</span><span class="nt">.</span><span class="c">2341  72</span><span class="nt">.</span><span class="c">1234  0</span><span class="nt">.</span><span class="c">8901     2;0  13</span><span class="nt">.</span><span class="c">80      14           1</span>
<span class="nb">-------------------------------------------------------------------------------------------------------------------------------</span>

<span class="c">======================== 1 passed in 2</span><span class="nt">.</span><span class="c">15s =========================</span>
</code></pre></div>

<h3 id="diagnostic-analysis-reading-benchmark-output">Diagnostic Analysis: Reading Benchmark Output</h3>
<p><strong>The benchmark table shows</strong>:</p>
<ol>
<li><strong>Min/Max</strong>: Range of execution times (71.23ms to 75.89ms)</li>
<li><strong>Mean</strong>: Average execution time (72.45ms)</li>
<li><strong>StdDev</strong>: Standard deviation (1.23ms) - low variance indicates stable performance</li>
<li><strong>Median</strong>: Middle value (72.12ms) - less affected by outliers than mean</li>
<li><strong>IQR</strong>: Interquartile range (0.89ms) - spread of middle 50% of data</li>
<li><strong>Outliers</strong>: Number of unusually fast/slow runs (2 slow, 0 fast)</li>
<li><strong>OPS</strong>: Operations per second (13.80)</li>
<li><strong>Rounds</strong>: Number of measurement rounds (14)</li>
<li><strong>Iterations</strong>: Calls per round (1)</li>
</ol>
<p><strong>What this tells us</strong>:
- Performance is stable (low StdDev)
- Single transaction takes ~72ms on average
- This is well under our 100ms requirement
- The benchmark ran 14 rounds to gather sufficient data</p>
<h2 id="iteration-2-comparing-cached-vs-uncached-performance">Iteration 2: Comparing Cached vs. Uncached Performance</h2>
<p>Let's use benchmarks to quantify cache effectiveness:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_cached_vs_uncached</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark cached transaction processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Prime the cache</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>

    <span class="c1"># Benchmark cached access</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_uncached</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark uncached transaction processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
</code></pre></div>

<p>Running both benchmarks:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_benchmark.py<span class="w"> </span>-v<span class="w"> </span>--benchmark-only
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">--------------------------</span><span class="c"> benchmark: 3 tests </span><span class="nb">--------------------------</span>
<span class="c">Name (time in us)                          Min       Max      Mean   StdDev    Median      IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">----------------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_cached_vs_uncached       2</span><span class="nt">.</span><span class="c">1234    3</span><span class="nt">.</span><span class="c">4567   2</span><span class="nt">.</span><span class="c">3456   0</span><span class="nt">.</span><span class="c">2341    2</span><span class="nt">.</span><span class="c">2891   0</span><span class="nt">.</span><span class="c">1234    15;0  426</span><span class="nt">.</span><span class="c">31    431           1</span>
<span class="c">test_benchmark_uncached              71234</span><span class="nt">.</span><span class="c">56  75890</span><span class="nt">.</span><span class="c">12  72451</span><span class="nt">.</span><span class="c">23  1234</span><span class="nt">.</span><span class="c">12  72123</span><span class="nt">.</span><span class="c">45  890</span><span class="nt">.</span><span class="c">12      2;0   13</span><span class="nt">.</span><span class="c">80     14           1</span>
<span class="c">test_benchmark_single_transaction    71245</span><span class="nt">.</span><span class="c">67  75901</span><span class="nt">.</span><span class="c">23  72462</span><span class="nt">.</span><span class="c">34  1235</span><span class="nt">.</span><span class="c">23  72134</span><span class="nt">.</span><span class="c">56  891</span><span class="nt">.</span><span class="c">23      2;0   13</span><span class="nt">.</span><span class="c">80     14           1</span>
<span class="nb">----------------------------------------------------------------------------------------------------------------------------------</span>

<span class="c">======================== 3 passed in 6</span><span class="nt">.</span><span class="c">45s =========================</span>
</code></pre></div>

<h3 id="diagnostic-analysis-comparing-benchmark-results">Diagnostic Analysis: Comparing Benchmark Results</h3>
<p><strong>Key observations</strong>:</p>
<ol>
<li><strong>Cached version</strong>: ~2.35 microseconds (us)</li>
<li><strong>Uncached version</strong>: ~72,451 microseconds (us) = ~72.45 milliseconds (ms)</li>
<li><strong>Speedup</strong>: 72,451 / 2.35 ‚âà <strong>30,830x faster</strong> with caching</li>
</ol>
<p><strong>What this tells us</strong>:
- Cache is extremely effective for repeated calculations
- Uncached performance is still acceptable for single calculations
- The cache lookup overhead is negligible (~2.35us)</p>
<p><strong>Current limitation</strong>: We're comparing results visually. We can't automatically assert that cached is faster or track regressions over time.</p>
<h2 id="iteration-3-using-benchmark-groups-for-direct-comparison">Iteration 3: Using Benchmark Groups for Direct Comparison</h2>
<p>pytest-benchmark allows grouping related benchmarks for easier comparison:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;caching&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_cached_grouped</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark cached transaction processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>  <span class="c1"># Prime cache</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;caching&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_uncached_grouped</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark uncached transaction processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
</code></pre></div>

<p>Running with grouping:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_benchmark.py<span class="w"> </span>-v<span class="w"> </span>--benchmark-only<span class="w"> </span>--benchmark-group-by<span class="o">=</span>group
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">--------------------------</span><span class="c"> benchmark &#39;caching&#39;: 2 tests </span><span class="nb">--------------------------</span>
<span class="c">Name (time in us)                          Min       Max      Mean   StdDev    Median      IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">------------------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_cached_grouped           2</span><span class="nt">.</span><span class="c">1234    3</span><span class="nt">.</span><span class="c">4567   2</span><span class="nt">.</span><span class="c">3456   0</span><span class="nt">.</span><span class="c">2341    2</span><span class="nt">.</span><span class="c">2891   0</span><span class="nt">.</span><span class="c">1234    15;0  426</span><span class="nt">.</span><span class="c">31    431           1</span>
<span class="c">test_benchmark_uncached_grouped      71234</span><span class="nt">.</span><span class="c">56  75890</span><span class="nt">.</span><span class="c">12  72451</span><span class="nt">.</span><span class="c">23  1234</span><span class="nt">.</span><span class="c">12  72123</span><span class="nt">.</span><span class="c">45  890</span><span class="nt">.</span><span class="c">12      2;0   13</span><span class="nt">.</span><span class="c">80     14           1</span>
<span class="nb">------------------------------------------------------------------------------------------------------------------------------------</span>

<span class="c">======================== 2 passed in 4</span><span class="nt">.</span><span class="c">30s =========================</span>
</code></pre></div>

<p>Now the related benchmarks are grouped together, making comparison easier.</p>
<h2 id="iteration-4-benchmarking-with-setupteardown">Iteration 4: Benchmarking with Setup/Teardown</h2>
<p>Sometimes we need to benchmark only the operation itself, not the setup. The <code>benchmark</code> fixture supports this:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_batch_processing</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark batch processing with proper setup.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>

    <span class="c1"># Setup: create test data (not benchmarked)</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
            <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
            <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Benchmark only the processing</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="s1">&#39;risk_score&#39;</span> <span class="ow">in</span> <span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">result</span><span class="p">)</span>
</code></pre></div>

<p>Running this benchmark:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_benchmark.py::test_benchmark_batch_processing<span class="w"> </span>-v
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">--------------------------</span><span class="c"> benchmark: 1 tests </span><span class="nb">--------------------------</span>
<span class="c">Name (time in s)                          Min     Max    Mean  StdDev  Median    IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">-------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_batch_processing       7</span><span class="nt">.</span><span class="c">1234  7</span><span class="nt">.</span><span class="c">5890  7</span><span class="nt">.</span><span class="c">2451  0</span><span class="nt">.</span><span class="c">1234  7</span><span class="nt">.</span><span class="c">2123  0</span><span class="nt">.</span><span class="c">0890     2;0  0</span><span class="nt">.</span><span class="c">14       7           1</span>
<span class="nb">-------------------------------------------------------------------------------------------------------------------------</span>

<span class="c">======================== 1 passed in 51</span><span class="nt">.</span><span class="c">23s =========================</span>
</code></pre></div>

<p>Processing 100 transactions takes ~7.2 seconds, or ~72ms per transaction.</p>
<h2 id="iteration-5-comparing-different-implementations">Iteration 5: Comparing Different Implementations</h2>
<p>Let's benchmark the parallel processing version:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;batch-processing&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_batch_sequential</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark sequential batch processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;batch-processing&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_batch_parallel</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark parallel batch processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch_parallel</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
</code></pre></div>

<p>Running the comparison:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_benchmark.py<span class="w"> </span>-v<span class="w"> </span>--benchmark-only<span class="w"> </span>--benchmark-group-by<span class="o">=</span>group
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">--------------------------</span><span class="c"> benchmark &#39;batch</span><span class="nb">-</span><span class="c">processing&#39;: 2 tests </span><span class="nb">--------------------------</span>
<span class="c">Name (time in s)                          Min     Max    Mean  StdDev  Median    IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">--------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_batch_parallel         7</span><span class="nt">.</span><span class="c">0123  7</span><span class="nt">.</span><span class="c">4567  7</span><span class="nt">.</span><span class="c">1234  0</span><span class="nt">.</span><span class="c">1123  7</span><span class="nt">.</span><span class="c">0891  0</span><span class="nt">.</span><span class="c">0823     2;0  0</span><span class="nt">.</span><span class="c">14       7           1</span>
<span class="c">test_benchmark_batch_sequential       7</span><span class="nt">.</span><span class="c">1234  7</span><span class="nt">.</span><span class="c">5890  7</span><span class="nt">.</span><span class="c">2451  0</span><span class="nt">.</span><span class="c">1234  7</span><span class="nt">.</span><span class="c">2123  0</span><span class="nt">.</span><span class="c">0890     2;0  0</span><span class="nt">.</span><span class="c">14       7           1</span>
<span class="nb">--------------------------------------------------------------------------------------------------------------------------</span>

<span class="c">======================== 2 passed in 102</span><span class="nt">.</span><span class="c">45s =========================</span>
</code></pre></div>

<h3 id="diagnostic-analysis-parallel-vs-sequential-performance">Diagnostic Analysis: Parallel vs. Sequential Performance</h3>
<p><strong>Surprising result</strong>: The parallel version is only marginally faster (~1.7% improvement).</p>
<p><strong>Why?</strong>
1. Our "parallel" implementation is simulated - it just processes in chunks
2. The actual computation is CPU-bound and runs in the same process
3. Python's GIL prevents true parallelism for CPU-bound tasks
4. Real parallelization would require <code>multiprocessing</code> or external workers</p>
<p><strong>This benchmark reveals a performance myth</strong>: Simply calling something "parallel" doesn't make it faster. We need actual parallel execution.</p>
<h2 id="iteration-6-saving-and-comparing-benchmark-results">Iteration 6: Saving and Comparing Benchmark Results</h2>
<p>pytest-benchmark can save results for historical comparison:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Save baseline results</span>
pytest<span class="w"> </span>test_data_processor_benchmark.py<span class="w"> </span>--benchmark-only<span class="w"> </span>--benchmark-save<span class="o">=</span>baseline

<span class="c1"># Make a code change, then compare</span>
pytest<span class="w"> </span>test_data_processor_benchmark.py<span class="w"> </span>--benchmark-only<span class="w"> </span>--benchmark-compare<span class="o">=</span>baseline
</code></pre></div>

<p><strong>Output after comparison</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">--------------------------</span><span class="c"> benchmark: comparison </span><span class="nb">--------------------------</span>
<span class="c">Name (time in ms)                          Min      Max     Mean  StdDev  Median     IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">-----------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_single_transaction      71</span><span class="nt">.</span><span class="c">2341  75</span><span class="nt">.</span><span class="c">8901  72</span><span class="nt">.</span><span class="c">4512  1</span><span class="nt">.</span><span class="c">2341  72</span><span class="nt">.</span><span class="c">1234  0</span><span class="nt">.</span><span class="c">8901     2;0  13</span><span class="nt">.</span><span class="c">80      14           1</span>

<span class="c">Compared to baseline:</span>
<span class="c">  test_benchmark_single_transaction: 1</span><span class="nt">.</span><span class="c">02x slower (72</span><span class="nt">.</span><span class="c">45ms vs 71</span><span class="nt">.</span><span class="c">03ms)</span>
<span class="nb">-----------------------------------------------------------------------------------------------------------------------------</span>
</code></pre></div>

<p>This allows tracking performance regressions over time.</p>
<h2 id="advanced-benchmark-configuration">Advanced Benchmark Configuration</h2>
<p>pytest-benchmark supports fine-grained control:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_with_custom_config</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark with custom configuration.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Configure benchmark behavior</span>
    <span class="n">benchmark</span><span class="o">.</span><span class="n">pedantic</span><span class="p">(</span>
        <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">transaction</span><span class="p">,),</span>
        <span class="n">rounds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>        <span class="c1"># Number of measurement rounds</span>
        <span class="n">iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>    <span class="c1"># Calls per round</span>
        <span class="n">warmup_rounds</span><span class="o">=</span><span class="mi">5</span>   <span class="c1"># Warmup before measuring</span>
    <span class="p">)</span>
</code></pre></div>

<p><strong>Configuration options</strong>:
- <code>rounds</code>: Number of times to measure (more = better statistics)
- <code>iterations</code>: Calls per measurement (for very fast operations)
- <code>warmup_rounds</code>: Runs before measurement (to stabilize JIT, caches)</p>
<h2 id="when-to-apply-benchmark-testing">When to Apply Benchmark Testing</h2>
<h3 id="use-pytest-benchmark-when">Use pytest-benchmark when:</h3>
<ul>
<li><strong>Comparing implementations</strong>: Which algorithm is faster?</li>
<li><strong>Tracking regressions</strong>: Has performance degraded over time?</li>
<li><strong>Validating optimizations</strong>: Did the optimization actually help?</li>
<li><strong>Establishing baselines</strong>: What is acceptable performance?</li>
</ul>
<h3 id="avoid-pytest-benchmark-when">Avoid pytest-benchmark when:</h3>
<ul>
<li><strong>Testing I/O-bound operations</strong>: Network/disk latency dominates</li>
<li><strong>Non-deterministic operations</strong>: Results vary too much to measure</li>
<li><strong>One-time scripts</strong>: Overhead not worth the setup</li>
<li><strong>Already using profilers</strong>: Different tools for different purposes</li>
</ul>
<h2 id="summary-pytest-benchmark-capabilities">Summary: pytest-benchmark Capabilities</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Benefit</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Automatic statistics</td>
<td>Reliable measurements</td>
<td>All benchmarks</td>
</tr>
<tr>
<td>Warmup rounds</td>
<td>Eliminate JIT effects</td>
<td>CPU-bound operations</td>
</tr>
<tr>
<td>Grouping</td>
<td>Easy comparison</td>
<td>Related implementations</td>
</tr>
<tr>
<td>Historical comparison</td>
<td>Track regressions</td>
<td>CI/CD integration</td>
</tr>
<tr>
<td>Pedantic mode</td>
<td>Fine-grained control</td>
<td>Critical performance paths</td>
</tr>
</tbody>
</table>
<p><strong>Key takeaway</strong>: pytest-benchmark provides statistically rigorous performance testing with minimal code changes. It's the standard tool for Python performance testing.</p>
<h2 id="memory-profiling-in-tests">Memory Profiling in Tests</h2>
<p>Performance isn't just about speed‚Äîmemory usage matters too. Memory leaks, excessive allocations, and inefficient data structures can cause production issues even when code runs fast enough.</p>
<h2 id="why-memory-profiling-matters">Why Memory Profiling Matters</h2>
<h3 id="common-memory-problems">Common Memory Problems</h3>
<ol>
<li><strong>Memory leaks</strong>: Objects not released, causing gradual memory growth</li>
<li><strong>Excessive allocations</strong>: Creating too many temporary objects</li>
<li><strong>Large data structures</strong>: Holding more data in memory than necessary</li>
<li><strong>Cache bloat</strong>: Caches that grow unbounded</li>
<li><strong>Reference cycles</strong>: Objects that can't be garbage collected</li>
</ol>
<h3 id="when-memory-profiling-is-critical">When Memory Profiling Is Critical</h3>
<ul>
<li><strong>Long-running services</strong>: Memory leaks accumulate over time</li>
<li><strong>Data processing pipelines</strong>: Large datasets can exhaust memory</li>
<li><strong>Caching systems</strong>: Need to verify cache size limits work</li>
<li><strong>Embedded systems</strong>: Limited memory requires careful management</li>
<li><strong>Container deployments</strong>: Memory limits trigger OOM kills</li>
</ul>
<h2 id="iteration-1-basic-memory-measurement-with-tracemalloc">Iteration 1: Basic Memory Measurement with tracemalloc</h2>
<p>Python's built-in <code>tracemalloc</code> module provides memory profiling:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_memory.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tracemalloc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_memory_single_transaction</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Measure memory usage for single transaction.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Start memory tracking</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># Take snapshot before operation</span>
    <span class="n">snapshot_before</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="c1"># Perform operation</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>

    <span class="c1"># Take snapshot after operation</span>
    <span class="n">snapshot_after</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="c1"># Stop tracking</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="c1"># Calculate memory difference</span>
    <span class="n">top_stats</span> <span class="o">=</span> <span class="n">snapshot_after</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot_before</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="n">total_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">top_stats</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Memory used: </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>

    <span class="c1"># Assert reasonable memory usage (&lt; 1 MB for single transaction)</span>
    <span class="k">assert</span> <span class="n">total_memory</span> <span class="o">&lt;</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Used </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB, expected &lt; 1024 KB&quot;</span>

    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_memory.py::test_memory_single_transaction<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor_memory.py::test_memory_single_transaction 
Memory used: 45.23 KB
PASSED

======================== 1 passed in 0.12s =========================
</code></pre></div>

<p>Single transaction uses ~45 KB, well under our 1 MB limit.</p>
<h2 id="iteration-2-testing-cache-memory-growth">Iteration 2: Testing Cache Memory Growth</h2>
<p>Let's verify that our cache doesn't grow unbounded:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_cache_memory_growth</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify cache doesn&#39;t grow unbounded.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">snapshot_before</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="c1"># Process many unique transactions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
            <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
            <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="p">}</span>
        <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>

    <span class="n">snapshot_after</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="n">top_stats</span> <span class="o">=</span> <span class="n">snapshot_after</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot_before</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="n">total_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">top_stats</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Memory used for 1000 cached items: </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>

    <span class="c1"># Cache should use reasonable memory (&lt; 5 MB for 1000 items)</span>
    <span class="k">assert</span> <span class="n">total_memory</span> <span class="o">&lt;</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Cache used </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB, expected &lt; 5120 KB&quot;</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_memory.py::test_cache_memory_growth<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor_memory.py::test_cache_memory_growth 
Memory used for 1000 cached items: 234.56 KB
PASSED

======================== 1 passed in 7.45s =========================
</code></pre></div>

<p>The cache uses ~235 KB for 1000 items, which is reasonable.</p>
<h2 id="iteration-3-detecting-memory-leaks">Iteration 3: Detecting Memory Leaks</h2>
<p>Let's test for memory leaks by processing many batches:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_no_memory_leak_in_batch_processing</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify batch processing doesn&#39;t leak memory.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">make_batch</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># Process first batch and measure</span>
    <span class="n">snapshot1</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">make_batch</span><span class="p">())</span>
    <span class="n">snapshot2</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="c1"># Process second batch and measure</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">make_batch</span><span class="p">())</span>
    <span class="n">snapshot3</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="c1"># Calculate memory growth</span>
    <span class="n">first_batch_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">snapshot2</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot1</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">second_batch_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">snapshot3</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot2</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">First batch: </span><span class="si">{</span><span class="n">first_batch_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Second batch: </span><span class="si">{</span><span class="n">second_batch_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>

    <span class="c1"># Second batch should use similar or less memory (allowing 20% variance)</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">second_batch_memory</span> <span class="o">/</span> <span class="n">first_batch_memory</span>
    <span class="k">assert</span> <span class="mf">0.5</span> <span class="o">&lt;=</span> <span class="n">ratio</span> <span class="o">&lt;=</span> <span class="mf">1.2</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Memory growth ratio </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, expected ~1.0 (no leak)&quot;</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_memory.py::test_no_memory_leak_in_batch_processing<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor_memory.py::test_no_memory_leak_in_batch_processing 
First batch: 1234.56 KB
Second batch: 1245.67 KB
PASSED

======================== 1 passed in 14.89s =========================
</code></pre></div>

<p>Memory usage is consistent between batches, indicating no leak.</p>
<h2 id="iteration-4-using-memory_profiler-for-detailed-analysis">Iteration 4: Using memory_profiler for Detailed Analysis</h2>
<p>For more detailed memory profiling, we can use the <code>memory_profiler</code> package:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>memory_profiler
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">memory_profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">profile</span>

<span class="nd">@profile</span>
<span class="k">def</span><span class="w"> </span><span class="nf">process_large_batch</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Profile memory usage of large batch processing.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_memory_profile_large_batch</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test with memory profiling enabled.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_large_batch</span><span class="p">()</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1000</span>
</code></pre></div>

<p>Running with memory profiling:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_memory.py::test_memory_profile_large_batch<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="gh">Line #    Mem usage    Increment  Occurrences   Line Contents</span>
<span class="gh">=============================================================</span>
     5     45.2 MiB     45.2 MiB           1   @profile
     6                                         def process_large_batch():
     7                                             &quot;&quot;&quot;Profile memory usage of large batch processing.&quot;&quot;&quot;
     8     45.3 MiB      0.1 MiB           1       processor = DataProcessor()
     9     47.8 MiB      2.5 MiB           1       transactions = [
    10                                                 {&#39;amount&#39;: 100.0 + i, &#39;merchant&#39;: f&#39;Store {i}&#39;, &#39;customer_id&#39;: f&#39;C{i}&#39;}
    11                                                 for i in range(1000)
    12                                             ]
    13     52.1 MiB      4.3 MiB           1       return processor.process_batch(transactions)

test_data_processor_memory.py::test_memory_profile_large_batch PASSED
</code></pre></div>

<h3 id="diagnostic-analysis-reading-memory-profiles">Diagnostic Analysis: Reading Memory Profiles</h3>
<p><strong>The memory_profiler output shows</strong>:</p>
<ol>
<li><strong>Line 8</strong>: Creating processor uses 0.1 MiB (minimal overhead)</li>
<li><strong>Lines 9-12</strong>: Creating 1000 transactions uses 2.5 MiB</li>
<li><strong>Line 13</strong>: Processing batch uses 4.3 MiB (includes results + cache)</li>
</ol>
<p><strong>What this tells us</strong>:
- Most memory is used during processing (4.3 MiB)
- Input data is relatively small (2.5 MiB)
- Total memory footprint is ~7 MiB for 1000 transactions</p>
<h2 id="iteration-5-creating-a-memory-profiling-fixture">Iteration 5: Creating a Memory Profiling Fixture</h2>
<p>Let's create a reusable fixture for memory testing:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tracemalloc</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">memory_tracker</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fixture to track memory usage in tests.&quot;&quot;&quot;</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">snapshot_before</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="k">yield</span>

    <span class="n">snapshot_after</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="n">top_stats</span> <span class="o">=</span> <span class="n">snapshot_after</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot_before</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="n">total_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">top_stats</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Memory used: </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>

    <span class="c1"># Print top 5 memory allocations</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top 5 memory allocations:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">top_stats</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">stat</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_with_memory_tracking</span><span class="p">(</span><span class="n">memory_tracker</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test using memory tracking fixture.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
</code></pre></div>

<p>Running with the fixture:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_memory.py::test_with_memory_tracking<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor_memory.py::test_with_memory_tracking 
Memory used: 456.78 KB

Top 5 memory allocations:
  data_processor.py:25: size=234 KiB (+234 KiB), count=1000 (+1000), average=240 B
  data_processor.py:42: size=123 KiB (+123 KiB), count=500 (+500), average=252 B
  test_data_processor_memory.py:78: size=89 KiB (+89 KiB), count=100 (+100), average=912 B
  ...

PASSED
</code></pre></div>

<p>The fixture provides detailed memory allocation information automatically.</p>
<h2 id="iteration-6-testing-memory-limits">Iteration 6: Testing Memory Limits</h2>
<p>Let's verify that our code respects memory constraints:</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_batch_processing_memory_limit</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify batch processing stays within memory limit.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>

    <span class="c1"># Set a memory limit (10 MB)</span>
    <span class="n">memory_limit</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>

    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">snapshot_before</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="c1"># Process large batch</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>

    <span class="n">snapshot_after</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="n">top_stats</span> <span class="o">=</span> <span class="n">snapshot_after</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot_before</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="n">total_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">top_stats</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Memory used: </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory limit: </span><span class="si">{</span><span class="n">memory_limit</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">total_memory</span> <span class="o">&lt;</span> <span class="n">memory_limit</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Used </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB, limit is </span><span class="si">{</span><span class="n">memory_limit</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> MB&quot;</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1000</span>
</code></pre></div>

<p>Running this test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_memory.py::test_batch_processing_memory_limit<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>test_data_processor_memory.py::test_batch_processing_memory_limit 
Memory used: 7.23 MB
Memory limit: 10.00 MB
PASSED

======================== 1 passed in 7.89s =========================
</code></pre></div>

<p>The batch processing stays well within the 10 MB limit.</p>
<h2 id="common-memory-issues-and-their-signatures">Common Memory Issues and Their Signatures</h2>
<h3 id="symptom-gradual-memory-growth-over-time">Symptom: Gradual Memory Growth Over Time</h3>
<p><strong>Diagnostic clues</strong>:
- Memory usage increases with each iteration
- Ratio of second_batch_memory / first_batch_memory &gt; 1.2
- <code>tracemalloc</code> shows accumulating allocations</p>
<p><strong>Root cause</strong>: Memory leak - objects not being released</p>
<p><strong>Solution</strong>: Check for:
- Unbounded caches
- Event listeners not being removed
- Circular references preventing garbage collection</p>
<h3 id="symptom-sudden-large-memory-spike">Symptom: Sudden Large Memory Spike</h3>
<p><strong>Diagnostic clues</strong>:
- Single operation uses disproportionate memory
- <code>memory_profiler</code> shows large allocation on specific line
- Memory usage doesn't decrease after operation</p>
<p><strong>Root cause</strong>: Loading entire dataset into memory</p>
<p><strong>Solution</strong>: Use streaming/chunking:
- Process data in batches
- Use generators instead of lists
- Implement pagination for large queries</p>
<h3 id="symptom-memory-usage-higher-than-expected">Symptom: Memory Usage Higher Than Expected</h3>
<p><strong>Diagnostic clues</strong>:
- Total memory exceeds theoretical minimum
- Many small allocations in <code>tracemalloc</code> output
- Memory usage varies significantly between runs</p>
<p><strong>Root cause</strong>: Inefficient data structures or excessive copying</p>
<p><strong>Solution</strong>:
- Use appropriate data structures (sets vs lists)
- Avoid unnecessary copying
- Use <code>__slots__</code> for classes with many instances</p>
<h2 id="when-to-apply-memory-profiling">When to Apply Memory Profiling</h2>
<h3 id="use-memory-profiling-when">Use memory profiling when:</h3>
<ul>
<li><strong>Long-running services</strong>: Memory leaks accumulate</li>
<li><strong>Large data processing</strong>: Need to verify memory efficiency</li>
<li><strong>Container deployments</strong>: Memory limits are enforced</li>
<li><strong>Cache implementations</strong>: Need to verify size limits</li>
<li><strong>Performance optimization</strong>: Memory and speed are related</li>
</ul>
<h3 id="avoid-memory-profiling-when">Avoid memory profiling when:</h3>
<ul>
<li><strong>Short-lived scripts</strong>: Memory is released on exit</li>
<li><strong>Small data volumes</strong>: Memory usage is negligible</li>
<li><strong>I/O-bound operations</strong>: Memory isn't the bottleneck</li>
<li><strong>Prototype code</strong>: Premature optimization</li>
</ul>
<h2 id="summary-memory-profiling-techniques">Summary: Memory Profiling Techniques</h2>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Use Case</th>
<th>Granularity</th>
<th>Overhead</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tracemalloc</code></td>
<td>General memory tracking</td>
<td>Line-level</td>
<td>Low</td>
</tr>
<tr>
<td><code>memory_profiler</code></td>
<td>Detailed analysis</td>
<td>Line-level</td>
<td>High</td>
</tr>
<tr>
<td>Custom fixtures</td>
<td>Automated testing</td>
<td>Test-level</td>
<td>Low</td>
</tr>
<tr>
<td>Manual snapshots</td>
<td>Specific operations</td>
<td>Operation-level</td>
<td>Low</td>
</tr>
</tbody>
</table>
<p><strong>Key takeaway</strong>: Memory profiling is essential for production-ready code. Use <code>tracemalloc</code> for automated testing and <code>memory_profiler</code> for detailed investigation.</p>
<h2 id="identifying-and-fixing-slow-tests">Identifying and Fixing Slow Tests</h2>
<p>A slow test suite is a productivity killer. Developers avoid running tests, CI/CD pipelines become bottlenecks, and feedback loops extend from seconds to minutes. This section focuses on identifying slow tests and applying systematic fixes.</p>
<h2 id="the-cost-of-slow-tests">The Cost of Slow Tests</h2>
<h3 id="impact-on-development-workflow">Impact on Development Workflow</h3>
<ul>
<li><strong>Local development</strong>: Developers skip running full suite</li>
<li><strong>CI/CD pipelines</strong>: Builds take too long, blocking deployments</li>
<li><strong>Feedback loops</strong>: Bugs discovered hours after commit</li>
<li><strong>Test parallelization</strong>: Becomes necessary but adds complexity</li>
<li><strong>Developer morale</strong>: Frustration with slow feedback</li>
</ul>
<h3 id="what-constitutes-slow">What Constitutes "Slow"?</h3>
<p><strong>General guidelines</strong>:
- <strong>Unit tests</strong>: &lt; 100ms each, &lt; 10s total
- <strong>Integration tests</strong>: &lt; 1s each, &lt; 1 minute total
- <strong>End-to-end tests</strong>: &lt; 10s each, &lt; 5 minutes total
- <strong>Full suite</strong>: &lt; 10 minutes (ideally &lt; 5 minutes)</p>
<h2 id="iteration-1-identifying-slow-tests-with-durations">Iteration 1: Identifying Slow Tests with --durations</h2>
<p>We've already seen <code>--durations</code>, but let's use it systematically:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Show slowest 10 tests</span>
pytest<span class="w"> </span>--durations<span class="o">=</span><span class="m">10</span>

<span class="c1"># Show all test durations</span>
pytest<span class="w"> </span>--durations<span class="o">=</span><span class="m">0</span>

<span class="c1"># Show only tests slower than 1 second</span>
pytest<span class="w"> </span>--durations-min<span class="o">=</span><span class="m">1</span>.0
</code></pre></div>

<p>Running on our test suite:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor.py<span class="w"> </span>test_data_processor_benchmark.py<span class="w"> </span>test_data_processor_memory.py<span class="w"> </span>--durations<span class="o">=</span><span class="m">10</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>======================== slowest 10 test durations ========================
7.2451s call     test_data_processor_benchmark.py::test_benchmark_batch_processing
7.1234s call     test_data_processor_benchmark.py::test_benchmark_batch_sequential
7.0123s call     test_data_processor_benchmark.py::test_benchmark_batch_parallel
1.4800s call     test_data_processor.py::test_batch_performance_scaling_fixed
0.8200s call     test_data_processor.py::test_cache_improves_performance
0.1500s call     test_data_processor.py::test_batch_processing_preserves_data
0.0800s call     test_data_processor.py::test_cache_returns_consistent_scores
0.0700s call     test_data_processor.py::test_risk_score_range
0.0120s call     test_data_processor_memory.py::test_memory_single_transaction
0.0050s setup    test_data_processor_benchmark.py::test_benchmark_single_transaction
======================== 15 passed in 45.67s =========================
</code></pre></div>

<h3 id="diagnostic-analysis-identifying-bottlenecks">Diagnostic Analysis: Identifying Bottlenecks</h3>
<p><strong>The slowest tests</strong>:
1. Benchmark tests: 7+ seconds each (expected - they run multiple iterations)
2. <code>test_batch_performance_scaling_fixed</code>: 1.48s (processing 110 transactions)
3. <code>test_cache_improves_performance</code>: 0.82s (20 repeated calculations)</p>
<p><strong>What this tells us</strong>:
- Benchmark tests are slow by design (not a problem)
- Regular tests processing batches are slow (potential optimization target)
- Tests with repeated operations accumulate time</p>
<p><strong>Current limitation</strong>: We can see which tests are slow, but not why they're slow or how to fix them.</p>
<h2 id="iteration-2-profiling-individual-tests">Iteration 2: Profiling Individual Tests</h2>
<p>Let's profile a slow test to understand where time is spent:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_profiling.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cProfile</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pstats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_profile_batch_processing</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Profile batch processing to identify bottlenecks.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Create profiler</span>
    <span class="n">profiler</span> <span class="o">=</span> <span class="n">cProfile</span><span class="o">.</span><span class="n">Profile</span><span class="p">()</span>

    <span class="c1"># Profile the operation</span>
    <span class="n">profiler</span><span class="o">.</span><span class="n">enable</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="n">profiler</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>

    <span class="c1"># Print statistics</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">()</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="n">pstats</span><span class="o">.</span><span class="n">Stats</span><span class="p">(</span><span class="n">profiler</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
    <span class="n">stats</span><span class="o">.</span><span class="n">sort_stats</span><span class="p">(</span><span class="s1">&#39;cumulative&#39;</span><span class="p">)</span>
    <span class="n">stats</span><span class="o">.</span><span class="n">print_stats</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Top 10 functions</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">stream</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
</code></pre></div>

<p>Running with profiling:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_profiling.py::test_profile_batch_processing<span class="w"> </span>-v<span class="w"> </span>-s
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      100    0.012    0.000    7.234    0.072 data_processor.py:12(calculate_risk_score)
    10000    5.123    0.001    5.123    0.001 {built-in method hashlib.sha256}
      100    1.234    0.012    1.234    0.012 {method &#39;digest&#39; of &#39;_hashlib.HASH&#39; objects}
      100    0.456    0.005    0.456    0.005 {built-in method json.dumps}
      100    0.234    0.002    0.234    0.002 data_processor.py:28(_get_cache_key)
        1    0.123    0.123    7.456    7.456 data_processor.py:35(process_batch)
      ...

test_data_processor_profiling.py::test_profile_batch_processing PASSED
</code></pre></div>

<h3 id="diagnostic-analysis-reading-profile-output">Diagnostic Analysis: Reading Profile Output</h3>
<p><strong>Key findings</strong>:
1. <strong><code>hashlib.sha256</code></strong>: 5.123s total (71% of time) - called 10,000 times
2. <strong><code>calculate_risk_score</code></strong>: 7.234s cumulative - the main bottleneck
3. <strong><code>digest</code> method</strong>: 1.234s - hash finalization
4. <strong><code>json.dumps</code></strong>: 0.456s - serialization overhead</p>
<p><strong>Root cause</strong>: The expensive hash operations dominate execution time. Each transaction requires 100 hash iterations.</p>
<p><strong>Optimization opportunities</strong>:
1. Reduce number of hash iterations
2. Cache more aggressively
3. Use faster hashing algorithm
4. Parallelize processing</p>
<h2 id="iteration-3-optimizing-with-reduced-hash-iterations">Iteration 3: Optimizing with Reduced Hash Iterations</h2>
<p>Let's create an optimized version:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># data_processor_optimized.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hashlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>

<span class="k">class</span><span class="w"> </span><span class="nc">OptimizedDataProcessor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimized version with fewer hash iterations.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cache_enabled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">hash_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_enabled</span> <span class="o">=</span> <span class="n">cache_enabled</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hash_iterations</span> <span class="o">=</span> <span class="n">hash_iterations</span>  <span class="c1"># Reduced from 100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_risk_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transaction</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate risk score with configurable iterations.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_enabled</span><span class="p">:</span>
            <span class="n">cache_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cache_key</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>

        <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">transaction</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Reduced iterations</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hash_iterations</span><span class="p">):</span>
            <span class="n">hash_obj</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">data</span><span class="si">}{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">encode</span><span class="p">())</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">hash_obj</span><span class="o">.</span><span class="n">digest</span><span class="p">())</span> <span class="o">/</span> <span class="mi">1000000</span>

        <span class="n">score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">score</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">hash_iterations</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_enabled</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>

        <span class="k">return</span> <span class="n">score</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_cache_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transaction</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">transaction</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">()</span>
        <span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">process_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transactions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">transaction</span> <span class="ow">in</span> <span class="n">transactions</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">transaction</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">result</span><span class="p">[</span><span class="s1">&#39;risk_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
            <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

<p>Now let's compare the optimized version:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_profiling.py (additions)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor_optimized</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizedDataProcessor</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;optimization&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_original</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark original implementation.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;optimization&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_optimized</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark optimized implementation.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">OptimizedDataProcessor</span><span class="p">(</span><span class="n">hash_iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
</code></pre></div>

<p>Running the comparison:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_profiling.py<span class="w"> </span>-v<span class="w"> </span>--benchmark-only<span class="w"> </span>--benchmark-group-by<span class="o">=</span>group
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">--------------------------</span><span class="c"> benchmark &#39;optimization&#39;: 2 tests </span><span class="nb">--------------------------</span>
<span class="c">Name (time in ms)                          Min      Max     Mean  StdDev  Median     IQR  Outliers  OPS  Rounds  Iterations</span>
<span class="nb">-----------------------------------------------------------------------------------------------------------------------------</span>
<span class="c">test_benchmark_optimized                723</span><span class="nt">.</span><span class="c">45   756</span><span class="nt">.</span><span class="c">78  734</span><span class="nt">.</span><span class="c">12   12</span><span class="nt">.</span><span class="c">34  731</span><span class="nt">.</span><span class="c">23   8</span><span class="nt">.</span><span class="c">90     2;0   1</span><span class="nt">.</span><span class="c">36       7           1</span>
<span class="c">test_benchmark_original                7123</span><span class="nt">.</span><span class="c">45  7589</span><span class="nt">.</span><span class="c">01 7245</span><span class="nt">.</span><span class="c">12  123</span><span class="nt">.</span><span class="c">45 7212</span><span class="nt">.</span><span class="c">34  89</span><span class="nt">.</span><span class="c">01     2;0   0</span><span class="nt">.</span><span class="c">14       7           1</span>
<span class="nb">-----------------------------------------------------------------------------------------------------------------------------</span>

<span class="c">======================== 2 passed in 56</span><span class="nt">.</span><span class="c">78s =========================</span>
</code></pre></div>

<h3 id="diagnostic-analysis-optimization-results">Diagnostic Analysis: Optimization Results</h3>
<p><strong>Performance improvement</strong>:
- Original: ~7245ms (7.2 seconds)
- Optimized: ~734ms (0.7 seconds)
- <strong>Speedup: 9.87x faster</strong></p>
<p><strong>Trade-off</strong>: Reduced hash iterations may affect risk score accuracy. This is a business decision: is 10x faster processing worth slightly less precise scores?</p>
<h2 id="iteration-4-fixing-slow-tests-with-fixtures">Iteration 4: Fixing Slow Tests with Fixtures</h2>
<p>Many slow tests are slow because they repeat expensive setup. Let's use fixtures to share setup:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Shared processor instance for all tests in module.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DataProcessor</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sample_transactions</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Shared test transactions.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">single_transaction</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single transaction for testing.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>
</code></pre></div>

<p>Now refactor tests to use fixtures:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_fast.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_risk_score_range_fast</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast version using fixtures.&quot;&quot;&quot;</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_processing_fast</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">sample_transactions</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast version using shared transactions.&quot;&quot;&quot;</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">sample_transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="s1">&#39;risk_score&#39;</span> <span class="ow">in</span> <span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_cache_consistency_fast</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast version testing cache.&quot;&quot;&quot;</span>
    <span class="n">score1</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="n">score2</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">score1</span> <span class="o">==</span> <span class="n">score2</span>
</code></pre></div>

<p>Running the fast tests:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_fast.py<span class="w"> </span>-v<span class="w"> </span>--durations<span class="o">=</span><span class="m">5</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>======================== slowest 5 test durations ========================
7.2341s call     test_data_processor_fast.py::test_batch_processing_fast
0.0723s call     test_data_processor_fast.py::test_risk_score_range_fast
0.0012s call     test_data_processor_fast.py::test_cache_consistency_fast
0.0001s setup    test_data_processor_fast.py::test_batch_processing_fast
0.0001s teardown test_data_processor_fast.py::test_batch_processing_fast
======================== 3 passed in 7.31s =========================
</code></pre></div>

<p><strong>Observation</strong>: The cache test is now extremely fast (0.0012s) because it reuses the cached result from the previous test. However, this creates test interdependency, which is problematic.</p>
<h2 id="iteration-5-isolating-tests-while-maintaining-speed">Iteration 5: Isolating Tests While Maintaining Speed</h2>
<p>Test interdependency is dangerous. Let's fix it:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py (updated)</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fresh processor instance for each test.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DataProcessor</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor_with_cache</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Processor with primed cache.&quot;&quot;&quot;</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">processor</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_isolated.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_cache_hit_fast</span><span class="p">(</span><span class="n">processor_with_cache</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test cache hit with isolated setup.&quot;&quot;&quot;</span>
    <span class="c1"># Cache is already primed by fixture</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor_with_cache</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="c1"># This should be fast due to cache hit</span>
</code></pre></div>

<p>Now each test is isolated but still fast when appropriate.</p>
<h2 id="iteration-6-using-mocks-to-speed-up-tests">Iteration 6: Using Mocks to Speed Up Tests</h2>
<p>For tests that don't need real computation, use mocks:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_data_processor_mocked.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">unittest.mock</span><span class="w"> </span><span class="kn">import</span> <span class="n">Mock</span><span class="p">,</span> <span class="n">patch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_processing_logic_fast</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test batch processing logic without expensive computation.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>

    <span class="c1"># Mock the expensive calculation</span>
    <span class="k">with</span> <span class="n">patch</span><span class="o">.</span><span class="n">object</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="s1">&#39;calculate_risk_score&#39;</span><span class="p">,</span> <span class="n">return_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;risk_score&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.5</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="o">.</span><span class="n">call_count</span> <span class="o">==</span> <span class="mi">100</span>
</code></pre></div>

<p>Running the mocked test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>test_data_processor_mocked.py::test_batch_processing_logic_fast<span class="w"> </span>-v<span class="w"> </span>--durations<span class="o">=</span><span class="m">1</span>
</code></pre></div>

<p><strong>Output</strong>:</p>
<div class="codehilite"><pre><span></span><code>======================== slowest 1 test durations ========================
0.0023s call     test_data_processor_mocked.py::test_batch_processing_logic_fast
======================== 1 passed in 0.01s =========================
</code></pre></div>

<p><strong>Speedup</strong>: From 7+ seconds to 0.0023 seconds (3000x faster) by mocking the expensive operation.</p>
<p><strong>Trade-off</strong>: We're no longer testing the actual risk calculation, only the batch processing logic.</p>
<h2 id="common-slow-test-patterns-and-fixes">Common Slow Test Patterns and Fixes</h2>
<h3 id="pattern-1-repeated-expensive-setup">Pattern 1: Repeated Expensive Setup</h3>
<p><strong>Symptom</strong>: Multiple tests create the same expensive objects</p>
<p><strong>Fix</strong>: Use module or session-scoped fixtures</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Before: Slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_one</span><span class="p">():</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>  <span class="c1"># Created every test</span>
    <span class="c1"># ...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_two</span><span class="p">():</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>  <span class="c1"># Created again</span>
    <span class="c1"># ...</span>

<span class="c1"># After: Fast</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;module&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">DataProcessor</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_one</span><span class="p">(</span><span class="n">processor</span><span class="p">):</span>  <span class="c1"># Shared instance</span>
    <span class="c1"># ...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_two</span><span class="p">(</span><span class="n">processor</span><span class="p">):</span>  <span class="c1"># Same instance</span>
    <span class="c1"># ...</span>
</code></pre></div>

<h3 id="pattern-2-testing-implementation-details">Pattern 2: Testing Implementation Details</h3>
<p><strong>Symptom</strong>: Tests that verify internal computation are slow</p>
<p><strong>Fix</strong>: Mock internal details, test behavior</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Before: Slow - tests actual hash computation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_risk_calculation</span><span class="p">():</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="c1"># After: Fast - mocks computation, tests integration</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_risk_calculation_integration</span><span class="p">():</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">patch</span><span class="o">.</span><span class="n">object</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="s1">&#39;calculate_risk_score&#39;</span><span class="p">,</span> <span class="n">return_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">([</span><span class="n">transaction</span><span class="p">])</span>
        <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;risk_score&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">0.5</span>
</code></pre></div>

<h3 id="pattern-3-large-data-volumes">Pattern 3: Large Data Volumes</h3>
<p><strong>Symptom</strong>: Tests process unrealistically large datasets</p>
<p><strong>Fix</strong>: Use representative small datasets</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Before: Slow - tests with 10,000 items</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_processing</span><span class="p">():</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_transaction</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">10000</span>

<span class="c1"># After: Fast - tests with 10 items</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_processing</span><span class="p">():</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span><span class="n">make_transaction</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">10</span>
    <span class="c1"># Behavior is the same, just smaller scale</span>
</code></pre></div>

<h3 id="pattern-4-synchronous-io-in-tests">Pattern 4: Synchronous I/O in Tests</h3>
<p><strong>Symptom</strong>: Tests wait for network/disk operations</p>
<p><strong>Fix</strong>: Mock I/O operations</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Before: Slow - actual HTTP request</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_api_call</span><span class="p">():</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://api.example.com/data&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span>

<span class="c1"># After: Fast - mocked response</span>
<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;requests.get&#39;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_api_call</span><span class="p">(</span><span class="n">mock_get</span><span class="p">):</span>
    <span class="n">mock_get</span><span class="o">.</span><span class="n">return_value</span> <span class="o">=</span> <span class="n">Mock</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://api.example.com/data&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span>
</code></pre></div>

<h3 id="pattern-5-unnecessary-computation-in-assertions">Pattern 5: Unnecessary Computation in Assertions</h3>
<p><strong>Symptom</strong>: Assertions perform expensive operations</p>
<p><strong>Fix</strong>: Assert on simpler properties</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Before: Slow - recalculates for assertion</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_results</span><span class="p">():</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">transactions</span><span class="p">]</span>
    <span class="k">assert</span> <span class="p">[</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;risk_score&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span> <span class="o">==</span> <span class="n">expected</span>

<span class="c1"># After: Fast - asserts on properties</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_results</span><span class="p">():</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">r</span><span class="p">[</span><span class="s1">&#39;risk_score&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">1.0</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">results</span><span class="p">)</span>
</code></pre></div>

<h2 id="decision-framework-when-to-optimize-tests">Decision Framework: When to Optimize Tests</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Optimize?</th>
<th>Strategy</th>
</tr>
</thead>
<tbody>
<tr>
<td>Test takes &gt; 1s</td>
<td>Yes</td>
<td>Profile and fix bottleneck</td>
</tr>
<tr>
<td>Test uses real I/O</td>
<td>Yes</td>
<td>Mock external dependencies</td>
</tr>
<tr>
<td>Test processes large data</td>
<td>Maybe</td>
<td>Use smaller representative data</td>
</tr>
<tr>
<td>Test is slow by design (benchmark)</td>
<td>No</td>
<td>Keep as-is, run separately</td>
</tr>
<tr>
<td>Test is slow but rarely run</td>
<td>No</td>
<td>Mark as slow, skip in CI</td>
</tr>
<tr>
<td>Setup is expensive</td>
<td>Yes</td>
<td>Use fixtures with appropriate scope</td>
</tr>
</tbody>
</table>
<h2 id="summary-strategies-for-fast-tests">Summary: Strategies for Fast Tests</h2>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Speedup</th>
<th>Trade-off</th>
</tr>
</thead>
<tbody>
<tr>
<td>Reduce computation</td>
<td>10-100x</td>
<td>May reduce test coverage</td>
</tr>
<tr>
<td>Use fixtures</td>
<td>2-10x</td>
<td>Requires careful scoping</td>
</tr>
<tr>
<td>Mock expensive operations</td>
<td>100-1000x</td>
<td>Tests behavior, not implementation</td>
</tr>
<tr>
<td>Smaller datasets</td>
<td>10-100x</td>
<td>May miss edge cases</td>
</tr>
<tr>
<td>Parallel execution</td>
<td>2-8x</td>
<td>Requires test isolation</td>
</tr>
</tbody>
</table>
<p><strong>Key takeaway</strong>: Fast tests are essential for productivity. Profile to identify bottlenecks, then apply targeted optimizations while maintaining test quality.</p>
<h2 id="performance-testing-in-cicd">Performance Testing in CI/CD</h2>
<p>Performance testing in CI/CD ensures that performance regressions are caught before reaching production. This section covers integrating performance tests into automated pipelines, tracking metrics over time, and establishing performance gates.</p>
<h2 id="why-performance-testing-in-cicd-matters">Why Performance Testing in CI/CD Matters</h2>
<h3 id="the-problem-with-manual-performance-testing">The Problem with Manual Performance Testing</h3>
<ul>
<li><strong>Inconsistent</strong>: Developers test on different machines</li>
<li><strong>Infrequent</strong>: Performance only checked before releases</li>
<li><strong>Reactive</strong>: Problems discovered after merge</li>
<li><strong>Subjective</strong>: No objective performance criteria</li>
</ul>
<h3 id="benefits-of-automated-performance-testing">Benefits of Automated Performance Testing</h3>
<ul>
<li><strong>Early detection</strong>: Catch regressions immediately</li>
<li><strong>Consistent environment</strong>: Same hardware, same conditions</li>
<li><strong>Historical tracking</strong>: See performance trends over time</li>
<li><strong>Objective gates</strong>: Automated pass/fail criteria</li>
<li><strong>Documentation</strong>: Performance characteristics are recorded</li>
</ul>
<h2 id="iteration-1-basic-performance-testing-in-github-actions">Iteration 1: Basic Performance Testing in GitHub Actions</h2>
<p>Let's create a GitHub Actions workflow that runs performance tests:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Performance Tests</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">develop</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="w"> </span><span class="p p-Indicator">]</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">performance</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pip install pytest pytest-benchmark</span>
<span class="w">        </span><span class="no">pip install -r requirements.txt</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run performance tests</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_data_processor_benchmark.py \</span>
<span class="w">          </span><span class="no">--benchmark-only \</span>
<span class="w">          </span><span class="no">--benchmark-json=benchmark_results.json</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload benchmark results</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-results</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark_results.json</span>
</code></pre></div>

<p>This workflow:
1. Runs on every push to main/develop and on pull requests
2. Sets up Python environment
3. Runs benchmark tests
4. Saves results as artifacts</p>
<h2 id="iteration-2-adding-performance-assertions">Iteration 2: Adding Performance Assertions</h2>
<p>Let's add explicit performance requirements that must pass:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_performance_requirements.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_single_transaction_performance_requirement</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single transaction must complete in under 100ms.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>

    <span class="c1"># Assert performance requirement</span>
    <span class="k">assert</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Mean time </span><span class="si">{</span><span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">s exceeds 100ms requirement&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_throughput_requirement</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Must process at least 10 transactions per second.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>

    <span class="c1"># Calculate throughput</span>
    <span class="n">throughput</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">/</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span>  <span class="c1"># transactions per second</span>

    <span class="k">assert</span> <span class="n">throughput</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Throughput </span><span class="si">{</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> tx/s is below 10 tx/s requirement&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_cache_effectiveness_requirement</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache must provide at least 10x speedup.&quot;&quot;&quot;</span>
    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Prime cache</span>
    <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>

    <span class="c1"># Benchmark cached access</span>
    <span class="n">cached_stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>

    <span class="c1"># Compare to known uncached time (~72ms from previous benchmarks)</span>
    <span class="n">uncached_time</span> <span class="o">=</span> <span class="mf">0.072</span>
    <span class="n">speedup</span> <span class="o">=</span> <span class="n">uncached_time</span> <span class="o">/</span> <span class="n">cached_stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span>

    <span class="k">assert</span> <span class="n">speedup</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Cache speedup </span><span class="si">{</span><span class="n">speedup</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x is below 10x requirement&quot;</span>
</code></pre></div>

<p>Update the workflow to run these tests:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance.yml (updated)</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run performance requirements</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_performance_requirements.py -v</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run benchmarks</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_data_processor_benchmark.py \</span>
<span class="w">          </span><span class="no">--benchmark-only \</span>
<span class="w">          </span><span class="no">--benchmark-json=benchmark_results.json</span>
</code></pre></div>

<p>Now the CI pipeline will fail if performance requirements aren't met.</p>
<h2 id="iteration-3-comparing-against-baseline">Iteration 3: Comparing Against Baseline</h2>
<p>Let's track performance over time by comparing against a baseline:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance.yml (updated)</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Download baseline benchmark</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/download-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-baseline</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">.benchmarks</span>
<span class="w">      </span><span class="nt">continue-on-error</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span><span class="w">  </span><span class="c1"># First run won&#39;t have baseline</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run benchmarks with comparison</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_data_processor_benchmark.py \</span>
<span class="w">          </span><span class="no">--benchmark-only \</span>
<span class="w">          </span><span class="no">--benchmark-json=benchmark_results.json \</span>
<span class="w">          </span><span class="no">--benchmark-compare=.benchmarks/benchmark_baseline.json \</span>
<span class="w">          </span><span class="no">--benchmark-compare-fail=mean:10%  # Fail if 10% slower</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Save as new baseline (on main branch)</span>
<span class="w">      </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.ref == &#39;refs/heads/main&#39;</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-baseline</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark_results.json</span>
</code></pre></div>

<p>This workflow:
1. Downloads the baseline from previous runs
2. Compares current performance to baseline
3. Fails if performance degrades by more than 10%
4. Updates baseline when merging to main</p>
<h2 id="iteration-4-generating-performance-reports">Iteration 4: Generating Performance Reports</h2>
<p>Let's create a custom script to generate readable performance reports:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># generate_performance_report.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_report</span><span class="p">(</span><span class="n">benchmark_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate human-readable performance report.&quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">benchmark_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="n">report</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;# Performance Test Report</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Machine: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;machine_info&#39;</span><span class="p">][</span><span class="s1">&#39;machine&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;machine_info&#39;</span><span class="p">][</span><span class="s1">&#39;python_version&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Date: </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;## Benchmark Results</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;| Test | Mean | Min | Max | StdDev | Status |</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;|------|------|-----|-----|--------|--------|</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">benchmark</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;benchmarks&#39;</span><span class="p">]:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">[</span><span class="s1">&#39;stats&#39;</span><span class="p">]</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># Convert to ms</span>
        <span class="n">min_time</span> <span class="o">=</span> <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">max_time</span> <span class="o">=</span> <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">stddev</span> <span class="o">=</span> <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;stddev&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1000</span>

        <span class="c1"># Determine status based on requirements</span>
        <span class="n">status</span> <span class="o">=</span> <span class="s2">&quot;‚úÖ PASS&quot;</span>
        <span class="k">if</span> <span class="s1">&#39;single_transaction&#39;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">and</span> <span class="n">mean</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">status</span> <span class="o">=</span> <span class="s2">&quot;‚ùå FAIL&quot;</span>
        <span class="k">elif</span> <span class="s1">&#39;batch&#39;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">and</span> <span class="n">mean</span> <span class="o">&gt;</span> <span class="mi">10000</span><span class="p">:</span>  <span class="c1"># 10s for 100 items</span>
            <span class="n">status</span> <span class="o">=</span> <span class="s2">&quot;‚ùå FAIL&quot;</span>

        <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;| </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms | </span><span class="si">{</span><span class="n">min_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms | &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">max_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms | </span><span class="si">{</span><span class="n">stddev</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms | </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s2"> |</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## Performance Requirements</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;- ‚úÖ Single transaction: &lt; 100ms</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;- ‚úÖ Batch throughput: &gt; 10 tx/s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">report</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;- ‚úÖ Cache speedup: &gt; 10x</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Report generated: </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Usage: python generate_performance_report.py &lt;benchmark.json&gt; &lt;output.md&gt;&quot;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">generate_report</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</code></pre></div>

<p>Add report generation to the workflow:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance.yml (updated)</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Generate performance report</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">python generate_performance_report.py \</span>
<span class="w">          </span><span class="no">benchmark_results.json \</span>
<span class="w">          </span><span class="no">performance_report.md</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload performance report</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">performance-report</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">performance_report.md</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Comment PR with performance report</span>
<span class="w">      </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;pull_request&#39;</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/github-script@v6</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">script</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">const fs = require(&#39;fs&#39;);</span>
<span class="w">          </span><span class="no">const report = fs.readFileSync(&#39;performance_report.md&#39;, &#39;utf8&#39;);</span>
<span class="w">          </span><span class="no">github.rest.issues.createComment({</span>
<span class="w">            </span><span class="no">issue_number: context.issue.number,</span>
<span class="w">            </span><span class="no">owner: context.repo.owner,</span>
<span class="w">            </span><span class="no">repo: context.repo.repo,</span>
<span class="w">            </span><span class="no">body: report</span>
<span class="w">          </span><span class="no">});</span>
</code></pre></div>

<p>Now every pull request gets an automatic performance report comment.</p>
<h2 id="iteration-5-conditional-performance-testing">Iteration 5: Conditional Performance Testing</h2>
<p>Not all tests need to run on every commit. Let's add conditional execution:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance.yml (updated)</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Performance Tests</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">schedule</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Run full performance suite nightly</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">cron</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;0</span><span class="nv"> </span><span class="s">2</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*&#39;</span>
<span class="w">  </span><span class="nt">workflow_dispatch</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Allow manual triggering</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">quick-performance</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Run on every PR</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;pull_request&#39;</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="c1"># ... setup steps ...</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run quick performance checks</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pytest test_performance_requirements.py -v</span>

<span class="w">  </span><span class="nt">full-performance</span><span class="p">:</span>
<span class="w">    </span><span class="c1"># Run on main branch and nightly</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;push&#39; || github.event_name == &#39;schedule&#39;</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="c1"># ... setup steps ...</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run full benchmark suite</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pytest test_data_processor_benchmark.py \</span>
<span class="w">            </span><span class="no">--benchmark-only \</span>
<span class="w">            </span><span class="no">--benchmark-json=benchmark_results.json</span>

<span class="w">      </span><span class="c1"># ... report generation ...</span>
</code></pre></div>

<p>This approach:
- Runs quick checks on every PR (fast feedback)
- Runs full benchmarks on main branch (comprehensive)
- Runs full suite nightly (catch gradual degradation)</p>
<h2 id="iteration-6-performance-testing-with-different-configurations">Iteration 6: Performance Testing with Different Configurations</h2>
<p>Let's test performance across different Python versions and configurations:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance-matrix.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Performance Matrix</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">schedule</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">cron</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;0</span><span class="nv"> </span><span class="s">2</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">0&#39;</span><span class="w">  </span><span class="c1"># Weekly on Sunday</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">performance-matrix</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ matrix.os }}</span>
<span class="w">    </span><span class="nt">strategy</span><span class="p">:</span>
<span class="w">      </span><span class="nt">matrix</span><span class="p">:</span>
<span class="w">        </span><span class="nt">os</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">ubuntu-latest</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">macos-latest</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&#39;3.9&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;3.10&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="s">&#39;3.12&#39;</span><span class="p p-Indicator">]</span>
<span class="w">        </span><span class="nt">cache-enabled</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">true</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">false</span><span class="p p-Indicator">]</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python ${{ matrix.python-version }}</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ matrix.python-version }}</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pip install pytest pytest-benchmark</span>
<span class="w">        </span><span class="no">pip install -r requirements.txt</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run benchmarks</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_data_processor_benchmark.py \</span>
<span class="w">          </span><span class="no">--benchmark-only \</span>
<span class="w">          </span><span class="no">--benchmark-json=benchmark_${{ matrix.os }}_py${{ matrix.python-version }}_cache${{ matrix.cache-enabled }}.json</span>
<span class="w">      </span><span class="nt">env</span><span class="p">:</span>
<span class="w">        </span><span class="nt">CACHE_ENABLED</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ matrix.cache-enabled }}</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload results</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-matrix-results</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark_*.json</span>
</code></pre></div>

<p>This matrix testing reveals:
- Performance differences across Python versions
- OS-specific performance characteristics
- Impact of configuration options (cache enabled/disabled)</p>
<h2 id="iteration-7-setting-up-performance-budgets">Iteration 7: Setting Up Performance Budgets</h2>
<p>Create a configuration file for performance budgets:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># performance_budgets.yml</span>
<span class="nt">budgets</span><span class="p">:</span>
<span class="w">  </span><span class="nt">single_transaction</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_mean</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span><span class="w">  </span><span class="c1"># milliseconds</span>
<span class="w">    </span><span class="nt">max_stddev</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Single</span><span class="nv"> </span><span class="s">transaction</span><span class="nv"> </span><span class="s">processing&quot;</span>

<span class="w">  </span><span class="nt">batch_100</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_mean</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span><span class="w">  </span><span class="c1"># milliseconds</span>
<span class="w">    </span><span class="nt">min_throughput</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w">  </span><span class="c1"># transactions per second</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Batch</span><span class="nv"> </span><span class="s">of</span><span class="nv"> </span><span class="s">100</span><span class="nv"> </span><span class="s">transactions&quot;</span>

<span class="w">  </span><span class="nt">cache_speedup</span><span class="p">:</span>
<span class="w">    </span><span class="nt">min_ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w">  </span><span class="c1"># times faster</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Cache</span><span class="nv"> </span><span class="s">effectiveness&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># test_performance_budgets.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_budgets</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load performance budgets from config file.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;performance_budgets.yml&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)[</span><span class="s1">&#39;budgets&#39;</span><span class="p">]</span>

<span class="n">BUDGETS</span> <span class="o">=</span> <span class="n">load_budgets</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_single_transaction_budget</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify single transaction meets performance budget.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">transaction</span><span class="p">)</span>

    <span class="n">budget</span> <span class="o">=</span> <span class="n">BUDGETS</span><span class="p">[</span><span class="s1">&#39;single_transaction&#39;</span><span class="p">]</span>
    <span class="n">mean_ms</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mi">1000</span>
    <span class="n">stddev_ms</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">stddev</span> <span class="o">*</span> <span class="mi">1000</span>

    <span class="k">assert</span> <span class="n">mean_ms</span> <span class="o">&lt;</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_mean&#39;</span><span class="p">],</span> \
        <span class="sa">f</span><span class="s2">&quot;Mean </span><span class="si">{</span><span class="n">mean_ms</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms exceeds budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_mean&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">ms&quot;</span>
    <span class="k">assert</span> <span class="n">stddev_ms</span> <span class="o">&lt;</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_stddev&#39;</span><span class="p">],</span> \
        <span class="sa">f</span><span class="s2">&quot;StdDev </span><span class="si">{</span><span class="n">stddev_ms</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms exceeds budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_stddev&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">ms&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_throughput_budget</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify batch processing meets throughput budget.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

    <span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">()</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>

    <span class="n">budget</span> <span class="o">=</span> <span class="n">BUDGETS</span><span class="p">[</span><span class="s1">&#39;batch_100&#39;</span><span class="p">]</span>
    <span class="n">mean_ms</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mi">1000</span>
    <span class="n">throughput</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">/</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span>

    <span class="k">assert</span> <span class="n">mean_ms</span> <span class="o">&lt;</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_mean&#39;</span><span class="p">],</span> \
        <span class="sa">f</span><span class="s2">&quot;Mean </span><span class="si">{</span><span class="n">mean_ms</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms exceeds budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_mean&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">ms&quot;</span>
    <span class="k">assert</span> <span class="n">throughput</span> <span class="o">&gt;=</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;min_throughput&#39;</span><span class="p">],</span> \
        <span class="sa">f</span><span class="s2">&quot;Throughput </span><span class="si">{</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> tx/s below budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;min_throughput&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> tx/s&quot;</span>
</code></pre></div>

<p>Performance budgets provide:
- Clear, documented performance requirements
- Easy-to-update thresholds
- Centralized performance governance
- Business-aligned metrics</p>
<h2 id="common-cicd-performance-testing-patterns">Common CI/CD Performance Testing Patterns</h2>
<h3 id="pattern-1-fast-feedback-loop">Pattern 1: Fast Feedback Loop</h3>
<p><strong>Strategy</strong>: Run quick performance checks on every commit</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Quick checks (&lt; 1 minute)</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Quick performance check</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest test_performance_requirements.py -v --maxfail=1</span>
</code></pre></div>

<h3 id="pattern-2-comprehensive-nightly-builds">Pattern 2: Comprehensive Nightly Builds</h3>
<p><strong>Strategy</strong>: Run full benchmark suite overnight</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Comprehensive benchmarks (10-30 minutes)</span>
<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">schedule</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">cron</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;0</span><span class="nv"> </span><span class="s">2</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*&#39;</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Full benchmark suite</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest tests/ --benchmark-only --benchmark-autosave</span>
</code></pre></div>

<h3 id="pattern-3-baseline-comparison-on-pr">Pattern 3: Baseline Comparison on PR</h3>
<p><strong>Strategy</strong>: Compare PR performance to main branch</p>
<div class="codehilite"><pre><span></span><code><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Checkout main branch</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">git fetch origin main</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run baseline benchmarks</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">    </span><span class="no">git checkout origin/main</span>
<span class="w">    </span><span class="no">pytest --benchmark-only --benchmark-save=baseline</span>

<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run PR benchmarks</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">    </span><span class="no">git checkout ${{ github.sha }}</span>
<span class="w">    </span><span class="no">pytest --benchmark-only --benchmark-compare=baseline</span>
</code></pre></div>

<h3 id="pattern-4-performance-regression-prevention">Pattern 4: Performance Regression Prevention</h3>
<p><strong>Strategy</strong>: Fail build if performance degrades significantly</p>
<div class="codehilite"><pre><span></span><code><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run benchmarks with strict comparison</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">    </span><span class="no">pytest --benchmark-only \</span>
<span class="w">      </span><span class="no">--benchmark-compare=baseline \</span>
<span class="w">      </span><span class="no">--benchmark-compare-fail=mean:5%</span>
</code></pre></div>

<h2 id="handling-performance-test-variability">Handling Performance Test Variability</h2>
<h3 id="problem-ci-environments-are-noisy">Problem: CI Environments Are Noisy</h3>
<p>CI runners share resources, causing performance variability:
- Other jobs running on same host
- Network latency variations
- Disk I/O contention
- CPU throttling</p>
<h3 id="solution-1-use-dedicated-performance-runners">Solution 1: Use Dedicated Performance Runners</h3>
<div class="codehilite"><pre><span></span><code><span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">performance</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">self-hosted</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">performance</span><span class="p p-Indicator">]</span><span class="w">  </span><span class="c1"># Dedicated runner</span>
</code></pre></div>

<h3 id="solution-2-increase-tolerance-thresholds">Solution 2: Increase Tolerance Thresholds</h3>
<div class="codehilite"><pre><span></span><code><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run benchmarks with relaxed thresholds</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">    </span><span class="no">pytest --benchmark-only \</span>
<span class="w">      </span><span class="no">--benchmark-compare-fail=mean:20%  # More tolerant in CI</span>
</code></pre></div>

<h3 id="solution-3-run-multiple-iterations">Solution 3: Run Multiple Iterations</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_stable_performance</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run multiple iterations to reduce variance.&quot;&quot;&quot;</span>
    <span class="n">benchmark</span><span class="o">.</span><span class="n">pedantic</span><span class="p">(</span>
        <span class="n">target_function</span><span class="p">,</span>
        <span class="n">rounds</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>      <span class="c1"># More rounds</span>
        <span class="n">iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>   <span class="c1"># More iterations per round</span>
        <span class="n">warmup_rounds</span><span class="o">=</span><span class="mi">10</span> <span class="c1"># More warmup</span>
    <span class="p">)</span>
</code></pre></div>

<h3 id="solution-4-statistical-comparison">Solution 4: Statistical Comparison</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">test_performance_with_statistics</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Use statistical tests for comparison.&quot;&quot;&quot;</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">target_function</span><span class="p">)</span>

    <span class="c1"># Use median instead of mean (less affected by outliers)</span>
    <span class="k">assert</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">median</span> <span class="o">&lt;</span> <span class="n">threshold</span>

    <span class="c1"># Check that 95th percentile is acceptable</span>
    <span class="k">assert</span> <span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">q_95</span> <span class="o">&lt;</span> <span class="n">threshold</span> <span class="o">*</span> <span class="mf">1.2</span>
</code></pre></div>

<h2 id="decision-framework-performance-testing-in-cicd">Decision Framework: Performance Testing in CI/CD</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Strategy</th>
<th>Frequency</th>
<th>Threshold</th>
</tr>
</thead>
<tbody>
<tr>
<td>Critical path</td>
<td>Strict budget</td>
<td>Every commit</td>
<td>5% degradation</td>
</tr>
<tr>
<td>Standard features</td>
<td>Baseline comparison</td>
<td>Every PR</td>
<td>10% degradation</td>
</tr>
<tr>
<td>Experimental features</td>
<td>Monitoring only</td>
<td>Nightly</td>
<td>No gate</td>
</tr>
<tr>
<td>Optimization work</td>
<td>Detailed benchmarks</td>
<td>On-demand</td>
<td>Show improvement</td>
</tr>
<tr>
<td>Legacy code</td>
<td>Establish baseline</td>
<td>Weekly</td>
<td>Track trends</td>
</tr>
</tbody>
</table>
<h2 id="summary-performance-testing-in-cicd">Summary: Performance Testing in CI/CD</h2>
<h3 id="key-principles">Key Principles</h3>
<ol>
<li><strong>Fast feedback</strong>: Quick checks on every commit</li>
<li><strong>Comprehensive coverage</strong>: Full suite periodically</li>
<li><strong>Baseline tracking</strong>: Compare against known good state</li>
<li><strong>Automated gates</strong>: Fail builds on regression</li>
<li><strong>Visible reports</strong>: Make performance data accessible</li>
</ol>
<h3 id="implementation-checklist">Implementation Checklist</h3>
<ul>
<li>[ ] Define performance budgets</li>
<li>[ ] Create performance requirement tests</li>
<li>[ ] Set up benchmark comparison</li>
<li>[ ] Configure CI workflow</li>
<li>[ ] Generate performance reports</li>
<li>[ ] Establish baseline</li>
<li>[ ] Document performance expectations</li>
<li>[ ] Set up alerts for degradation</li>
</ul>
<h3 id="tools-and-techniques">Tools and Techniques</h3>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Purpose</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td>pytest-benchmark</td>
<td>Rigorous benchmarking</td>
<td>All performance tests</td>
</tr>
<tr>
<td>GitHub Actions</td>
<td>CI/CD automation</td>
<td>Standard workflow</td>
</tr>
<tr>
<td>Performance budgets</td>
<td>Clear requirements</td>
<td>Define expectations</td>
</tr>
<tr>
<td>Baseline comparison</td>
<td>Regression detection</td>
<td>Track changes</td>
</tr>
<tr>
<td>Matrix testing</td>
<td>Cross-platform validation</td>
<td>Comprehensive testing</td>
</tr>
</tbody>
</table>
<p><strong>Key takeaway</strong>: Performance testing in CI/CD catches regressions early, provides objective metrics, and ensures performance remains a first-class concern throughout development.</p>
<h2 id="the-complete-performance-testing-journey">The Complete Performance Testing Journey</h2>
<p>Let's synthesize everything we've learned by reviewing the complete evolution of our performance testing approach.</p>
<h2 id="the-journey-from-problem-to-solution">The Journey: From Problem to Solution</h2>
<table>
<thead>
<tr>
<th>Iteration</th>
<th>Challenge</th>
<th>Technique Applied</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>No performance visibility</td>
<td>Basic correctness tests</td>
<td>Tests pass but no performance data</td>
</tr>
<tr>
<td>1</td>
<td>Need to see test duration</td>
<td><code>--durations</code> flag</td>
<td>Identified slow tests</td>
</tr>
<tr>
<td>2</td>
<td>Need performance assertions</td>
<td>Manual timing with <code>time.perf_counter()</code></td>
<td>Can assert on performance</td>
</tr>
<tr>
<td>3</td>
<td>Timing is unreliable</td>
<td>pytest-benchmark</td>
<td>Statistical rigor</td>
</tr>
<tr>
<td>4</td>
<td>Memory usage unknown</td>
<td>tracemalloc</td>
<td>Memory profiling</td>
</tr>
<tr>
<td>5</td>
<td>Tests are too slow</td>
<td>Profiling + optimization</td>
<td>10x speedup</td>
</tr>
<tr>
<td>6</td>
<td>No regression detection</td>
<td>CI/CD integration</td>
<td>Automated performance gates</td>
</tr>
</tbody>
</table>
<h2 id="final-implementation-production-ready-performance-testing">Final Implementation: Production-Ready Performance Testing</h2>
<p>Here's the complete, production-ready performance testing setup:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py - Shared fixtures and configuration</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tracemalloc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">data_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fresh processor instance for each test.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DataProcessor</span><span class="p">()</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor_cached</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Processor with caching enabled.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">processor_uncached</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Processor with caching disabled.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">single_transaction</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Standard test transaction.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span>
        <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test Store&#39;</span><span class="p">,</span>
        <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C123&#39;</span>
    <span class="p">}</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">batch_transactions</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch of 100 test transactions.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span>
            <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
            <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="p">]</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span>
<span class="k">def</span><span class="w"> </span><span class="nf">memory_tracker</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Track memory usage during test.&quot;&quot;&quot;</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">snapshot_before</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="k">yield</span>

    <span class="n">snapshot_after</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>
    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="n">top_stats</span> <span class="o">=</span> <span class="n">snapshot_after</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot_before</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">)</span>
    <span class="n">total_memory</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">stat</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">top_stats</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Memory used: </span><span class="si">{</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> KB&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># test_performance_suite.py - Complete performance test suite</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_budgets</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load performance budgets from configuration.&quot;&quot;&quot;</span>
    <span class="n">budget_file</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span> <span class="o">/</span> <span class="s1">&#39;performance_budgets.yml&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">budget_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)[</span><span class="s1">&#39;budgets&#39;</span><span class="p">]</span>

<span class="n">BUDGETS</span> <span class="o">=</span> <span class="n">load_budgets</span><span class="p">()</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Performance Requirement Tests (Run on every commit)</span>
<span class="c1"># ============================================================================</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_single_transaction_performance</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Single transaction must meet performance budget.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="n">budget</span> <span class="o">=</span> <span class="n">BUDGETS</span><span class="p">[</span><span class="s1">&#39;single_transaction&#39;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">duration</span> <span class="o">&lt;</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_mean&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Duration </span><span class="si">{</span><span class="n">duration</span><span class="o">*</span><span class="mi">1000</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms exceeds budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;max_mean&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">ms&quot;</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_batch_throughput</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">batch_transactions</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch processing must meet throughput budget.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">batch_transactions</span><span class="p">)</span>
    <span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="n">throughput</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_transactions</span><span class="p">)</span> <span class="o">/</span> <span class="n">duration</span>
    <span class="n">budget</span> <span class="o">=</span> <span class="n">BUDGETS</span><span class="p">[</span><span class="s1">&#39;batch_100&#39;</span><span class="p">]</span>

    <span class="k">assert</span> <span class="n">throughput</span> <span class="o">&gt;=</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;min_throughput&#39;</span><span class="p">],</span> \
        <span class="sa">f</span><span class="s2">&quot;Throughput </span><span class="si">{</span><span class="n">throughput</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> tx/s below budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;min_throughput&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> tx/s&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_transactions</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_cache_effectiveness</span><span class="p">(</span><span class="n">processor_cached</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Cache must provide required speedup.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

    <span class="c1"># Measure uncached</span>
    <span class="n">processor_uncached</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">cache_enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">processor_uncached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="n">uncached_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="c1"># Prime cache</span>
    <span class="n">processor_cached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>

    <span class="c1"># Measure cached</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
    <span class="n">processor_cached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="n">cached_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>

    <span class="n">speedup</span> <span class="o">=</span> <span class="n">uncached_time</span> <span class="o">/</span> <span class="n">cached_time</span>
    <span class="n">budget</span> <span class="o">=</span> <span class="n">BUDGETS</span><span class="p">[</span><span class="s1">&#39;cache_speedup&#39;</span><span class="p">]</span>

    <span class="k">assert</span> <span class="n">speedup</span> <span class="o">&gt;=</span> <span class="n">budget</span><span class="p">[</span><span class="s1">&#39;min_ratio&#39;</span><span class="p">],</span> \
        <span class="sa">f</span><span class="s2">&quot;Cache speedup </span><span class="si">{</span><span class="n">speedup</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x below budget </span><span class="si">{</span><span class="n">budget</span><span class="p">[</span><span class="s1">&#39;min_ratio&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">x&quot;</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Benchmark Tests (Run periodically)</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;single-transaction&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_single_cached</span><span class="p">(</span><span class="n">benchmark</span><span class="p">,</span> <span class="n">processor_cached</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark single transaction with cache.&quot;&quot;&quot;</span>
    <span class="n">processor_cached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>  <span class="c1"># Prime</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor_cached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;single-transaction&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_single_uncached</span><span class="p">(</span><span class="n">benchmark</span><span class="p">,</span> <span class="n">processor_uncached</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark single transaction without cache.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor_uncached</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">result</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;batch-processing&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_batch_100</span><span class="p">(</span><span class="n">benchmark</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">batch_transactions</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark batch of 100 transactions.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">batch_transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;batch-processing&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_benchmark_batch_1000</span><span class="p">(</span><span class="n">benchmark</span><span class="p">,</span> <span class="n">processor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark batch of 1000 transactions.&quot;&quot;&quot;</span>
    <span class="n">large_batch</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">large_batch</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1000</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Memory Tests (Run periodically)</span>
<span class="c1"># ============================================================================</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_memory_single_transaction</span><span class="p">(</span><span class="n">memory_tracker</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">single_transaction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify single transaction memory usage.&quot;&quot;&quot;</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">single_transaction</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">score</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="c1"># Memory usage printed by fixture</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_memory_batch_processing</span><span class="p">(</span><span class="n">memory_tracker</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">batch_transactions</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify batch processing memory usage.&quot;&quot;&quot;</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">(</span><span class="n">batch_transactions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_transactions</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_no_memory_leak</span><span class="p">(</span><span class="n">processor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify no memory leak in repeated processing.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">tracemalloc</span>

    <span class="n">transaction</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="s1">&#39;Test&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="s1">&#39;C1&#39;</span><span class="p">}</span>

    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># First batch</span>
    <span class="n">snapshot1</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">snapshot2</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="c1"># Second batch</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">processor</span><span class="o">.</span><span class="n">calculate_risk_score</span><span class="p">(</span><span class="n">transaction</span><span class="p">)</span>
    <span class="n">snapshot3</span> <span class="o">=</span> <span class="n">tracemalloc</span><span class="o">.</span><span class="n">take_snapshot</span><span class="p">()</span>

    <span class="n">tracemalloc</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

    <span class="c1"># Compare memory growth</span>
    <span class="n">first_growth</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">snapshot2</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot1</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">))</span>
    <span class="n">second_growth</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">size_diff</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">snapshot3</span><span class="o">.</span><span class="n">compare_to</span><span class="p">(</span><span class="n">snapshot2</span><span class="p">,</span> <span class="s1">&#39;lineno&#39;</span><span class="p">))</span>

    <span class="c1"># Second batch should use similar or less memory</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">second_growth</span> <span class="o">/</span> <span class="n">first_growth</span> <span class="k">if</span> <span class="n">first_growth</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">ratio</span> <span class="o">&lt;=</span> <span class="mf">1.2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Memory growth ratio </span><span class="si">{</span><span class="n">ratio</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> indicates potential leak&quot;</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Scaling Tests (Run on-demand)</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_scaling_characteristics</span><span class="p">(</span><span class="n">benchmark</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test how performance scales with batch size.&quot;&quot;&quot;</span>
    <span class="n">transactions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s1">&#39;amount&#39;</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;merchant&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Store </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;customer_id&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="n">stats</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">process_batch</span><span class="p">,</span> <span class="n">transactions</span><span class="p">)</span>

    <span class="c1"># Calculate per-item time</span>
    <span class="n">per_item_ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>

    <span class="c1"># Per-item time should remain relatively constant (within 50%)</span>
    <span class="n">expected_per_item</span> <span class="o">=</span> <span class="mi">72</span>  <span class="c1"># ms, from single transaction benchmarks</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">per_item_ms</span> <span class="o">/</span> <span class="n">expected_per_item</span>

    <span class="k">assert</span> <span class="mf">0.5</span> <span class="o">&lt;=</span> <span class="n">ratio</span> <span class="o">&lt;=</span> <span class="mf">1.5</span><span class="p">,</span> \
        <span class="sa">f</span><span class="s2">&quot;Per-item time </span><span class="si">{</span><span class="n">per_item_ms</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms deviates significantly from expected </span><span class="si">{</span><span class="n">expected_per_item</span><span class="si">}</span><span class="s2">ms&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># performance_budgets.yml - Performance requirements</span>
<span class="nt">budgets</span><span class="p">:</span>
<span class="w">  </span><span class="nt">single_transaction</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_mean</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">100</span><span class="w">  </span><span class="c1"># milliseconds</span>
<span class="w">    </span><span class="nt">max_stddev</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Single</span><span class="nv"> </span><span class="s">transaction</span><span class="nv"> </span><span class="s">processing</span><span class="nv"> </span><span class="s">time&quot;</span>

<span class="w">  </span><span class="nt">batch_100</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_mean</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10000</span><span class="w">  </span><span class="c1"># milliseconds (10 seconds)</span>
<span class="w">    </span><span class="nt">min_throughput</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w">  </span><span class="c1"># transactions per second</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Batch</span><span class="nv"> </span><span class="s">of</span><span class="nv"> </span><span class="s">100</span><span class="nv"> </span><span class="s">transactions&quot;</span>

<span class="w">  </span><span class="nt">cache_speedup</span><span class="p">:</span>
<span class="w">    </span><span class="nt">min_ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w">  </span><span class="c1"># times faster</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Cache</span><span class="nv"> </span><span class="s">effectiveness</span><span class="nv"> </span><span class="s">vs</span><span class="nv"> </span><span class="s">uncached&quot;</span>

<span class="w">  </span><span class="nt">memory_single</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_kb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span><span class="w">  </span><span class="c1"># 1 MB</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Memory</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">single</span><span class="nv"> </span><span class="s">transaction&quot;</span>

<span class="w">  </span><span class="nt">memory_batch_100</span><span class="p">:</span>
<span class="w">    </span><span class="nt">max_kb</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5120</span><span class="w">  </span><span class="c1"># 5 MB</span>
<span class="w">    </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Memory</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">batch</span><span class="nv"> </span><span class="s">of</span><span class="nv"> </span><span class="s">100&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/performance.yml - Complete CI/CD workflow</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Performance Testing</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">develop</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="w"> </span><span class="nv">main</span><span class="w"> </span><span class="p p-Indicator">]</span>
<span class="w">  </span><span class="nt">schedule</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">cron</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;0</span><span class="nv"> </span><span class="s">2</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*&#39;</span><span class="w">  </span><span class="c1"># Nightly at 2 AM</span>
<span class="w">  </span><span class="nt">workflow_dispatch</span><span class="p">:</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">quick-checks</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Quick Performance Checks</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;pull_request&#39;</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pip install pytest pytest-benchmark pyyaml</span>
<span class="w">        </span><span class="no">pip install -r requirements.txt</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run performance requirements</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_performance_suite.py \</span>
<span class="w">          </span><span class="no">-v \</span>
<span class="w">          </span><span class="no">-k &quot;not benchmark and not slow&quot; \</span>
<span class="w">          </span><span class="no">--tb=short</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload results</span>
<span class="w">      </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">always()</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">quick-check-results</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">.pytest_cache/</span>
<span class="w">          </span><span class="no">test-results/</span>

<span class="w">  </span><span class="nt">full-benchmarks</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Full Benchmark Suite</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;push&#39; || github.event_name == &#39;schedule&#39;</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pip install pytest pytest-benchmark pyyaml</span>
<span class="w">        </span><span class="no">pip install -r requirements.txt</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Download baseline</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/download-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-baseline</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">.benchmarks</span>
<span class="w">      </span><span class="nt">continue-on-error</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run benchmarks</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_performance_suite.py \</span>
<span class="w">          </span><span class="no">--benchmark-only \</span>
<span class="w">          </span><span class="no">--benchmark-json=benchmark_results.json \</span>
<span class="w">          </span><span class="no">--benchmark-compare=.benchmarks/baseline.json \</span>
<span class="w">          </span><span class="no">--benchmark-compare-fail=mean:10%</span>
<span class="w">      </span><span class="nt">continue-on-error</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Generate report</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">python scripts/generate_performance_report.py \</span>
<span class="w">          </span><span class="no">benchmark_results.json \</span>
<span class="w">          </span><span class="no">performance_report.md</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload benchmark results</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-results</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark_results.json</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload performance report</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">performance-report</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">performance_report.md</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Save as baseline (main branch only)</span>
<span class="w">      </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.ref == &#39;refs/heads/main&#39;</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark-baseline</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">benchmark_results.json</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Comment on PR</span>
<span class="w">      </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;pull_request&#39;</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/github-script@v6</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">script</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">const fs = require(&#39;fs&#39;);</span>
<span class="w">          </span><span class="no">const report = fs.readFileSync(&#39;performance_report.md&#39;, &#39;utf8&#39;);</span>
<span class="w">          </span><span class="no">github.rest.issues.createComment({</span>
<span class="w">            </span><span class="no">issue_number: context.issue.number,</span>
<span class="w">            </span><span class="no">owner: context.repo.owner,</span>
<span class="w">            </span><span class="no">repo: context.repo.repo,</span>
<span class="w">            </span><span class="no">body: report</span>
<span class="w">          </span><span class="no">});</span>

<span class="w">  </span><span class="nt">memory-profiling</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Memory Profiling</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;schedule&#39; || github.event_name == &#39;workflow_dispatch&#39;</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pip install pytest memory-profiler</span>
<span class="w">        </span><span class="no">pip install -r requirements.txt</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run memory tests</span>
<span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">        </span><span class="no">pytest test_performance_suite.py \</span>
<span class="w">          </span><span class="no">-v \</span>
<span class="w">          </span><span class="no">-k &quot;memory&quot; \</span>
<span class="w">          </span><span class="no">-s</span>

<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload memory results</span>
<span class="w">      </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">      </span><span class="nt">with</span><span class="p">:</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">memory-results</span>
<span class="w">        </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">.pytest_cache/</span>
<span class="w">          </span><span class="no">memory_profile_*.txt</span>
</code></pre></div>

<h2 id="running-the-complete-suite-locally">Running the Complete Suite Locally</h2>
<h3 id="quick-performance-check-1-minute">Quick Performance Check (&lt; 1 minute)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run only performance requirement tests</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span>-v<span class="w"> </span>-k<span class="w"> </span><span class="s2">&quot;not benchmark and not slow&quot;</span>
</code></pre></div>

<h3 id="full-benchmark-suite-5-10-minutes">Full Benchmark Suite (5-10 minutes)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run all benchmarks</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span>--benchmark-only

<span class="c1"># Compare to baseline</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--benchmark-only<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--benchmark-compare<span class="o">=</span>baseline<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--benchmark-compare-fail<span class="o">=</span>mean:10%

<span class="c1"># Save new baseline</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--benchmark-only<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--benchmark-save<span class="o">=</span>baseline
</code></pre></div>

<h3 id="memory-profiling-2-5-minutes">Memory Profiling (2-5 minutes)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run memory tests with output</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span>-v<span class="w"> </span>-k<span class="w"> </span><span class="s2">&quot;memory&quot;</span><span class="w"> </span>-s

<span class="c1"># Run with detailed memory profiling</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span>-v<span class="w"> </span>-k<span class="w"> </span><span class="s2">&quot;memory&quot;</span><span class="w"> </span>--memprof
</code></pre></div>

<h3 id="scaling-analysis-10-30-minutes">Scaling Analysis (10-30 minutes)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run scaling tests</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span>-v<span class="w"> </span>-m<span class="w"> </span>slow

<span class="c1"># Run with specific batch sizes</span>
pytest<span class="w"> </span>test_performance_suite.py<span class="w"> </span>-v<span class="w"> </span>-k<span class="w"> </span><span class="s2">&quot;scaling&quot;</span>
</code></pre></div>

<h2 id="decision-framework-which-tests-to-run-when">Decision Framework: Which Tests to Run When</h2>
<table>
<thead>
<tr>
<th>Context</th>
<th>Tests to Run</th>
<th>Frequency</th>
<th>Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td>Local development</td>
<td>Performance requirements</td>
<td>Before commit</td>
<td>&lt; 1 min</td>
</tr>
<tr>
<td>Pull request</td>
<td>Quick checks</td>
<td>Automatic</td>
<td>&lt; 1 min</td>
</tr>
<tr>
<td>Merge to main</td>
<td>Full benchmarks</td>
<td>Automatic</td>
<td>5-10 min</td>
</tr>
<tr>
<td>Nightly build</td>
<td>Complete suite + memory</td>
<td>Scheduled</td>
<td>15-30 min</td>
</tr>
<tr>
<td>Performance work</td>
<td>Benchmarks + profiling</td>
<td>On-demand</td>
<td>10-20 min</td>
</tr>
<tr>
<td>Release candidate</td>
<td>Complete suite + scaling</td>
<td>Manual</td>
<td>30-60 min</td>
</tr>
</tbody>
</table>
<h2 id="lessons-learned">Lessons Learned</h2>
<h3 id="1-start-simple-add-complexity-gradually">1. Start Simple, Add Complexity Gradually</h3>
<p>We began with basic timing and progressively added:
- Statistical benchmarking
- Memory profiling
- CI/CD integration
- Performance budgets</p>
<h3 id="2-different-tests-for-different-purposes">2. Different Tests for Different Purposes</h3>
<ul>
<li><strong>Requirements tests</strong>: Fast, run always, gate quality</li>
<li><strong>Benchmarks</strong>: Detailed, run periodically, track trends</li>
<li><strong>Memory tests</strong>: Specialized, run on-demand, catch leaks</li>
<li><strong>Scaling tests</strong>: Expensive, run rarely, validate architecture</li>
</ul>
<h3 id="3-performance-testing-is-a-balance">3. Performance Testing Is a Balance</h3>
<p><strong>What to optimize for</strong>:
- Fast feedback (quick tests)
- Comprehensive coverage (full suite)
- Statistical rigor (benchmarks)
- Actionable results (clear failures)</p>
<p><strong>What to sacrifice</strong>:
- Perfect accuracy (accept some variance)
- Complete coverage (focus on critical paths)
- Continuous monitoring (periodic is often enough)</p>
<h3 id="4-automation-is-essential">4. Automation Is Essential</h3>
<p>Manual performance testing is:
- Inconsistent (different environments)
- Infrequent (only when remembered)
- Subjective (no clear criteria)</p>
<p>Automated performance testing provides:
- Consistency (same environment)
- Continuous (every commit)
- Objective (clear pass/fail)</p>
<h3 id="5-performance-budgets-drive-behavior">5. Performance Budgets Drive Behavior</h3>
<p>Without budgets:
- "Is this fast enough?" (subjective)
- Performance degrades gradually
- No clear accountability</p>
<p>With budgets:
- "Does this meet the budget?" (objective)
- Regressions caught immediately
- Clear performance requirements</p>
<h2 id="where-to-go-from-here">Where to Go From Here</h2>
<h3 id="advanced-topics-not-covered">Advanced Topics Not Covered</h3>
<ol>
<li><strong>Distributed performance testing</strong>: Testing across multiple machines</li>
<li><strong>Load testing</strong>: Simulating many concurrent users</li>
<li><strong>Stress testing</strong>: Finding breaking points</li>
<li><strong>Endurance testing</strong>: Long-running stability tests</li>
<li><strong>Real-user monitoring</strong>: Production performance tracking</li>
</ol>
<h3 id="recommended-tools">Recommended Tools</h3>
<ul>
<li><strong>locust</strong>: Load testing framework</li>
<li><strong>pytest-xdist</strong>: Parallel test execution</li>
<li><strong>py-spy</strong>: Low-overhead profiler</li>
<li><strong>scalene</strong>: CPU + memory profiler</li>
<li><strong>Grafana</strong>: Performance metrics visualization</li>
</ul>
<h3 id="further-reading">Further Reading</h3>
<ul>
<li>"The Art of Performance Testing" by Scott Barber</li>
<li>"Systems Performance" by Brendan Gregg</li>
<li>pytest-benchmark documentation</li>
<li>Python profiling documentation</li>
</ul>
<h2 id="final-checklist-production-ready-performance-testing">Final Checklist: Production-Ready Performance Testing</h2>
<ul>
<li>[ ] Performance budgets defined and documented</li>
<li>[ ] Performance requirement tests in place</li>
<li>[ ] Benchmark suite established</li>
<li>[ ] Memory profiling configured</li>
<li>[ ] CI/CD integration complete</li>
<li>[ ] Baseline benchmarks saved</li>
<li>[ ] Performance reports automated</li>
<li>[ ] Team trained on performance testing</li>
<li>[ ] Performance regression alerts configured</li>
<li>[ ] Documentation updated</li>
</ul>
<p><strong>Congratulations!</strong> You now have a comprehensive, production-ready performance testing system that catches regressions early, provides objective metrics, and ensures performance remains a first-class concern throughout your development process.</p>
        </div>
        <div class="footer">
            Generated on 2025-12-03 10:37:11 | Made with ‚ù§Ô∏è by GitHub Pages Generator
        </div>
    </div>
    <script>
        // Syntax highlighting for code blocks
        document.addEventListener('DOMContentLoaded', (event) => {
            // Highlight code blocks
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightElement(block);
            });
            
            // Add copy buttons to code blocks
            document.querySelectorAll('pre').forEach((pre) => {
                const button = document.createElement('button');
                button.className = 'copy-btn';
                button.textContent = 'Copy';
                
                button.addEventListener('click', () => {
                    const code = pre.querySelector('code').textContent;
                    navigator.clipboard.writeText(code).then(() => {
                        button.textContent = 'Copied!';
                        button.classList.add('copied');
                        setTimeout(() => {
                            button.textContent = 'Copy';
                            button.classList.remove('copied');
                        }, 2000);
                    }).catch(err => {
                        console.error('Failed to copy:', err);
                        button.textContent = 'Error';
                        setTimeout(() => {
                            button.textContent = 'Copy';
                        }, 2000);
                    });
                });
                
                pre.appendChild(button);
            });
        });
    </script>
</body>
</html>