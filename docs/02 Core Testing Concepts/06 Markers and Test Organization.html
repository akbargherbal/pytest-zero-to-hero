<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>06 Markers and Test Organization</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --secondary: #8b5cf6;
            --bg-main: #0f172a;
            --bg-card: #1e293b;
            --bg-code: #0f172a;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --border: #334155;
            --accent: #06b6d4;
            --success: #10b981;
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body { 
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.7; 
            color: var(--text-primary); 
            background: var(--bg-main);
        }
        
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px; 
        }
        
        .home-btn { 
            position: fixed; 
            top: 20px; 
            right: 20px; 
            background: var(--accent);
            color: white; 
            width: 50px;
            height: 50px;
            border-radius: 50%;
            text-decoration: none; 
            z-index: 1000;
            box-shadow: 0 4px 20px rgba(6, 182, 212, 0.4);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            font-size: 24px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .home-btn:hover { 
            background: #0891b2;
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(6, 182, 212, 0.5);
        }
        
        .breadcrumb { 
            background: var(--bg-card);
            padding: 12px 0; 
            margin-bottom: 24px; 
            font-size: 14px;
            border-radius: 8px;
            border: 1px solid var(--border);
        }
        
        .breadcrumb a { 
            color: var(--accent);
            text-decoration: none;
            transition: color 0.2s;
        }
        
        .breadcrumb a:hover { 
            color: var(--primary);
            text-decoration: underline;
        }
        
        .content { 
            background: var(--bg-card);
            padding: 3rem; 
            border-radius: 16px; 
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            border: 1px solid var(--border);
        }
        
        .file-list { 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); 
            gap: 1.5rem; 
            margin: 2rem 0; 
        }
        
        .file-item { 
            padding: 1.5rem; 
            border: 1px solid var(--border);
            border-radius: 12px; 
            background: var(--bg-main);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }
        
        .file-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, var(--primary), var(--secondary));
            opacity: 0;
            transition: opacity 0.3s;
        }
        
        .file-item:hover { 
            transform: translateY(-4px); 
            box-shadow: 0 8px 30px rgba(99, 102, 241, 0.3);
            border-color: var(--primary);
        }
        
        .file-item:hover::before {
            opacity: 1;
        }
        
        .file-item a { 
            color: var(--text-primary);
            text-decoration: none; 
            font-weight: 600; 
            display: block;
            font-size: 1.1rem;
        }
        
        .file-item a:hover { 
            color: var(--primary);
        }
        
        .file-type { 
            font-size: 13px; 
            color: var(--text-secondary);
            margin-top: 8px; 
            font-weight: 500;
        }
        
        /* Code Blocks */
        pre { 
            background: var(--bg-code);
            padding: 1.5rem; 
            border-radius: 12px; 
            overflow-x: auto;
            border: 1px solid var(--border);
            margin: 1.5rem 0;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
            position: relative;
        }
        
        pre code { 
            background: none;
            padding: 0;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        /* Copy Button */
        .copy-btn {
            position: absolute;
            top: 8px;
            right: 8px;
            background: var(--primary);
            color: white;
            border: none;
            padding: 6px 12px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 12px;
            font-weight: 600;
            transition: all 0.2s;
            opacity: 0.7;
            z-index: 10;
        }
        
        .copy-btn:hover {
            opacity: 1;
            background: var(--primary-dark);
            transform: translateY(-1px);
        }
        
        .copy-btn.copied {
            background: var(--success);
        }
        
        pre:hover .copy-btn {
            opacity: 1;
        }
        
        /* Inline Code */
        code { 
            background: var(--bg-code);
            color: #8b5cf6;
            padding: 3px 8px; 
            border-radius: 6px; 
            font-size: 1.1em;
            font-family: 'Fira Code', 'Consolas', monospace;
            border: 1px solid var(--border);
        }
        
        /* Headings */
        h1, h2, h3, h4, h5, h6 { 
            color: var(--text-primary);
            margin: 2rem 0 1rem 0;
            font-weight: 700;
            letter-spacing: -0.5px;
        }
        
        h1 { 
            font-size: 2.5rem;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text;
            border-bottom: 3px solid var(--primary);
            padding-bottom: 12px;
            margin-bottom: 1.5rem;
        }
        
        h2 { 
            font-size: 2rem;
            color: var(--primary);
            border-bottom: 2px solid var(--border);
            padding-bottom: 8px;
        }
        
        h3 { 
            font-size: 1.5rem;
            color: var(--accent);
        }
        
        /* Links */
        a { 
            color: var(--accent);
            transition: color 0.2s;
        }
        
        a:hover { 
            color: var(--primary);
        }
        
        /* Paragraphs */
        p {
            margin: 1rem 0;
            color: var(--text-secondary);
        }
        
        /* Lists */
        ul, ol {
            margin: 1rem 0;
            padding-left: 2rem;
            color: var(--text-secondary);
        }
        
        li {
            margin: 0.5rem 0;
        }
        
        /* Tables */
        table { 
            border-collapse: collapse;
            width: 100%;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        }
        
        th, td { 
            border: 1px solid var(--border);
            padding: 12px 16px;
            text-align: left;
        }
        
        th { 
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            font-weight: 600;
        }
        
        tr:hover {
            background: var(--bg-card);
        }
        
        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--primary);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 0 8px 8px 0;
            color: var(--text-secondary);
            font-style: italic;
        }
        
        /* Horizontal Rule */
        hr {
            border: none;
            border-top: 2px solid var(--border);
            margin: 2rem 0;
        }
        
        .footer { 
            text-align: center; 
            padding: 2rem; 
            color: var(--text-secondary);
            border-top: 1px solid var(--border);
            margin-top: 3rem; 
            font-size: 14px;
        }
        
        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 12px;
            height: 12px;
        }
        
        ::-webkit-scrollbar-track {
            background: var(--bg-main);
        }
        
        ::-webkit-scrollbar-thumb {
            background: var(--border);
            border-radius: 6px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: var(--primary);
        }
        
        @media (max-width: 768px) {
            .container { padding: 10px; }
            .file-list { grid-template-columns: 1fr; }
            .content { padding: 1.5rem; }
            h1 { font-size: 2rem; }
            h2 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>
    <a href="../index.html" class="home-btn">üè†</a>
    <div class="container">
        <div class="breadcrumb">
            <div style="padding: 0 20px;">
                <a href="../index.html">üè† Home</a> <span style="color: #64748b;">/</span> <a href="index.html">02 Core Testing Concepts</a>
            </div>
        </div>
        <div class="content">
            <h1 id="chapter-6-markers-and-test-organization">Chapter 6: Markers and Test Organization</h1>
<h2 id="what-are-markers">What Are Markers?</h2>
<h2 id="the-problem-tests-that-need-different-treatment">The Problem: Tests That Need Different Treatment</h2>
<p>You're building a payment processing system. Your test suite includes:</p>
<ul>
<li>Fast unit tests that run in milliseconds</li>
<li>Slow integration tests that hit a test database</li>
<li>Tests that require specific environment variables</li>
<li>Tests that only work on certain operating systems</li>
<li>Tests for experimental features that aren't ready yet</li>
</ul>
<p>Right now, every time you run <code>pytest</code>, all tests execute. The slow database tests make your feedback loop painful during development. You want to run only the fast tests while coding, but run everything before committing.</p>
<p><strong>The naive approach</strong>: Create separate test files for each category. But this fragments your test organization and makes it hard to find related tests.</p>
<p><strong>What you need</strong>: A way to tag tests with metadata and selectively run subsets based on those tags.</p>
<p>This is exactly what pytest markers solve.</p>
<h2 id="what-markers-are">What Markers Are</h2>
<p>A <strong>marker</strong> is metadata you attach to a test function. It's like putting a sticky note on a test that says "this test is slow" or "skip this test on Windows" or "this test requires authentication."</p>
<p>Markers don't change what your test does‚Äîthey change how pytest treats it.</p>
<h3 id="the-simplest-marker">The Simplest Marker</h3>
<p>Let's start with a concrete example. Here's a payment processing test suite:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>

<span class="k">def</span><span class="w"> </span><span class="nf">validate_credit_card</span><span class="p">(</span><span class="n">card_number</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validate credit card using Luhn algorithm.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">card_number</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="n">digits</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">card_number</span><span class="p">]</span>
    <span class="n">checksum</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">digit</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">digits</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">digit</span> <span class="o">*=</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">digit</span> <span class="o">&gt;</span> <span class="mi">9</span><span class="p">:</span>
                <span class="n">digit</span> <span class="o">-=</span> <span class="mi">9</span>
        <span class="n">checksum</span> <span class="o">+=</span> <span class="n">digit</span>

    <span class="k">return</span> <span class="n">checksum</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">process_payment</span><span class="p">(</span><span class="n">amount</span><span class="p">,</span> <span class="n">card_number</span><span class="p">,</span> <span class="n">database_connection</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process payment through payment gateway and record in database.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">card_number</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid credit card number&quot;</span><span class="p">)</span>

    <span class="c1"># Simulate payment gateway call (slow)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Record transaction in database (slow)</span>
    <span class="n">database_connection</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="s2">&quot;INSERT INTO transactions (amount, card_number) VALUES (?, ?)&quot;</span><span class="p">,</span>
        <span class="p">(</span><span class="n">amount</span><span class="p">,</span> <span class="n">card_number</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;success&quot;</span><span class="p">,</span> <span class="s2">&quot;amount&quot;</span><span class="p">:</span> <span class="n">amount</span><span class="p">}</span>

<span class="c1"># Tests</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_accepts_valid_number</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast unit test - runs in milliseconds.&quot;&quot;&quot;</span>
    <span class="n">valid_card</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>  <span class="c1"># Valid test card</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">valid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_rejects_invalid_number</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast unit test - runs in milliseconds.&quot;&quot;&quot;</span>
    <span class="n">invalid_card</span> <span class="o">=</span> <span class="s2">&quot;1234567890123456&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">invalid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_with_valid_card</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Slow integration test - takes 2+ seconds.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database_connection</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
</code></pre></div>

<p>When you run this test suite, you wait over 2 seconds every time, even though the validation tests are instant. During development, you want to run only the fast tests.</p>
<p><strong>Without markers</strong>, you'd need to:
- Put tests in separate files
- Remember which files contain which types of tests
- Manually specify file paths every time</p>
<p><strong>With markers</strong>, you tag the slow test and filter by that tag.</p>
<h3 id="applying-your-first-marker">Applying Your First Marker</h3>
<p>Here's the same test suite with a marker applied:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="c1"># ... (same validate_credit_card and process_payment functions) ...</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_accepts_valid_number</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast unit test - runs in milliseconds.&quot;&quot;&quot;</span>
    <span class="n">valid_card</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">valid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_rejects_invalid_number</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast unit test - runs in milliseconds.&quot;&quot;&quot;</span>
    <span class="n">invalid_card</span> <span class="o">=</span> <span class="s2">&quot;1234567890123456&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">invalid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_with_valid_card</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Slow integration test - takes 2+ seconds.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database_connection</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
</code></pre></div>

<p><strong>What changed</strong>: We added <code>@pytest.mark.slow</code> above the slow test.</p>
<p>This is a <strong>decorator</strong>‚Äîa Python feature that modifies function behavior. The <code>@pytest.mark.slow</code> decorator attaches metadata to the test function without changing what the test does.</p>
<h3 id="running-tests-selectively">Running Tests Selectively</h3>
<p>Now you can control which tests run:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run only fast tests (skip tests marked as slow)</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not slow&quot;</span>

<span class="c1"># Run only slow tests</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;slow&quot;</span>

<span class="c1"># Run all tests (default behavior)</span>
pytest
</code></pre></div>

<p><strong>Output when running fast tests only</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not slow&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">3</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">1</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">2</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid_number<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">1</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.02s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Key observations</strong>:</p>
<ol>
<li><strong>"3 items / 1 deselected / 2 selected"</strong>: Pytest found 3 tests total, deselected 1 (the slow one), and ran 2</li>
<li><strong>Execution time</strong>: 0.02 seconds instead of 2+ seconds</li>
<li><strong>The marker didn't change the test</strong>: It only changed whether pytest ran it</li>
</ol>
<h3 id="the-anatomy-of-a-marker">The Anatomy of a Marker</h3>
<p>Let's break down the syntax:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_with_valid_card</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="c1"># test code</span>
</code></pre></div>

<p><strong>Components</strong>:</p>
<ul>
<li><code>@</code>: Python decorator syntax</li>
<li><code>pytest.mark</code>: The marker namespace (all pytest markers start here)</li>
<li><code>.slow</code>: The marker name (you choose this)</li>
<li>Applied to: The function immediately below it</li>
</ul>
<p><strong>The marker name can be anything</strong>: <code>@pytest.mark.slow</code>, <code>@pytest.mark.integration</code>, <code>@pytest.mark.requires_database</code>, <code>@pytest.mark.wip</code> (work in progress). You define the vocabulary that makes sense for your project.</p>
<h2 id="how-markers-work-under-the-hood">How Markers Work Under the Hood</h2>
<p>When pytest collects tests, it builds a list of test items. Each item has:</p>
<ul>
<li>The test function itself</li>
<li>Metadata about the test (name, location, etc.)</li>
<li><strong>Markers attached to it</strong></li>
</ul>
<p>When you run <code>pytest -m "not slow"</code>, pytest:</p>
<ol>
<li>Collects all tests</li>
<li>Checks each test's markers</li>
<li>Evaluates the expression <code>"not slow"</code> against each test's markers</li>
<li>Runs only tests where the expression is True</li>
</ol>
<p><strong>The marker is stored as metadata</strong>. You can inspect it programmatically:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py or any test file</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_inspect_markers</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate that markers are accessible metadata.&quot;&quot;&quot;</span>
    <span class="c1"># Get the current test&#39;s markers</span>
    <span class="n">test_item</span> <span class="o">=</span> <span class="n">pytest</span><span class="o">.</span><span class="n">current_test_item</span>  <span class="c1"># (This is conceptual - actual access differs)</span>

    <span class="c1"># In reality, markers are accessed during test collection</span>
    <span class="c1"># This example shows the concept, not the exact API</span>
</code></pre></div>

<p><strong>Why this matters</strong>: Markers are not magic. They're structured metadata that pytest's collection and execution engine uses to make decisions. Understanding this helps you reason about more complex marker scenarios.</p>
<h2 id="markers-vs-other-organizational-tools">Markers vs. Other Organizational Tools</h2>
<p>You might wonder: "Why not just use separate test files or test classes?"</p>
<p><strong>Comparison</strong>:</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>Flexibility</th>
<th>Discoverability</th>
<th>Maintenance</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Separate files</strong></td>
<td>Low - tests are physically separated</td>
<td>Medium - must know file structure</td>
<td>High - moving tests requires file changes</td>
</tr>
<tr>
<td><strong>Test classes</strong></td>
<td>Medium - tests grouped but in same file</td>
<td>High - clear hierarchy</td>
<td>Medium - refactoring changes class structure</td>
</tr>
<tr>
<td><strong>Markers</strong></td>
<td>High - same test can have multiple tags</td>
<td>High - markers visible in test code</td>
<td>Low - just add/remove decorators</td>
</tr>
</tbody>
</table>
<p><strong>When to use markers</strong>:</p>
<ul>
<li>Tests need multiple categorizations (e.g., both "slow" and "requires_auth")</li>
<li>You want to run different subsets in different contexts (CI vs. local development)</li>
<li>Test organization is orthogonal to code organization (e.g., integration tests for multiple modules)</li>
</ul>
<p><strong>When to use files/classes instead</strong>:</p>
<ul>
<li>Tests naturally group by module or feature</li>
<li>You never need to run cross-cutting subsets</li>
<li>Physical separation aids understanding</li>
</ul>
<p><strong>Best practice</strong>: Use both. Organize tests into logical files and classes, then use markers for cross-cutting concerns like speed, dependencies, or stability.</p>
<h2 id="what-youve-learned">What You've Learned</h2>
<p>Markers are metadata tags you attach to tests using the <code>@pytest.mark.name</code> decorator syntax. They don't change what tests do‚Äîthey change how pytest treats them.</p>
<p><strong>Core concepts</strong>:</p>
<ol>
<li>Markers are applied with <code>@pytest.mark.marker_name</code></li>
<li>Tests are filtered with <code>pytest -m "expression"</code></li>
<li>Markers are metadata stored on test items</li>
<li>Multiple markers can be applied to the same test</li>
<li>Markers complement (don't replace) file and class organization</li>
</ol>
<p><strong>What's next</strong>: We've used a custom marker (<code>slow</code>) without any special setup. Pytest allowed this, but issued a warning. In the next sections, we'll explore:</p>
<ul>
<li>Built-in markers that pytest provides</li>
<li>How to properly register custom markers</li>
<li>Advanced marker expressions for complex filtering</li>
<li>Organizing entire test suites with marker strategies</li>
</ul>
<h2 id="built-in-markers-skip-xfail-filterwarnings">Built-in Markers (skip, xfail, filterwarnings)</h2>
<h2 id="the-problem-tests-that-cant-always-run">The Problem: Tests That Can't Always Run</h2>
<p>Your payment processor now has tests that:</p>
<ol>
<li><strong>Require specific platforms</strong>: Payment gateway integration only works on Linux servers</li>
<li><strong>Are known to fail</strong>: A bug in the external API causes intermittent failures</li>
<li><strong>Generate annoying warnings</strong>: Deprecated library functions that you can't fix yet</li>
</ol>
<p>Running these tests creates noise:</p>
<ul>
<li>Platform-specific tests fail on developer machines (Windows/Mac)</li>
<li>Known failures make it hard to spot new failures</li>
<li>Warning spam obscures real issues</li>
</ul>
<p><strong>What you need</strong>: Built-in markers that handle these common scenarios with well-defined behavior.</p>
<h2 id="built-in-markers-pytests-standard-vocabulary">Built-in Markers: Pytest's Standard Vocabulary</h2>
<p>Pytest provides several markers out of the box. These markers have special meaning to pytest's execution engine‚Äîthey're not just metadata, they trigger specific behaviors.</p>
<h3 id="the-three-most-important-built-in-markers">The Three Most Important Built-in Markers</h3>
<ol>
<li><strong><code>@pytest.mark.skip</code></strong>: Don't run this test at all</li>
<li><strong><code>@pytest.mark.skipif</code></strong>: Skip this test if a condition is true</li>
<li><strong><code>@pytest.mark.xfail</code></strong>: Run this test, but expect it to fail</li>
</ol>
<p>Let's see each one in action with our payment processor.</p>
<h2 id="iteration-1-unconditional-skip-with-pytestmarkskip">Iteration 1: Unconditional Skip with @pytest.mark.skip</h2>
<h3 id="the-scenario">The Scenario</h3>
<p>You're developing a new feature: cryptocurrency payment support. The implementation isn't ready, but you've written tests for it. You want these tests in version control, but they shouldn't run yet.</p>
<p><strong>First attempt</strong>: Comment out the tests.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>

<span class="c1"># def test_process_bitcoin_payment():</span>
<span class="c1">#     &quot;&quot;&quot;Test bitcoin payment processing.&quot;&quot;&quot;</span>
<span class="c1">#     result = process_payment(</span>
<span class="c1">#         amount=100.00,</span>
<span class="c1">#         payment_method=&quot;bitcoin&quot;,</span>
<span class="c1">#         wallet_address=&quot;1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa&quot;</span>
<span class="c1">#     )</span>
<span class="c1">#     assert result[&quot;status&quot;] == &quot;success&quot;</span>
</code></pre></div>

<p><strong>Problems with this approach</strong>:</p>
<ul>
<li>Test is invisible to pytest (won't show in <code>--collect-only</code>)</li>
<li>Easy to forget about commented tests</li>
<li>No documentation of why it's disabled</li>
<li>Can't track skipped tests in reports</li>
</ul>
<h3 id="the-solution-pytestmarkskip">The Solution: @pytest.mark.skip</h3>
<p>Mark the test as skipped with a reason:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Bitcoin payment not implemented yet&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_bitcoin_payment</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test bitcoin payment processing.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">payment_method</span><span class="o">=</span><span class="s2">&quot;bitcoin&quot;</span><span class="p">,</span>
        <span class="n">wallet_address</span><span class="o">=</span><span class="s2">&quot;1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa&quot;</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
</code></pre></div>

<p><strong>Run the test suite</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">4</span><span class="w"> </span>items

test_payment_processor.py::test_validate_credit_card_accepts_valid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment_with_valid_card<span class="w"> </span>PASSED
test_payment_processor.py::test_process_bitcoin_payment<span class="w"> </span>SKIPPED<span class="w"> </span><span class="o">(</span>Bitcoin<span class="w"> </span>payment<span class="w"> </span>not<span class="w"> </span>implemented<span class="w"> </span>yet<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">3</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">1</span><span class="w"> </span>skipped<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.03s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li>Pytest collected the test (it's not invisible)</li>
<li>Pytest didn't run the test code</li>
<li>The test shows as <code>SKIPPED</code> with your reason</li>
<li>The summary shows <code>1 skipped</code></li>
</ol>
<p><strong>Key insight</strong>: The test function body never executes. Pytest sees the <code>@pytest.mark.skip</code> decorator and immediately marks the test as skipped during collection.</p>
<h3 id="when-to-use-unconditional-skip">When to Use Unconditional Skip</h3>
<p>Use <code>@pytest.mark.skip</code> when:</p>
<ul>
<li>Feature not implemented yet (like our bitcoin example)</li>
<li>Test is temporarily broken and you need to commit</li>
<li>Test requires manual setup that's not automated</li>
</ul>
<p><strong>Don't use it for</strong>:</p>
<ul>
<li>Platform-specific tests (use <code>skipif</code> instead)</li>
<li>Tests that should fail (use <code>xfail</code> instead)</li>
<li>Tests you'll never fix (delete them instead)</li>
</ul>
<h2 id="iteration-2-conditional-skip-with-pytestmarkskipif">Iteration 2: Conditional Skip with @pytest.mark.skipif</h2>
<h3 id="the-scenario_1">The Scenario</h3>
<p>Your payment gateway integration requires Linux because it uses Linux-specific system calls. On Windows and Mac, the test should skip automatically.</p>
<p><strong>First attempt</strong>: Manual platform check inside the test.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_integration</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test integration with payment gateway (Linux only).&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">!=</span> <span class="s2">&quot;linux&quot;</span><span class="p">:</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="s2">&quot;Payment gateway only available on Linux&quot;</span><span class="p">)</span>

    <span class="c1"># Test code here</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment_via_gateway</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;gateway_response&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;approved&quot;</span>
</code></pre></div>

<p><strong>Problems</strong>:</p>
<ul>
<li>Test function executes partially (runs the if statement)</li>
<li>Skip logic is inside the test (not visible in test list)</li>
<li>Every platform-specific test needs this boilerplate</li>
</ul>
<h3 id="the-solution-pytestmarkskipif">The Solution: @pytest.mark.skipif</h3>
<p>Move the condition to the decorator:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">!=</span> <span class="s2">&quot;linux&quot;</span><span class="p">,</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Payment gateway only available on Linux&quot;</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_integration</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test integration with payment gateway (Linux only).&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment_via_gateway</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;gateway_response&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;approved&quot;</span>
</code></pre></div>

<p><strong>Run on macOS</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_payment_processor.py::test_payment_gateway_integration
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

test_payment_processor.py::test_payment_gateway_integration<span class="w"> </span>SKIPPED<span class="w"> </span><span class="o">(</span>Payment<span class="w"> </span>gateway<span class="w"> </span>only<span class="w"> </span>available<span class="w"> </span>on<span class="w"> </span>Linux<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>skipped<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.01s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Run on Linux</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_payment_processor.py::test_payment_gateway_integration
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

test_payment_processor.py::test_payment_gateway_integration<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span>.34s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What changed</strong>:</p>
<ol>
<li><strong>On macOS</strong>: Test skipped during collection (function never runs)</li>
<li><strong>On Linux</strong>: Test runs normally</li>
<li><strong>Visibility</strong>: The skip condition is visible in the test signature</li>
</ol>
<h3 id="common-skipif-conditions">Common skipif Conditions</h3>
<p>Here are real-world examples:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="c1"># Platform-specific</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;win32&quot;</span><span class="p">,</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Unix-only test&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_unix_file_permissions</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">!=</span> <span class="s2">&quot;darwin&quot;</span><span class="p">,</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;macOS-only test&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_macos_keychain_integration</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="c1"># Python version-specific</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Requires Python 3.10+ match statement&quot;</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_pattern_matching</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="c1"># Dependency-specific</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span>
    <span class="ow">not</span> <span class="n">pytest</span><span class="o">.</span><span class="n">importorskip</span><span class="p">(</span><span class="s2">&quot;requests&quot;</span><span class="p">),</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Requires requests library&quot;</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_http_client</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="c1"># Environment-specific</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span>
    <span class="s2">&quot;CI&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Only runs in CI environment&quot;</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_deployment_pipeline</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre></div>

<h3 id="reusing-skip-conditions">Reusing Skip Conditions</h3>
<p>When multiple tests share the same skip condition, define it once:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="c1"># Define the condition once</span>
<span class="n">requires_linux</span> <span class="o">=</span> <span class="n">pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">!=</span> <span class="s2">&quot;linux&quot;</span><span class="p">,</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Requires Linux&quot;</span>
<span class="p">)</span>

<span class="c1"># Apply to multiple tests</span>
<span class="nd">@requires_linux</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_integration</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="nd">@requires_linux</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_refund</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="nd">@requires_linux</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_batch_processing</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Benefits</strong>:</p>
<ul>
<li>Single source of truth for the condition</li>
<li>Easy to update if logic changes</li>
<li>Self-documenting test requirements</li>
</ul>
<h2 id="iteration-3-expected-failures-with-pytestmarkxfail">Iteration 3: Expected Failures with @pytest.mark.xfail</h2>
<h3 id="the-scenario_2">The Scenario</h3>
<p>The payment gateway API has a known bug: refunds over $10,000 fail with a 500 error. You've reported it to the vendor, but it's not fixed yet. You want to:</p>
<ol>
<li>Document the bug with a test</li>
<li>Track when it's fixed</li>
<li>Not have this failure hide other failures</li>
</ol>
<p><strong>First attempt</strong>: Skip the test.</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Gateway bug: refunds over $10k fail&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_large_refund</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test refund of large amount.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_refund</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">15000.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
</code></pre></div>

<p><strong>Problem</strong>: When the bug is fixed, you won't know. The test will stay skipped forever.</p>
<h3 id="the-solution-pytestmarkxfail">The Solution: @pytest.mark.xfail</h3>
<p>Mark the test as expected to fail:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">xfail</span><span class="p">(</span><span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Gateway bug: refunds over $10k fail with 500 error&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_large_refund</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test refund of large amount.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_refund</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">15000.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
</code></pre></div>

<p><strong>Run the test while the bug exists</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_payment_processor.py::test_large_refund
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

test_payment_processor.py::test_large_refund<span class="w"> </span>XFAIL<span class="w"> </span><span class="o">(</span>Gateway<span class="w"> </span>bug:<span class="w"> </span>refunds<span class="w"> </span>over<span class="w"> </span><span class="nv">$10</span>k<span class="w"> </span>fail<span class="w"> </span>with<span class="w"> </span><span class="m">500</span><span class="w"> </span>error<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>xfailed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.45s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li>Pytest <strong>ran the test</strong> (unlike <code>skip</code>)</li>
<li>The test <strong>failed</strong> as expected</li>
<li>Pytest marked it as <code>XFAIL</code> (expected failure)</li>
<li>The test suite still passes overall</li>
</ol>
<p><strong>Now the bug gets fixed</strong>. Run the test again:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_payment_processor.py::test_large_refund
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

test_payment_processor.py::test_large_refund<span class="w"> </span>XPASS<span class="w"> </span><span class="o">(</span>Gateway<span class="w"> </span>bug:<span class="w"> </span>refunds<span class="w"> </span>over<span class="w"> </span><span class="nv">$10</span>k<span class="w"> </span>fail<span class="w"> </span>with<span class="w"> </span><span class="m">500</span><span class="w"> </span>error<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>xpassed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.45s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Critical difference</strong>: The test shows <code>XPASS</code> (unexpectedly passed). This alerts you that:</p>
<ol>
<li>The bug is fixed</li>
<li>You can remove the <code>xfail</code> marker</li>
<li>The test should now be a regular passing test</li>
</ol>
<h3 id="xfail-vs-skip-when-to-use-each">xfail vs. skip: When to Use Each</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Use</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feature not implemented</td>
<td><code>skip</code></td>
<td>No point running the test</td>
</tr>
<tr>
<td>Known bug in your code</td>
<td><code>xfail</code></td>
<td>Track when it's fixed</td>
</tr>
<tr>
<td>Known bug in external dependency</td>
<td><code>xfail</code></td>
<td>Track when vendor fixes it</td>
</tr>
<tr>
<td>Platform not supported</td>
<td><code>skipif</code></td>
<td>Test can't run here</td>
</tr>
<tr>
<td>Flaky test being investigated</td>
<td><code>xfail</code></td>
<td>Don't block CI while debugging</td>
</tr>
</tbody>
</table>
<h3 id="xfail-with-conditions">xfail with Conditions</h3>
<p>You can combine <code>xfail</code> with conditions:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">xfail</span><span class="p">(</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;win32&quot;</span><span class="p">,</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Known issue on Windows - investigating&quot;</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_file_locking</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test file locking mechanism.&quot;&quot;&quot;</span>
    <span class="c1"># This test passes on Linux/Mac but fails on Windows</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Behavior</strong>:</p>
<ul>
<li>On Windows: Runs and expects failure (XFAIL if fails, XPASS if passes)</li>
<li>On Linux/Mac: Runs normally (PASS or FAIL)</li>
</ul>
<h3 id="strict-xfail-fail-if-test-passes">Strict xfail: Fail if Test Passes</h3>
<p>Sometimes you want to be notified immediately when an xfail test passes:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">xfail</span><span class="p">(</span>
    <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Gateway bug: refunds over $10k fail&quot;</span><span class="p">,</span>
    <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_large_refund</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test refund of large amount.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_refund</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">15000.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
</code></pre></div>

<p><strong>With <code>strict=True</code></strong>:</p>
<ul>
<li>If test fails: XFAIL (expected, test suite passes)</li>
<li>If test passes: <strong>FAILED</strong> (unexpected, test suite fails)</li>
</ul>
<p><strong>Use strict mode when</strong>: You want CI to fail if an expected failure suddenly passes, forcing you to update the test immediately.</p>
<h2 id="iteration-4-filtering-warnings-with-pytestmarkfilterwarnings">Iteration 4: Filtering Warnings with @pytest.mark.filterwarnings</h2>
<h3 id="the-scenario_3">The Scenario</h3>
<p>Your payment processor uses a library that's deprecated but still works. Every test run shows:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span><span class="nv">pytest</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items

test_payment_processor.py::test_validate_credit_card<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment<span class="w"> </span>PASSED
<span class="w">  </span>/path/to/payment_lib.py:45:<span class="w"> </span>DeprecationWarning:<span class="w"> </span>process_payment_v1<span class="w"> </span>is<span class="w"> </span>deprecated,<span class="w"> </span>use<span class="w"> </span>process_payment_v2
<span class="w">    </span>warnings.warn<span class="o">(</span><span class="s2">&quot;process_payment_v1 is deprecated, use process_payment_v2&quot;</span>,<span class="w"> </span>DeprecationWarning<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">1</span><span class="w"> </span>warning<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.05s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Problem</strong>: The warning spam makes it hard to see real issues. You can't fix it yet (migration planned for next quarter), but you want clean test output.</p>
<h3 id="the-solution-pytestmarkfilterwarnings">The Solution: @pytest.mark.filterwarnings</h3>
<p>Suppress specific warnings for specific tests:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore::DeprecationWarning&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_legacy_api</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test payment processing using legacy API.&quot;&quot;&quot;</span>
    <span class="c1"># This test uses the deprecated function</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment_v1</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_new_api</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test payment processing using new API.&quot;&quot;&quot;</span>
    <span class="c1"># This test uses the new function (no warning)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment_v2</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
</code></pre></div>

<p><strong>Run the tests</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">2</span><span class="w"> </span>items

test_payment_processor.py::test_process_payment_legacy_api<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment_new_api<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.03s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What happened</strong>: The deprecation warning from <code>test_process_payment_legacy_api</code> was suppressed. Other warnings still appear.</p>
<h3 id="warning-filter-syntax">Warning Filter Syntax</h3>
<p>The filter string follows Python's warning filter format:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Ignore all deprecation warnings</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore::DeprecationWarning&quot;</span><span class="p">)</span>

<span class="c1"># Ignore specific warning message</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore:process_payment_v1 is deprecated&quot;</span><span class="p">)</span>

<span class="c1"># Turn warnings into errors (strict mode)</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;error::DeprecationWarning&quot;</span><span class="p">)</span>

<span class="c1"># Ignore warnings from specific module</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore::DeprecationWarning:payment_lib&quot;</span><span class="p">)</span>
</code></pre></div>

<h3 id="when-to-use-filterwarnings">When to Use filterwarnings</h3>
<p><strong>Good uses</strong>:</p>
<ul>
<li>Suppress known warnings from third-party libraries you can't fix</li>
<li>Test code that intentionally triggers warnings</li>
<li>Temporarily silence warnings during migration</li>
</ul>
<p><strong>Bad uses</strong>:</p>
<ul>
<li>Hiding warnings in your own code (fix them instead)</li>
<li>Suppressing all warnings globally (you'll miss real issues)</li>
<li>Using it as a permanent solution (warnings indicate technical debt)</li>
</ul>
<h2 id="diagnostic-analysis-understanding-marker-behavior">Diagnostic Analysis: Understanding Marker Behavior</h2>
<p>Let's intentionally create scenarios to understand how markers work:</p>
<h3 id="scenario-1-what-happens-when-xfail-test-passes">Scenario 1: What Happens When xfail Test Passes?</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_marker_behavior.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">xfail</span><span class="p">(</span><span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Expected to fail&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_xfail_that_actually_passes</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This test is marked xfail but will pass.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">2</span>  <span class="c1"># This will pass</span>
</code></pre></div>

<p><strong>Run it</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_marker_behavior.py::test_xfail_that_actually_passes
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

test_marker_behavior.py::test_xfail_that_actually_passes<span class="w"> </span>XPASS<span class="w"> </span><span class="o">(</span>Expected<span class="w"> </span>to<span class="w"> </span>fail<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>xpassed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.01s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Analysis</strong>:</p>
<ol>
<li><strong>Status</strong>: <code>XPASS</code> (unexpectedly passed)</li>
<li><strong>Test suite result</strong>: Still passes (xpass doesn't fail the suite by default)</li>
<li><strong>What this tells us</strong>: xfail tests always run; the marker only changes how pytest interprets the result</li>
</ol>
<h3 id="scenario-2-combining-multiple-markers">Scenario 2: Combining Multiple Markers</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_marker_behavior.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s2">&quot;win32&quot;</span><span class="p">,</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Unix only&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_with_multiple_markers</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test with both slow and skipif markers.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="kc">True</span>
</code></pre></div>

<p><strong>Run on Windows</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_marker_behavior.py::test_with_multiple_markers
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">1</span><span class="w"> </span>item

test_marker_behavior.py::test_with_multiple_markers<span class="w"> </span>SKIPPED<span class="w"> </span><span class="o">(</span>Unix<span class="w"> </span>only<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>skipped<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.01s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Analysis</strong>:</p>
<ol>
<li><strong>Skip takes precedence</strong>: Test never runs, so the <code>slow</code> marker is irrelevant</li>
<li><strong>Marker order doesn't matter</strong>: <code>skipif</code> is evaluated during collection, before execution</li>
<li><strong>What this tells us</strong>: Markers are evaluated in a specific order (skip/skipif first, then xfail, then custom markers)</li>
</ol>
<h3 id="scenario-3-skip-inside-test-vs-skip-marker">Scenario 3: Skip Inside Test vs. Skip Marker</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_marker_behavior.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_skip_inside_function</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Skip called inside the test function.&quot;&quot;&quot;</span>
    <span class="n">pytest</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="s2">&quot;Skipping for demonstration&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">False</span>  <span class="c1"># This line never executes</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Skipping for demonstration&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_skip_with_marker</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Skip using marker.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="kc">False</span>  <span class="c1"># This line never executes</span>
</code></pre></div>

<p><strong>Run both</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v<span class="w"> </span>test_marker_behavior.py<span class="w"> </span>-k<span class="w"> </span><span class="s2">&quot;skip&quot;</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">2</span><span class="w"> </span>items

test_marker_behavior.py::test_skip_inside_function<span class="w"> </span>SKIPPED<span class="w"> </span><span class="o">(</span>Skipping<span class="w"> </span><span class="k">for</span><span class="w"> </span>demonstration<span class="o">)</span>
test_marker_behavior.py::test_skip_with_marker<span class="w"> </span>SKIPPED<span class="w"> </span><span class="o">(</span>Skipping<span class="w"> </span><span class="k">for</span><span class="w"> </span>demonstration<span class="o">)</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>skipped<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.02s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Analysis</strong>:</p>
<ol>
<li><strong>Both show as SKIPPED</strong>: Same end result</li>
<li><strong>Timing difference</strong>: Marker skip happens during collection (0ms), function skip happens during execution (after setup)</li>
<li><strong>When to use each</strong>:</li>
<li>Marker: Condition known before test runs (platform, Python version)</li>
<li>Function: Condition determined during test execution (missing file, API unavailable)</li>
</ol>
<h2 id="built-in-markers-summary">Built-in Markers Summary</h2>
<table>
<thead>
<tr>
<th>Marker</th>
<th>Purpose</th>
<th>Test Runs?</th>
<th>Use When</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>@pytest.mark.skip</code></td>
<td>Don't run this test</td>
<td>No</td>
<td>Feature not ready, test broken</td>
</tr>
<tr>
<td><code>@pytest.mark.skipif(condition)</code></td>
<td>Skip if condition true</td>
<td>No</td>
<td>Platform/version specific</td>
</tr>
<tr>
<td><code>@pytest.mark.xfail</code></td>
<td>Expect this test to fail</td>
<td>Yes</td>
<td>Known bug, flaky test</td>
</tr>
<tr>
<td><code>@pytest.mark.filterwarnings</code></td>
<td>Control warning display</td>
<td>Yes</td>
<td>Suppress known warnings</td>
</tr>
</tbody>
</table>
<h3 id="decision-framework-which-marker-to-use">Decision Framework: Which Marker to Use?</h3>
<p><strong>Question 1</strong>: Should the test run at all?</p>
<ul>
<li><strong>No</strong> ‚Üí Use <code>skip</code> or <code>skipif</code></li>
<li><strong>Yes</strong> ‚Üí Continue to Question 2</li>
</ul>
<p><strong>Question 2</strong>: Do you expect it to pass?</p>
<ul>
<li><strong>Yes</strong> ‚Üí No marker needed (or use custom markers for organization)</li>
<li><strong>No</strong> ‚Üí Use <code>xfail</code></li>
</ul>
<p><strong>Question 3</strong>: Does it generate warnings?</p>
<ul>
<li><strong>Yes, and I can't fix them</strong> ‚Üí Add <code>filterwarnings</code></li>
<li><strong>Yes, and I should fix them</strong> ‚Üí Don't suppress, fix the code</li>
</ul>
<h2 id="what-youve-learned_1">What You've Learned</h2>
<p>Built-in markers provide standard solutions for common testing scenarios:</p>
<ol>
<li><strong><code>skip</code>/<code>skipif</code></strong>: Prevent tests from running based on conditions</li>
<li><strong><code>xfail</code></strong>: Run tests that are expected to fail, track when they pass</li>
<li><strong><code>filterwarnings</code></strong>: Control warning output for specific tests</li>
</ol>
<p><strong>Key insights</strong>:</p>
<ul>
<li>Markers are evaluated in order: skip ‚Üí xfail ‚Üí execution</li>
<li><code>xfail</code> tests always run (unlike <code>skip</code>)</li>
<li>Markers can be combined, but skip takes precedence</li>
<li>Built-in markers have special behavior (not just metadata)</li>
</ul>
<p><strong>What's next</strong>: Built-in markers cover common cases, but real projects need custom markers for domain-specific organization. In the next section, we'll create custom markers for our payment processor test suite.</p>
<h2 id="creating-custom-markers">Creating Custom Markers</h2>
<h2 id="the-problem-project-specific-test-categories">The Problem: Project-Specific Test Categories</h2>
<p>Your payment processor test suite has grown. You now have:</p>
<ul>
<li><strong>Unit tests</strong>: Fast, isolated, no external dependencies</li>
<li><strong>Integration tests</strong>: Hit test database, slower</li>
<li><strong>End-to-end tests</strong>: Full payment flow, very slow</li>
<li><strong>Security tests</strong>: Test fraud detection, PCI compliance</li>
<li><strong>Performance tests</strong>: Benchmark payment processing speed</li>
</ul>
<p>You want to:</p>
<ul>
<li>Run only unit tests during development (fast feedback)</li>
<li>Run integration tests before committing</li>
<li>Run security tests before deployment</li>
<li>Run performance tests nightly</li>
</ul>
<p>Built-in markers (<code>skip</code>, <code>xfail</code>) don't fit these categories. You need <strong>custom markers</strong> that reflect your project's structure.</p>
<h2 id="iteration-1-creating-your-first-custom-marker">Iteration 1: Creating Your First Custom Marker</h2>
<h3 id="the-naive-approach">The Naive Approach</h3>
<p>Let's try using a custom marker without any setup:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fast unit test.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_with_database</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Integration test with database.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span> <span class="n">test_database</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>
</code></pre></div>

<p><strong>Run the tests</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">2</span><span class="w"> </span>items

test_payment_processor.py::test_validate_credit_card<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">1</span><span class="w"> </span>warning<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.03s<span class="w"> </span><span class="o">===================</span>

warnings<span class="w"> </span>summary
test_payment_processor.py:4
<span class="w">  </span>/path/to/test_payment_processor.py:4:<span class="w"> </span>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.unit<span class="w"> </span>-<span class="w"> </span>is<span class="w"> </span>this<span class="w"> </span>a<span class="w"> </span>typo?<span class="w">  </span>You<span class="w"> </span>can<span class="w"> </span>register<span class="w"> </span>custom<span class="w"> </span>marks<span class="w"> </span>to<span class="w"> </span>avoid<span class="w"> </span>this<span class="w"> </span>warning<span class="w"> </span>-<span class="w"> </span><span class="k">for</span><span class="w"> </span>details,<span class="w"> </span>see<span class="w"> </span>https://docs.pytest.org/en/stable/how-to/mark.html
<span class="w">    </span>@pytest.mark.unit

test_payment_processor.py:9
<span class="w">  </span>/path/to/test_payment_processor.py:9:<span class="w"> </span>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.integration<span class="w"> </span>-<span class="w"> </span>is<span class="w"> </span>this<span class="w"> </span>a<span class="w"> </span>typo?<span class="w">  </span>You<span class="w"> </span>can<span class="w"> </span>register<span class="w"> </span>custom<span class="w"> </span>marks<span class="w"> </span>to<span class="w"> </span>avoid<span class="w"> </span>this<span class="w"> </span>warning<span class="w"> </span>-<span class="w"> </span><span class="k">for</span><span class="w"> </span>details,<span class="w"> </span>see<span class="w"> </span>https://docs.pytest.org/en/stable/how-to/mark.html
<span class="w">    </span>@pytest.mark.integration
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li>‚úÖ Tests ran successfully</li>
<li>‚úÖ Markers were applied (you can filter with <code>-m unit</code>)</li>
<li>‚ö†Ô∏è Pytest issued warnings about unknown markers</li>
</ol>
<p><strong>Why the warning?</strong>: Pytest doesn't know if <code>unit</code> and <code>integration</code> are:</p>
<ul>
<li>Intentional custom markers</li>
<li>Typos (e.g., <code>@pytest.mark.integratoin</code>)</li>
<li>Mistakes (e.g., <code>@pytest.mark.slow</code> when you meant the built-in)</li>
</ul>
<h3 id="the-solution-register-custom-markers">The Solution: Register Custom Markers</h3>
<p>Tell pytest about your custom markers in a configuration file. Create <code>pytest.ini</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">unit</span><span class="o">:</span><span class="w"> </span><span class="s">Fast unit tests with no external dependencies</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">Integration tests that use test database</span>
</code></pre></div>

<p><strong>Run the tests again</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">2</span><span class="w"> </span>items

test_payment_processor.py::test_validate_credit_card<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment_with_database<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.03s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What changed</strong>:</p>
<ol>
<li>‚úÖ No warnings</li>
<li>‚úÖ Markers are now "official" parts of your test suite</li>
<li>‚úÖ Typos will be caught (e.g., <code>@pytest.mark.integratoin</code> will still warn)</li>
</ol>
<h3 id="viewing-registered-markers">Viewing Registered Markers</h3>
<p>See all available markers:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>--markers
@pytest.mark.unit:<span class="w"> </span>Fast<span class="w"> </span>unit<span class="w"> </span>tests<span class="w"> </span>with<span class="w"> </span>no<span class="w"> </span>external<span class="w"> </span>dependencies

@pytest.mark.integration:<span class="w"> </span>Integration<span class="w"> </span>tests<span class="w"> </span>that<span class="w"> </span>use<span class="w"> </span><span class="nb">test</span><span class="w"> </span>database

@pytest.mark.skip<span class="o">(</span><span class="nv">reason</span><span class="o">=</span>None<span class="o">)</span>:<span class="w"> </span>skip<span class="w"> </span>the<span class="w"> </span>given<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="k">function</span><span class="w"> </span>with<span class="w"> </span>an<span class="w"> </span>optional<span class="w"> </span>reason...

@pytest.mark.skipif<span class="o">(</span>condition,<span class="w"> </span>...,<span class="w"> </span>*,<span class="w"> </span><span class="nv">reason</span><span class="o">=</span>...<span class="o">)</span>:<span class="w"> </span>skip<span class="w"> </span>the<span class="w"> </span>given<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">if</span><span class="w"> </span>any<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>conditions<span class="w"> </span>evaluate<span class="w"> </span>to<span class="w"> </span>True...

@pytest.mark.xfail<span class="o">(</span>condition,<span class="w"> </span>...,<span class="w"> </span>*,<span class="w"> </span><span class="nv">reason</span><span class="o">=</span>...,<span class="w"> </span><span class="nv">run</span><span class="o">=</span>True,<span class="w"> </span><span class="nv">raises</span><span class="o">=</span>None,<span class="w"> </span><span class="nv">strict</span><span class="o">=</span>xfail_strict<span class="o">)</span>:<span class="w"> </span>mark<span class="w"> </span><span class="nb">test</span><span class="w"> </span>as<span class="w"> </span>expected<span class="w"> </span>to<span class="w"> </span>fail...

@pytest.mark.filterwarnings<span class="o">(</span>warning<span class="o">)</span>:<span class="w"> </span>add<span class="w"> </span>a<span class="w"> </span>warning<span class="w"> </span>filter<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>given<span class="w"> </span>test...

@pytest.mark.parametrize<span class="o">(</span>argnames,<span class="w"> </span>argvalues<span class="o">)</span>:<span class="w"> </span>call<span class="w"> </span>a<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="k">function</span><span class="w"> </span>multiple<span class="w"> </span><span class="nb">times</span><span class="w"> </span>passing<span class="w"> </span><span class="k">in</span><span class="w"> </span>different<span class="w"> </span>arguments...

<span class="o">[</span>...<span class="w"> </span>more<span class="w"> </span>built-in<span class="w"> </span>markers<span class="w"> </span>...<span class="o">]</span>
</code></pre></div>

<p><strong>Key observation</strong>: Your custom markers appear alongside built-in markers, with your descriptions visible.</p>
<h2 id="iteration-2-building-a-complete-marker-taxonomy">Iteration 2: Building a Complete Marker Taxonomy</h2>
<h3 id="the-scenario_4">The Scenario</h3>
<p>Your payment processor now has a comprehensive test suite. You need markers for:</p>
<ol>
<li><strong>Test type</strong>: unit, integration, e2e</li>
<li><strong>Test speed</strong>: fast, slow</li>
<li><strong>Test category</strong>: security, performance, smoke</li>
<li><strong>Requirements</strong>: requires_database, requires_network, requires_auth</li>
</ol>
<p>Let's build a complete marker system:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="c1"># Test types</span>
<span class="w">    </span><span class="na">unit</span><span class="o">:</span><span class="w"> </span><span class="s">Fast unit tests with no external dependencies</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">Integration tests that use test database or external services</span>
<span class="w">    </span><span class="na">e2e</span><span class="o">:</span><span class="w"> </span><span class="s">End-to-end tests that test complete user workflows</span>

<span class="w">    </span><span class="c1"># Speed categories</span>
<span class="w">    </span><span class="na">fast</span><span class="o">:</span><span class="w"> </span><span class="s">Tests that complete in under 100ms</span>
<span class="w">    </span><span class="na">slow</span><span class="o">:</span><span class="w"> </span><span class="s">Tests that take more than 1 second</span>

<span class="w">    </span><span class="c1"># Functional categories</span>
<span class="w">    </span><span class="na">security</span><span class="o">:</span><span class="w"> </span><span class="s">Security-related tests (fraud detection, PCI compliance)</span>
<span class="w">    </span><span class="na">performance</span><span class="o">:</span><span class="w"> </span><span class="s">Performance and load testing</span>
<span class="w">    </span><span class="na">smoke</span><span class="o">:</span><span class="w"> </span><span class="s">Critical path tests that should always pass</span>

<span class="w">    </span><span class="c1"># Requirements</span>
<span class="w">    </span><span class="na">requires_database</span><span class="o">:</span><span class="w"> </span><span class="s">Test requires database connection</span>
<span class="w">    </span><span class="na">requires_network</span><span class="o">:</span><span class="w"> </span><span class="s">Test requires network access</span>
<span class="w">    </span><span class="na">requires_auth</span><span class="o">:</span><span class="w"> </span><span class="s">Test requires authentication setup</span>
</code></pre></div>

<p><strong>Now apply these markers to your test suite</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Unit Tests - Fast, No Dependencies</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_accepts_valid_number</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validate credit card using Luhn algorithm.&quot;&quot;&quot;</span>
    <span class="n">valid_card</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">valid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_rejects_invalid_number</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reject invalid credit card number.&quot;&quot;&quot;</span>
    <span class="n">invalid_card</span> <span class="o">=</span> <span class="s2">&quot;1234567890123456&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">invalid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_calculate_transaction_fee</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate correct transaction fee.&quot;&quot;&quot;</span>
    <span class="n">fee</span> <span class="o">=</span> <span class="n">calculate_transaction_fee</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span> <span class="n">card_type</span><span class="o">=</span><span class="s2">&quot;visa&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">fee</span> <span class="o">==</span> <span class="mf">2.90</span>  <span class="c1"># 2.9% for Visa</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Integration Tests - Database Required</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_records_transaction</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process payment and verify database record.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database_connection</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>

    <span class="c1"># Verify transaction recorded</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">test_database</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="s2">&quot;SELECT * FROM transactions WHERE amount = ?&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">100.00</span><span class="p">,)</span>
    <span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">transaction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">transaction</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_refund_updates_transaction_status</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process refund and verify status update.&quot;&quot;&quot;</span>
    <span class="c1"># First create a transaction</span>
    <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span> <span class="n">test_database</span><span class="p">)</span>

    <span class="c1"># Then refund it</span>
    <span class="n">refund_payment</span><span class="p">(</span><span class="n">transaction_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">database_connection</span><span class="o">=</span><span class="n">test_database</span><span class="p">)</span>

    <span class="c1"># Verify status updated</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">test_database</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="s2">&quot;SELECT status FROM transactions WHERE id = ?&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;refunded&quot;</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># End-to-End Tests - Full Workflow</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">e2e</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_network</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_complete_payment_workflow</span><span class="p">(</span><span class="n">test_database</span><span class="p">,</span> <span class="n">mock_payment_gateway</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test complete payment workflow from cart to confirmation.&quot;&quot;&quot;</span>
    <span class="c1"># 1. Create shopping cart</span>
    <span class="n">cart</span> <span class="o">=</span> <span class="n">create_cart</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;product_id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;quantity&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;price&quot;</span><span class="p">:</span> <span class="mf">29.99</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;product_id&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;quantity&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;price&quot;</span><span class="p">:</span> <span class="mf">49.99</span><span class="p">}</span>
    <span class="p">])</span>

    <span class="c1"># 2. Process payment</span>
    <span class="n">payment_result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="n">cart</span><span class="o">.</span><span class="n">total</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database_connection</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>

    <span class="c1"># 3. Verify payment gateway called</span>
    <span class="k">assert</span> <span class="n">mock_payment_gateway</span><span class="o">.</span><span class="n">was_called</span><span class="p">()</span>

    <span class="c1"># 4. Verify order created</span>
    <span class="n">order</span> <span class="o">=</span> <span class="n">get_order</span><span class="p">(</span><span class="n">payment_result</span><span class="p">[</span><span class="s2">&quot;order_id&quot;</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">order</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;confirmed&quot;</span>
    <span class="k">assert</span> <span class="n">order</span><span class="o">.</span><span class="n">total</span> <span class="o">==</span> <span class="n">cart</span><span class="o">.</span><span class="n">total</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Security Tests</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">security</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_credit_card_number_is_masked_in_logs</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Ensure credit card numbers are masked in log output.&quot;&quot;&quot;</span>
    <span class="n">card_number</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>
    <span class="n">log_entry</span> <span class="o">=</span> <span class="n">create_log_entry</span><span class="p">(</span><span class="n">card_number</span><span class="p">)</span>

    <span class="c1"># Should show only last 4 digits</span>
    <span class="k">assert</span> <span class="s2">&quot;4532015112830366&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">log_entry</span>
    <span class="k">assert</span> <span class="s2">&quot;****0366&quot;</span> <span class="ow">in</span> <span class="n">log_entry</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">security</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_fraud_detection_blocks_suspicious_transaction</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test fraud detection system blocks suspicious patterns.&quot;&quot;&quot;</span>
    <span class="c1"># Attempt multiple rapid transactions from same card</span>
    <span class="n">card_number</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
            <span class="n">amount</span><span class="o">=</span><span class="mf">1000.00</span><span class="p">,</span>
            <span class="n">card_number</span><span class="o">=</span><span class="n">card_number</span><span class="p">,</span>
            <span class="n">database_connection</span><span class="o">=</span><span class="n">test_database</span>
        <span class="p">)</span>

    <span class="c1"># 10th transaction should be blocked</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;blocked&quot;</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reason&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;fraud_detection&quot;</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Performance Tests</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">performance</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_processing_performance</span><span class="p">(</span><span class="n">benchmark</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Benchmark payment processing speed.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span>
        <span class="n">process_payment</span><span class="p">,</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database_connection</span><span class="o">=</span><span class="kc">None</span>  <span class="c1"># Use mock</span>
    <span class="p">)</span>

    <span class="c1"># Should process in under 100ms</span>
    <span class="k">assert</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mean</span> <span class="o">&lt;</span> <span class="mf">0.1</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Smoke Tests - Critical Path</span>
<span class="c1"># ============================================================================</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">smoke</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_processor_is_importable</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify payment processor module can be imported.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">payment_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>
    <span class="k">assert</span> <span class="nb">callable</span><span class="p">(</span><span class="n">process_payment</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">smoke</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_can_connect_to_database</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify database connection works.&quot;&quot;&quot;</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">test_database</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT 1&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</code></pre></div>

<p><strong>What we've built</strong>:</p>
<ol>
<li><strong>Clear categorization</strong>: Every test has meaningful markers</li>
<li><strong>Multiple dimensions</strong>: Tests can be unit + fast + security</li>
<li><strong>Flexible filtering</strong>: Can run tests by type, speed, category, or requirements</li>
<li><strong>Self-documenting</strong>: Markers explain what each test needs</li>
</ol>
<h2 id="iteration-3-using-markers-for-selective-test-execution">Iteration 3: Using Markers for Selective Test Execution</h2>
<p>Now that tests are marked, let's use markers to run specific subsets:</p>
<h3 id="development-workflow-fast-feedback">Development Workflow: Fast Feedback</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run only fast unit tests during development</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and fast&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">25</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">20</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">5</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span>PASSED
test_payment_processor.py::test_credit_card_number_is_masked_in_logs<span class="w"> </span>PASSED
test_payment_processor.py::test_payment_processor_is_importable<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">5</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">20</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.05s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Result</strong>: 5 tests in 0.05 seconds. Perfect for TDD cycle.</p>
<h3 id="pre-commit-integration-tests">Pre-Commit: Integration Tests</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run unit and integration tests before committing</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">25</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">8</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">17</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid_number<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment_records_transaction<span class="w"> </span>PASSED
test_payment_processor.py::test_refund_updates_transaction_status<span class="w"> </span>PASSED
test_payment_processor.py::test_credit_card_number_is_masked_in_logs<span class="w"> </span>PASSED
test_payment_processor.py::test_fraud_detection_blocks_suspicious_transaction<span class="w"> </span>PASSED
test_payment_processor.py::test_payment_processor_is_importable<span class="w"> </span>PASSED
test_payment_processor.py::test_can_connect_to_database<span class="w"> </span>PASSED
<span class="o">[</span>...<span class="w"> </span>more<span class="w"> </span>tests<span class="w"> </span>...<span class="o">]</span>

<span class="o">===================</span><span class="w"> </span><span class="m">17</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">8</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span>.34s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Result</strong>: 17 tests in 2.34 seconds. Reasonable for pre-commit hook.</p>
<h3 id="ci-pipeline-security-and-smoke-tests">CI Pipeline: Security and Smoke Tests</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run security and smoke tests in CI</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;security or smoke&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">25</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">20</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">5</span><span class="w"> </span>selected

test_payment_processor.py::test_credit_card_number_is_masked_in_logs<span class="w"> </span>PASSED
test_payment_processor.py::test_fraud_detection_blocks_suspicious_transaction<span class="w"> </span>PASSED
test_payment_processor.py::test_payment_processor_is_importable<span class="w"> </span>PASSED
test_payment_processor.py::test_can_connect_to_database<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">4</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">20</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span>.23s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<h3 id="nightly-build-everything">Nightly Build: Everything</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run all tests including slow performance tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">25</span><span class="w"> </span>items

<span class="o">[</span>...<span class="w"> </span>all<span class="w"> </span>tests<span class="w"> </span>run<span class="w"> </span>...<span class="o">]</span>

<span class="o">===================</span><span class="w"> </span><span class="m">25</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">15</span>.67s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<h3 id="complex-marker-expressions">Complex Marker Expressions</h3>
<p>Pytest supports boolean logic in marker expressions:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run integration tests that don&#39;t require network</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;integration and not requires_network&quot;</span>

<span class="c1"># Run fast tests OR smoke tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;fast or smoke&quot;</span>

<span class="c1"># Run security tests that are also unit tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;security and unit&quot;</span>

<span class="c1"># Run everything except slow tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not slow&quot;</span>

<span class="c1"># Run tests that require database but not network</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;requires_database and not requires_network&quot;</span>
</code></pre></div>

<p><strong>Operator precedence</strong>:</p>
<ol>
<li><code>not</code> (highest)</li>
<li><code>and</code></li>
<li><code>or</code> (lowest)</li>
</ol>
<p>Use parentheses for clarity: <code>pytest -m "(unit or integration) and not slow"</code></p>
<h2 id="iteration-4-markers-with-arguments">Iteration 4: Markers with Arguments</h2>
<h3 id="the-scenario_5">The Scenario</h3>
<p>Some tests require specific Python versions or external service versions. You want to document these requirements in the marker itself.</p>
<p><strong>Custom markers can accept arguments</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="c1"># ... previous markers ...</span>
<span class="w">    </span><span class="na">requires_python(version)</span><span class="o">:</span><span class="w"> </span><span class="s">Test requires specific Python version</span>
<span class="w">    </span><span class="na">requires_service(name, version)</span><span class="o">:</span><span class="w"> </span><span class="s">Test requires external service</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_python</span><span class="p">(</span><span class="s2">&quot;3.10&quot;</span><span class="p">)</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;Requires Python 3.10+&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_pattern_matching_in_payment_routing</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test payment routing using Python 3.10 match statement.&quot;&quot;&quot;</span>
    <span class="n">payment_type</span> <span class="o">=</span> <span class="s2">&quot;credit_card&quot;</span>

    <span class="k">match</span> <span class="n">payment_type</span><span class="p">:</span>
        <span class="k">case</span> <span class="s2">&quot;credit_card&quot;</span><span class="p">:</span>
            <span class="n">processor</span> <span class="o">=</span> <span class="n">CreditCardProcessor</span><span class="p">()</span>
        <span class="k">case</span> <span class="s2">&quot;paypal&quot;</span><span class="p">:</span>
            <span class="n">processor</span> <span class="o">=</span> <span class="n">PayPalProcessor</span><span class="p">()</span>
        <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
            <span class="n">processor</span> <span class="o">=</span> <span class="n">DefaultProcessor</span><span class="p">()</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="n">CreditCardProcessor</span><span class="p">)</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_service</span><span class="p">(</span><span class="s2">&quot;payment_gateway&quot;</span><span class="p">,</span> <span class="s2">&quot;v2.0&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_v2_features</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test features specific to payment gateway v2.0.&quot;&quot;&quot;</span>
    <span class="c1"># Test code here</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Why use markers with arguments?</strong></p>
<ol>
<li><strong>Documentation</strong>: The marker shows requirements clearly</li>
<li><strong>Filtering</strong>: Can filter by specific versions if needed</li>
<li><strong>Reporting</strong>: Test reports show which versions are required</li>
<li><strong>Automation</strong>: CI can parse markers to set up correct environment</li>
</ol>
<p><strong>Note</strong>: The marker itself doesn't enforce the requirement‚Äîyou still need <code>skipif</code> for that. The marker is documentation and metadata.</p>
<h2 id="diagnostic-analysis-common-marker-mistakes">Diagnostic Analysis: Common Marker Mistakes</h2>
<h3 id="mistake-1-forgetting-to-register-markers">Mistake 1: Forgetting to Register Markers</h3>
<p><strong>Symptom</strong>: Warning about unknown marker.</p>
<div class="codehilite"><pre><span></span><code>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.mymarker<span class="w"> </span>-<span class="w"> </span>is<span class="w"> </span>this<span class="w"> </span>a<span class="w"> </span>typo?
</code></pre></div>

<p><strong>Root cause</strong>: Marker used but not registered in <code>pytest.ini</code>.</p>
<p><strong>Solution</strong>: Add to <code>pytest.ini</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">mymarker</span><span class="o">:</span><span class="w"> </span><span class="s">Description of what this marker means</span>
</code></pre></div>

<h3 id="mistake-2-typo-in-marker-name">Mistake 2: Typo in Marker Name</h3>
<p><strong>Symptom</strong>: Tests don't run when filtering by marker.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;integratoin&quot;</span><span class="w">  </span><span class="c1"># Typo: should be &quot;integration&quot;</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">25</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">25</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="nv">selected</span>

<span class="o">===================</span><span class="w"> </span><span class="m">25</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.02s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Root cause</strong>: Marker name in filter doesn't match marker name in code.</p>
<p><strong>Solution</strong>: </p>
<ol>
<li>Check marker spelling in test code</li>
<li>Use <code>pytest --markers</code> to see registered markers</li>
<li>Consider using constants for marker names:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py</span>
<span class="n">MARKER_UNIT</span> <span class="o">=</span> <span class="s2">&quot;unit&quot;</span>
<span class="n">MARKER_INTEGRATION</span> <span class="o">=</span> <span class="s2">&quot;integration&quot;</span>

<span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">conftest</span><span class="w"> </span><span class="kn">import</span> <span class="n">MARKER_UNIT</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">MARKER_UNIT</span><span class="p">)</span>  <span class="c1"># Not recommended, just showing concept</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Better approach</strong>: Use IDE autocomplete and rely on the warning system to catch typos.</p>
<h3 id="mistake-3-over-marking-tests">Mistake 3: Over-Marking Tests</h3>
<p><strong>Symptom</strong>: Tests have 5+ markers, making them hard to understand.</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">security</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">smoke</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">critical</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">regression</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Root cause</strong>: Trying to categorize tests in too many dimensions.</p>
<p><strong>Solution</strong>: Choose 2-3 primary dimensions:</p>
<ol>
<li><strong>Test type</strong> (unit/integration/e2e)</li>
<li><strong>Speed</strong> (fast/slow)</li>
<li><strong>Category</strong> (security/performance/smoke)</li>
</ol>
<p><strong>Guideline</strong>: If a test needs more than 3 markers, your marker taxonomy is too complex.</p>
<h3 id="mistake-4-inconsistent-marker-usage">Mistake 4: Inconsistent Marker Usage</h3>
<p><strong>Symptom</strong>: Some integration tests marked <code>integration</code>, others not.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Some tests marked</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_with_database</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="c1"># Others not marked</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_refund_with_database</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>  <span class="c1"># Missing marker!</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Root cause</strong>: No enforcement of marker policy.</p>
<p><strong>Solution</strong>: Create a pytest hook to enforce markers:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pytest_collection_modifyitems</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">items</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Ensure all tests have required markers.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
        <span class="c1"># Get all markers on this test</span>
        <span class="n">markers</span> <span class="o">=</span> <span class="p">[</span><span class="n">mark</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">mark</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">iter_markers</span><span class="p">()]</span>

        <span class="c1"># Check if test has at least one type marker</span>
        <span class="n">type_markers</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="s2">&quot;integration&quot;</span><span class="p">,</span> <span class="s2">&quot;e2e&quot;</span><span class="p">}</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">m</span> <span class="ow">in</span> <span class="n">type_markers</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">markers</span><span class="p">):</span>
            <span class="c1"># Add default marker or raise error</span>
            <span class="n">item</span><span class="o">.</span><span class="n">add_marker</span><span class="p">(</span><span class="n">pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span><span class="p">)</span>  <span class="c1"># Default to unit</span>

            <span class="c1"># Or raise error to force explicit marking:</span>
            <span class="c1"># pytest.fail(f&quot;Test {item.nodeid} missing type marker (unit/integration/e2e)&quot;)</span>
</code></pre></div>

<p><strong>This hook runs during test collection and can</strong>:</p>
<ul>
<li>Add default markers</li>
<li>Validate marker presence</li>
<li>Enforce marker policies</li>
</ul>
<h2 id="when-to-apply-custom-markers">When to Apply Custom Markers</h2>
<h3 id="use-custom-markers-when">Use Custom Markers When:</h3>
<ol>
<li><strong>Multiple test categories exist</strong>: unit, integration, e2e</li>
<li><strong>Different execution contexts</strong>: local dev, CI, nightly builds</li>
<li><strong>Resource requirements vary</strong>: database, network, authentication</li>
<li><strong>Speed matters</strong>: fast feedback loop vs. comprehensive testing</li>
<li><strong>Compliance needs</strong>: security, performance, smoke tests</li>
</ol>
<h3 id="dont-use-custom-markers-when">Don't Use Custom Markers When:</h3>
<ol>
<li><strong>Only one test type</strong>: Just use files/directories</li>
<li><strong>Never run subsets</strong>: Always run all tests</li>
<li><strong>Categories are obvious</strong>: File structure already clear</li>
<li><strong>Over-engineering</strong>: 5 tests don't need 10 markers</li>
</ol>
<h3 id="decision-framework-files-vs-markers">Decision Framework: Files vs. Markers</h3>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Use</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tests naturally group by module</td>
<td>Files/directories</td>
<td>Physical organization matches logical</td>
</tr>
<tr>
<td>Tests span multiple modules</td>
<td>Markers</td>
<td>Cross-cutting concerns</td>
</tr>
<tr>
<td>Never run partial suite</td>
<td>Files</td>
<td>No need for filtering</td>
</tr>
<tr>
<td>Frequently run subsets</td>
<td>Markers</td>
<td>Flexible filtering</td>
</tr>
<tr>
<td>Team &lt; 3 people</td>
<td>Files</td>
<td>Simpler</td>
</tr>
<tr>
<td>Team &gt; 10 people</td>
<td>Markers</td>
<td>Standardized categories</td>
</tr>
</tbody>
</table>
<h2 id="what-youve-learned_2">What You've Learned</h2>
<p>Custom markers let you create project-specific test categories:</p>
<ol>
<li><strong>Register markers</strong> in <code>pytest.ini</code> to avoid warnings</li>
<li><strong>Apply multiple markers</strong> to tests for multi-dimensional categorization</li>
<li><strong>Filter tests</strong> using boolean expressions: <code>and</code>, <code>or</code>, <code>not</code></li>
<li><strong>Markers with arguments</strong> document requirements</li>
<li><strong>Enforce marker policies</strong> with pytest hooks</li>
</ol>
<p><strong>Key insights</strong>:</p>
<ul>
<li>Markers are metadata, not behavior (except built-in markers)</li>
<li>Good marker taxonomy has 2-3 dimensions</li>
<li>Markers enable flexible test execution strategies</li>
<li>Registration prevents typos and documents intent</li>
</ul>
<p><strong>What's next</strong>: We've created markers and applied them to tests. But where do you register them? How do you share marker definitions across projects? The next section covers marker registration and configuration in depth.</p>
<h2 id="registering-markers-in-configuration">Registering Markers in Configuration</h2>
<h2 id="the-problem-marker-configuration-chaos">The Problem: Marker Configuration Chaos</h2>
<p>Your payment processor project has grown. You now have:</p>
<ul>
<li>Multiple test files using the same markers</li>
<li>New team members who don't know which markers exist</li>
<li>Typos in marker names causing silent failures</li>
<li>No documentation of what each marker means</li>
</ul>
<p><strong>Current state</strong>: Markers work, but there's no central source of truth.</p>
<p><strong>What you need</strong>: A configuration system that:</p>
<ol>
<li>Defines all available markers in one place</li>
<li>Documents what each marker means</li>
<li>Catches typos automatically</li>
<li>Works across different configuration formats</li>
</ol>
<p>This is what marker registration solves.</p>
<h2 id="iteration-1-basic-registration-in-pytestini">Iteration 1: Basic Registration in pytest.ini</h2>
<h3 id="the-scenario_6">The Scenario</h3>
<p>You have three test files, all using the same markers:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="c1"># test_fraud_detection.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_fraud_score_calculation</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">security</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_fraud_detection_blocks_suspicious</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="c1"># test_reporting.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_generate_transaction_report</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_generate_annual_report</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Without registration</strong>, running tests produces warnings:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span><span class="nv">pytest</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">6</span><span class="w"> </span>items

test_payment_processor.py<span class="w"> </span>..<span class="w">                                   </span><span class="o">[</span><span class="w"> </span><span class="m">33</span>%<span class="o">]</span>
test_fraud_detection.py<span class="w"> </span>..<span class="w">                                     </span><span class="o">[</span><span class="w"> </span><span class="m">66</span>%<span class="o">]</span>
test_reporting.py<span class="w"> </span>..<span class="w">                                           </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">===================</span><span class="w"> </span><span class="m">6</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">4</span><span class="w"> </span>warnings<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.15s<span class="w"> </span><span class="o">===================</span>

warnings<span class="w"> </span>summary
test_payment_processor.py:3
<span class="w">  </span>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.unit
test_payment_processor.py:7
<span class="w">  </span>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.integration
test_fraud_detection.py:7
<span class="w">  </span>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.security
test_reporting.py:7
<span class="w">  </span>PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.slow
</code></pre></div>

<h3 id="the-solution-create-pytestini">The Solution: Create pytest.ini</h3>
<p>Create a <code>pytest.ini</code> file in your project root:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">unit</span><span class="o">:</span><span class="w"> </span><span class="s">Fast unit tests with no external dependencies</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">Integration tests that use test database</span>
<span class="w">    </span><span class="na">security</span><span class="o">:</span><span class="w"> </span><span class="s">Security-related tests</span>
<span class="w">    </span><span class="na">slow</span><span class="o">:</span><span class="w"> </span><span class="s">Tests that take more than 1 second</span>
</code></pre></div>

<p><strong>Run tests again</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span><span class="nv">pytest</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">6</span><span class="w"> </span>items

test_payment_processor.py<span class="w"> </span>..<span class="w">                                   </span><span class="o">[</span><span class="w"> </span><span class="m">33</span>%<span class="o">]</span>
test_fraud_detection.py<span class="w"> </span>..<span class="w">                                     </span><span class="o">[</span><span class="w"> </span><span class="m">66</span>%<span class="o">]</span>
test_reporting.py<span class="w"> </span>..<span class="w">                                           </span><span class="o">[</span><span class="m">100</span>%<span class="o">]</span>

<span class="o">===================</span><span class="w"> </span><span class="m">6</span><span class="w"> </span>passed<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.15s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What changed</strong>:</p>
<ol>
<li>‚úÖ No warnings</li>
<li>‚úÖ All markers recognized</li>
<li>‚úÖ Single source of truth for marker definitions</li>
</ol>
<h3 id="viewing-registered-markers_1">Viewing Registered Markers</h3>
<p>Check what markers are available:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>--markers
@pytest.mark.unit:<span class="w"> </span>Fast<span class="w"> </span>unit<span class="w"> </span>tests<span class="w"> </span>with<span class="w"> </span>no<span class="w"> </span>external<span class="w"> </span>dependencies

@pytest.mark.integration:<span class="w"> </span>Integration<span class="w"> </span>tests<span class="w"> </span>that<span class="w"> </span>use<span class="w"> </span><span class="nb">test</span><span class="w"> </span>database

@pytest.mark.security:<span class="w"> </span>Security-related<span class="w"> </span>tests

@pytest.mark.slow:<span class="w"> </span>Tests<span class="w"> </span>that<span class="w"> </span>take<span class="w"> </span>more<span class="w"> </span>than<span class="w"> </span><span class="m">1</span><span class="w"> </span>second

@pytest.mark.skip<span class="o">(</span><span class="nv">reason</span><span class="o">=</span>None<span class="o">)</span>:<span class="w"> </span>skip<span class="w"> </span>the<span class="w"> </span>given<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="k">function</span>...
<span class="o">[</span>...<span class="w"> </span>built-in<span class="w"> </span>markers<span class="w"> </span>...<span class="o">]</span>
</code></pre></div>

<p><strong>Key observation</strong>: Your custom markers appear first, with descriptions, followed by built-in markers.</p>
<h2 id="iteration-2-alternative-configuration-formats">Iteration 2: Alternative Configuration Formats</h2>
<h3 id="the-scenario_7">The Scenario</h3>
<p>Your project uses <code>pyproject.toml</code> for Python packaging. You want to keep all configuration in one file instead of having separate <code>pytest.ini</code>.</p>
<p>Pytest supports three configuration formats:</p>
<ol>
<li><strong>pytest.ini</strong> - Dedicated pytest configuration</li>
<li><strong>setup.cfg</strong> - Legacy Python packaging format</li>
<li><strong>pyproject.toml</strong> - Modern Python packaging format (PEP 518)</li>
</ol>
<h3 id="option-1-pytestini-already-covered">Option 1: pytest.ini (Already Covered)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">unit</span><span class="o">:</span><span class="w"> </span><span class="s">Fast unit tests with no external dependencies</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">Integration tests that use test database</span>
</code></pre></div>

<p><strong>Pros</strong>:</p>
<ul>
<li>Dedicated pytest configuration</li>
<li>Clear separation of concerns</li>
<li>Easy to find</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Another file to maintain</li>
<li>Not used if project has <code>pyproject.toml</code></li>
</ul>
<h3 id="option-2-setupcfg">Option 2: setup.cfg</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># setup.cfg</span>
<span class="k">[tool:pytest]</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">unit</span><span class="o">:</span><span class="w"> </span><span class="s">Fast unit tests with no external dependencies</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">Integration tests that use test database</span>
</code></pre></div>

<p><strong>Pros</strong>:</p>
<ul>
<li>Combines with other Python tool configuration</li>
<li>Legacy projects already have this file</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li><code>setup.cfg</code> is being phased out in favor of <code>pyproject.toml</code></li>
<li>Less clear than dedicated <code>pytest.ini</code></li>
</ul>
<h3 id="option-3-pyprojecttoml-recommended-for-new-projects">Option 3: pyproject.toml (Recommended for New Projects)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;security: Security-related tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Tests that take more than 1 second&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>Pros</strong>:</p>
<ul>
<li>Modern Python standard (PEP 518)</li>
<li>Single file for all tool configuration</li>
<li>Better for projects using Poetry, Hatch, or PDM</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>TOML syntax slightly different from INI</li>
<li>Requires pytest 6.0+</li>
</ul>
<h3 id="which-format-to-choose">Which Format to Choose?</h3>
<p><strong>Decision tree</strong>:</p>
<ol>
<li><strong>Does your project have <code>pyproject.toml</code>?</strong></li>
<li>Yes ‚Üí Use <code>pyproject.toml</code></li>
<li>
<p>No ‚Üí Continue to step 2</p>
</li>
<li>
<p><strong>Are you starting a new project?</strong></p>
</li>
<li>Yes ‚Üí Use <code>pyproject.toml</code> (future-proof)</li>
<li>
<p>No ‚Üí Continue to step 3</p>
</li>
<li>
<p><strong>Does your project have <code>setup.cfg</code>?</strong></p>
</li>
<li>Yes ‚Üí Use <code>setup.cfg</code> (consistency)</li>
<li>No ‚Üí Use <code>pytest.ini</code> (clarity)</li>
</ol>
<p><strong>For our payment processor example</strong>, we'll use <code>pyproject.toml</code> since it's a modern project:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[build-system]</span>
<span class="n">requires</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;setuptools&gt;=61.0&quot;</span><span class="p">]</span>
<span class="n">build-backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;setuptools.build_meta&quot;</span>

<span class="k">[project]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;payment-processor&quot;</span>
<span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;1.0.0&quot;</span>
<span class="n">dependencies</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;pytest&gt;=7.0&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;e2e: End-to-end tests that test complete workflows&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;security: Security-related tests (fraud detection, PCI compliance)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;performance: Performance and load testing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;smoke: Critical path tests that should always pass&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Tests that take more than 1 second&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;fast: Tests that complete in under 100ms&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;requires_database: Test requires database connection&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;requires_network: Test requires network access&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;requires_auth: Test requires authentication setup&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<h2 id="iteration-3-marker-descriptions-and-documentation">Iteration 3: Marker Descriptions and Documentation</h2>
<h3 id="the-scenario_8">The Scenario</h3>
<p>A new developer joins your team. They see <code>@pytest.mark.smoke</code> in the code and wonder:</p>
<ul>
<li>What does "smoke" mean?</li>
<li>When should they use it?</li>
<li>What's the difference between <code>smoke</code> and <code>fast</code>?</li>
</ul>
<p><strong>The marker description should answer these questions.</strong></p>
<h3 id="writing-good-marker-descriptions">Writing Good Marker Descriptions</h3>
<p><strong>Bad descriptions</strong> (too vague):</p>
<div class="codehilite"><pre><span></span><code><span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Unit tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Slow tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;security: Security tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>Good descriptions</strong> (clear and actionable):</p>
<div class="codehilite"><pre><span></span><code><span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies (&lt; 100ms, no database/network)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Tests that take more than 1 second (typically integration or e2e tests)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;security: Security-related tests including fraud detection, PCI compliance, and vulnerability scanning&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="comprehensive-marker-documentation">Comprehensive Marker Documentation</h3>
<p>Here's a complete, well-documented marker configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># Test Types (mutually exclusive - each test should have exactly one)</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies (&lt; 100ms, no database/network)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database or external services (1-5 seconds)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;e2e: End-to-end tests that test complete user workflows (5+ seconds)&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># Speed Categories (optional, for additional filtering)</span>
<span class="w">    </span><span class="s2">&quot;fast: Tests that complete in under 100ms (useful for TDD workflow)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Tests that take more than 1 second (run less frequently)&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># Functional Categories (optional, can have multiple per test)</span>
<span class="w">    </span><span class="s2">&quot;security: Security-related tests (fraud detection, PCI compliance, vulnerability scanning)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;performance: Performance and load testing (benchmarks, stress tests)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;smoke: Critical path tests that should always pass (run first in CI)&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># Requirements (optional, documents what test needs)</span>
<span class="w">    </span><span class="s2">&quot;requires_database: Test requires database connection (uses test_database fixture)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;requires_network: Test requires network access (may fail if offline)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;requires_auth: Test requires authentication setup (uses auth fixtures)&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># Platform-Specific (optional, combined with skipif)</span>
<span class="w">    </span><span class="s2">&quot;linux_only: Test only runs on Linux (uses Linux-specific features)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;windows_only: Test only runs on Windows (uses Windows-specific features)&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>What makes this good</strong>:</p>
<ol>
<li><strong>Grouped by category</strong>: Test types, speed, functional, requirements, platform</li>
<li><strong>Clear expectations</strong>: Timing, dependencies, and usage documented</li>
<li><strong>Mutually exclusive noted</strong>: "each test should have exactly one" for test types</li>
<li><strong>Examples provided</strong>: "(uses test_database fixture)"</li>
<li><strong>Comments explain structure</strong>: Helps maintainers understand organization</li>
</ol>
<h2 id="iteration-4-enforcing-marker-registration">Iteration 4: Enforcing Marker Registration</h2>
<h3 id="the-scenario_9">The Scenario</h3>
<p>A developer adds a new marker <code>@pytest.mark.wip</code> (work in progress) but forgets to register it. Tests run fine locally, but CI fails with warnings.</p>
<p><strong>You want to</strong>: Catch unregistered markers immediately, not in CI.</p>
<h3 id="the-solution-strict-marker-checking">The Solution: Strict Marker Checking</h3>
<p>Add this to your pytest configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="c1"># ... other markers ...</span>
<span class="p">]</span>

<span class="c1"># Treat unknown markers as errors</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;--strict-markers&quot;</span>
</code></pre></div>

<p><strong>Now try using an unregistered marker</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payment_processor.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">wip</span>  <span class="c1"># Not registered!</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_new_feature</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>test_payment_processor.py::test_new_feature
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">0</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="nv">error</span>

<span class="o">================================</span><span class="w"> </span><span class="nv">ERRORS</span><span class="w"> </span><span class="o">================================</span>
_____________<span class="w"> </span>ERROR<span class="w"> </span>collecting<span class="w"> </span>test_payment_processor.py<span class="w"> </span>______________
<span class="s1">&#39;wip&#39;</span><span class="w"> </span>not<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="sb">`</span>markers<span class="sb">`</span><span class="w"> </span>configuration<span class="w"> </span>option
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li>‚ùå Test collection failed (didn't even run tests)</li>
<li>‚ùå Clear error message: "'wip' not found in <code>markers</code> configuration option"</li>
<li>‚úÖ Caught the mistake immediately</li>
</ol>
<p><strong>To fix</strong>: Register the marker:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;wip: Work in progress - test under development&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;--strict-markers&quot;</span>
</code></pre></div>

<p><strong>When to use strict markers</strong>:</p>
<ul>
<li>‚úÖ Team projects (prevent typos)</li>
<li>‚úÖ CI/CD pipelines (catch mistakes early)</li>
<li>‚úÖ Projects with many markers (enforce discipline)</li>
<li>‚ùå Solo projects (may be too strict)</li>
<li>‚ùå Exploratory testing (slows down experimentation)</li>
</ul>
<h2 id="iteration-5-configuration-inheritance-and-overrides">Iteration 5: Configuration Inheritance and Overrides</h2>
<h3 id="the-scenario_10">The Scenario</h3>
<p>Your payment processor is part of a larger monorepo with multiple Python projects. Each project has its own markers, but some markers are shared across all projects.</p>
<p><strong>Project structure</strong>:</p>
<div class="codehilite"><pre><span></span><code>monorepo/
‚îú‚îÄ‚îÄ<span class="w"> </span>pyproject.toml<span class="w">          </span><span class="c1"># Root configuration (shared markers)</span>
‚îú‚îÄ‚îÄ<span class="w"> </span>payment-processor/
‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>pyproject.toml<span class="w">      </span><span class="c1"># Payment-specific markers</span>
‚îÇ<span class="w">   </span>‚îî‚îÄ‚îÄ<span class="w"> </span>tests/
‚îú‚îÄ‚îÄ<span class="w"> </span>fraud-detection/
‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>pyproject.toml<span class="w">      </span><span class="c1"># Fraud-specific markers</span>
‚îÇ<span class="w">   </span>‚îî‚îÄ‚îÄ<span class="w"> </span>tests/
‚îî‚îÄ‚îÄ<span class="w"> </span>reporting/
<span class="w">    </span>‚îú‚îÄ‚îÄ<span class="w"> </span>pyproject.toml<span class="w">      </span><span class="c1"># Reporting-specific markers</span>
<span class="w">    </span>‚îî‚îÄ‚îÄ<span class="w"> </span>tests/
</code></pre></div>

<h3 id="root-configuration-shared-markers">Root Configuration (Shared Markers)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># monorepo/pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># Shared markers used by all projects</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;e2e: End-to-end tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Tests that take more than 1 second&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;fast: Tests that complete in under 100ms&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="project-specific-configuration">Project-Specific Configuration</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># monorepo/payment-processor/pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># Payment-specific markers (in addition to shared markers)</span>
<span class="w">    </span><span class="s2">&quot;pci_compliance: PCI DSS compliance tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;payment_gateway: Tests that interact with payment gateway&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;refund: Refund processing tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># monorepo/fraud-detection/pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># Fraud-specific markers</span>
<span class="w">    </span><span class="s2">&quot;ml_model: Tests for machine learning models&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;rule_engine: Tests for fraud detection rules&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;false_positive: Tests for false positive scenarios&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>How pytest resolves configuration</strong>:</p>
<ol>
<li>Looks for configuration in current directory</li>
<li>Walks up directory tree until it finds a configuration file</li>
<li>Uses the <strong>first</strong> configuration file found (no merging)</li>
</ol>
<p><strong>Problem</strong>: Project-specific markers override shared markers (no inheritance).</p>
<h3 id="solution-document-shared-markers-in-each-project">Solution: Document Shared Markers in Each Project</h3>
<p>Since pytest doesn't merge configurations, you need to duplicate shared markers:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># monorepo/payment-processor/pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># Shared markers (duplicated from root)</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;e2e: End-to-end tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Tests that take more than 1 second&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;fast: Tests that complete in under 100ms&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># Payment-specific markers</span>
<span class="w">    </span><span class="s2">&quot;pci_compliance: PCI DSS compliance tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;payment_gateway: Tests that interact with payment gateway&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;refund: Refund processing tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>Alternative</strong>: Use a shared configuration file:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># monorepo/shared_pytest_config.py</span>
<span class="n">SHARED_MARKERS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;unit: Fast unit tests with no external dependencies&quot;</span><span class="p">,</span>
    <span class="s2">&quot;integration: Integration tests that use test database&quot;</span><span class="p">,</span>
    <span class="s2">&quot;e2e: End-to-end tests&quot;</span><span class="p">,</span>
    <span class="s2">&quot;slow: Tests that take more than 1 second&quot;</span><span class="p">,</span>
    <span class="s2">&quot;fast: Tests that complete in under 100ms&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># monorepo/payment-processor/conftest.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">shared_pytest_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">SHARED_MARKERS</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pytest_configure</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Register shared markers programmatically.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">marker</span> <span class="ow">in</span> <span class="n">SHARED_MARKERS</span><span class="p">:</span>
        <span class="n">config</span><span class="o">.</span><span class="n">addinivalue_line</span><span class="p">(</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="p">)</span>

    <span class="c1"># Add project-specific markers</span>
    <span class="n">config</span><span class="o">.</span><span class="n">addinivalue_line</span><span class="p">(</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span> <span class="s2">&quot;pci_compliance: PCI DSS compliance tests&quot;</span><span class="p">)</span>
    <span class="n">config</span><span class="o">.</span><span class="n">addinivalue_line</span><span class="p">(</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span> <span class="s2">&quot;payment_gateway: Tests that interact with payment gateway&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>This approach</strong>:</p>
<ul>
<li>‚úÖ Single source of truth for shared markers</li>
<li>‚úÖ Each project can add its own markers</li>
<li>‚úÖ No duplication</li>
<li>‚ùå More complex (requires conftest.py)</li>
</ul>
<h2 id="diagnostic-analysis-configuration-issues">Diagnostic Analysis: Configuration Issues</h2>
<h3 id="issue-1-markers-not-recognized-despite-registration">Issue 1: Markers Not Recognized Despite Registration</h3>
<p><strong>Symptom</strong>: Markers registered in <code>pyproject.toml</code> but pytest still warns about unknown markers.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest
PytestUnknownMarkWarning:<span class="w"> </span>Unknown<span class="w"> </span>pytest.mark.unit
</code></pre></div>

<p><strong>Diagnostic steps</strong>:</p>
<ol>
<li><strong>Check pytest version</strong>: <code>pytest --version</code></li>
<li><code>pyproject.toml</code> support requires pytest 6.0+</li>
<li>
<p>If using older pytest, use <code>pytest.ini</code> instead</p>
</li>
<li>
<p><strong>Verify configuration location</strong>: <code>pytest --version -v</code></p>
</li>
<li>Pytest shows which configuration file it's using</li>
<li>
<p>Make sure it's finding your <code>pyproject.toml</code></p>
</li>
<li>
<p><strong>Check TOML syntax</strong>:</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># Wrong (missing quotes)</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="err">unit: Fast unit tests</span>
<span class="err">]</span>

<span class="c1"># Correct</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<ol>
<li><strong>Verify section name</strong>:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># Wrong</span>
<span class="k">[pytest]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="err">...]</span>

<span class="c1"># Correct</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="err">...]</span>
</code></pre></div>

<h3 id="issue-2-configuration-not-found">Issue 2: Configuration Not Found</h3>
<p><strong>Symptom</strong>: Pytest doesn't find your configuration file.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>--version<span class="w"> </span>-v
pytest<span class="w"> </span><span class="m">7</span>.4.0
rootdir:<span class="w"> </span>/home/user/project
configfile:<span class="w"> </span>None<span class="w">  </span><span class="c1"># &lt;-- No config file found!</span>
</code></pre></div>

<p><strong>Root cause</strong>: Configuration file not in pytest's search path.</p>
<p><strong>Pytest searches for configuration in this order</strong>:</p>
<ol>
<li><code>pytest.ini</code> in current directory</li>
<li><code>pyproject.toml</code> in current directory</li>
<li><code>setup.cfg</code> in current directory</li>
<li>Walk up directory tree repeating steps 1-3</li>
</ol>
<p><strong>Solution</strong>: Place configuration file in project root or run pytest from correct directory.</p>
<h3 id="issue-3-strict-markers-too-strict">Issue 3: Strict Markers Too Strict</h3>
<p><strong>Symptom</strong>: Can't use built-in markers with <code>--strict-markers</code>.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>--strict-markers
ERROR:<span class="w"> </span><span class="s1">&#39;parametrize&#39;</span><span class="w"> </span>not<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="sb">`</span>markers<span class="sb">`</span><span class="w"> </span>configuration<span class="w"> </span>option
</code></pre></div>

<p><strong>Root cause</strong>: <code>--strict-markers</code> requires ALL markers to be registered, including built-in ones.</p>
<p><strong>Solution</strong>: Don't register built-in markers‚Äîthey're automatically available. The error suggests you're using a marker that looks built-in but isn't, or there's a typo.</p>
<p><strong>Check</strong>: <code>pytest --markers</code> to see all available markers.</p>
<h2 id="configuration-best-practices">Configuration Best Practices</h2>
<h3 id="1-choose-one-configuration-format">1. Choose One Configuration Format</h3>
<p>Don't mix formats. If you have <code>pyproject.toml</code>, don't also create <code>pytest.ini</code>.</p>
<p><strong>Pytest's precedence</strong> (first found wins):</p>
<ol>
<li><code>pytest.ini</code></li>
<li><code>pyproject.toml</code></li>
<li><code>tox.ini</code></li>
<li><code>setup.cfg</code></li>
</ol>
<h3 id="2-document-marker-usage">2. Document Marker Usage</h3>
<p>Include usage guidelines in your marker descriptions:</p>
<div class="codehilite"><pre><span></span><code><span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests (&lt; 100ms). Use for: pure functions, business logic, no I/O&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests (1-5s). Use for: database operations, API calls&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="3-use-strict-markers-in-ci">3. Use Strict Markers in CI</h3>
<p>Enable strict markers in CI but not locally:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="err">...]</span>

<span class="c1"># Don&#39;t add --strict-markers here</span>
<span class="c1"># Instead, add it in CI configuration</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/test.yml</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run tests</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest --strict-markers</span>
</code></pre></div>

<p><strong>Why</strong>: Developers can experiment locally, but CI enforces discipline.</p>
<h3 id="4-keep-marker-list-organized">4. Keep Marker List Organized</h3>
<p>Group markers by category with comments:</p>
<div class="codehilite"><pre><span></span><code><span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># === Test Types ===</span>
<span class="w">    </span><span class="s2">&quot;unit: ...&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: ...&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># === Speed ===</span>
<span class="w">    </span><span class="s2">&quot;fast: ...&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: ...&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># === Requirements ===</span>
<span class="w">    </span><span class="s2">&quot;requires_database: ...&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="5-review-markers-regularly">5. Review Markers Regularly</h3>
<p>Markers accumulate over time. Periodically review and remove unused markers:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Find all markers used in code</span>
$<span class="w"> </span>grep<span class="w"> </span>-r<span class="w"> </span><span class="s2">&quot;@pytest.mark.&quot;</span><span class="w"> </span>tests/<span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span><span class="s1">&#39;s/.*@pytest.mark.\([a-z_]*\).*/\1/&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sort<span class="w"> </span>-u

<span class="c1"># Compare with registered markers</span>
$<span class="w"> </span>pytest<span class="w"> </span>--markers<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span><span class="s2">&quot;^@pytest.mark&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span><span class="s2">&quot;skip\|xfail\|parametrize&quot;</span>
</code></pre></div>

<h2 id="what-youve-learned_3">What You've Learned</h2>
<p>Marker registration provides a central source of truth for test categorization:</p>
<ol>
<li><strong>Three configuration formats</strong>: <code>pytest.ini</code>, <code>setup.cfg</code>, <code>pyproject.toml</code></li>
<li><strong>Choose <code>pyproject.toml</code></strong> for new projects (modern standard)</li>
<li><strong>Write clear descriptions</strong> that explain when to use each marker</li>
<li><strong>Use <code>--strict-markers</code></strong> to catch typos and enforce registration</li>
<li><strong>Configuration doesn't inherit</strong> in monorepos (must duplicate or use conftest.py)</li>
</ol>
<p><strong>Key insights</strong>:</p>
<ul>
<li>Registration prevents typos and documents intent</li>
<li>Good descriptions answer "when should I use this marker?"</li>
<li>Strict markers enforce discipline in team projects</li>
<li>Configuration format choice depends on project structure</li>
</ul>
<p><strong>What's next</strong>: We've registered markers and applied them to tests. Now we need to use them effectively. The next section covers filtering tests by markers and building efficient test execution strategies.</p>
<h2 id="filtering-tests-by-markers">Filtering Tests by Markers</h2>
<h2 id="the-problem-running-the-right-tests-at-the-right-time">The Problem: Running the Right Tests at the Right Time</h2>
<p>Your payment processor test suite has 150 tests:</p>
<ul>
<li>80 fast unit tests (&lt; 100ms each)</li>
<li>50 integration tests (1-3 seconds each)</li>
<li>15 end-to-end tests (5-10 seconds each)</li>
<li>5 performance tests (30+ seconds each)</li>
</ul>
<p><strong>Total runtime</strong>: ~8 minutes for the full suite.</p>
<p><strong>The challenge</strong>: Different contexts need different test subsets:</p>
<ul>
<li><strong>During development</strong>: Run only fast unit tests (instant feedback)</li>
<li><strong>Before committing</strong>: Run unit + integration tests (confidence)</li>
<li><strong>In CI pull requests</strong>: Run everything except performance tests (thorough but fast)</li>
<li><strong>Nightly builds</strong>: Run everything including performance tests (comprehensive)</li>
</ul>
<p><strong>What you need</strong>: Precise control over which tests run in each context.</p>
<h2 id="iteration-1-basic-marker-filtering">Iteration 1: Basic Marker Filtering</h2>
<h3 id="the-scenario_11">The Scenario</h3>
<p>You're developing a new feature in the payment validation module. You want to run only the unit tests for this module to get instant feedback.</p>
<p><strong>First, let's see all tests</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>--collect-only<span class="w"> </span>-q
test_payment_processor.py::test_validate_credit_card_accepts_valid
test_payment_processor.py::test_validate_credit_card_rejects_invalid
test_payment_processor.py::test_calculate_transaction_fee
test_payment_processor.py::test_process_payment_records_transaction
test_payment_processor.py::test_refund_updates_transaction_status
test_payment_processor.py::test_complete_payment_workflow
test_fraud_detection.py::test_fraud_score_calculation
test_fraud_detection.py::test_fraud_detection_blocks_suspicious
test_reporting.py::test_generate_transaction_report
test_reporting.py::test_generate_annual_report

<span class="m">10</span><span class="w"> </span>tests<span class="w"> </span>collected
</code></pre></div>

<h3 id="filter-by-single-marker">Filter by Single Marker</h3>
<p>Run only unit tests:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>unit<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">6</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">4</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span>PASSED
test_fraud_detection.py::test_fraud_score_calculation<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">4</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">6</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.08s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li><strong>"10 items / 6 deselected / 4 selected"</strong>: Pytest found 10 tests, filtered out 6, ran 4</li>
<li><strong>Execution time</strong>: 0.08 seconds (vs. 8 minutes for full suite)</li>
<li><strong>Only unit tests ran</strong>: Integration and e2e tests were skipped</li>
</ol>
<h3 id="understanding-the-m-flag">Understanding the -m Flag</h3>
<p>The <code>-m</code> flag accepts a <strong>marker expression</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Basic syntax</span>
pytest<span class="w"> </span>-m<span class="w"> </span>MARKER_NAME

<span class="c1"># Examples</span>
pytest<span class="w"> </span>-m<span class="w"> </span>unit<span class="w">           </span><span class="c1"># Run tests marked with @pytest.mark.unit</span>
pytest<span class="w"> </span>-m<span class="w"> </span>integration<span class="w">    </span><span class="c1"># Run tests marked with @pytest.mark.integration</span>
pytest<span class="w"> </span>-m<span class="w"> </span>slow<span class="w">           </span><span class="c1"># Run tests marked with @pytest.mark.slow</span>
</code></pre></div>

<p><strong>Key insight</strong>: The <code>-m</code> flag doesn't run tests in a specific file or directory‚Äîit filters the entire test collection based on markers.</p>
<h2 id="iteration-2-boolean-logic-in-marker-expressions">Iteration 2: Boolean Logic in Marker Expressions</h2>
<h3 id="the-scenario_12">The Scenario</h3>
<p>You want to run unit tests AND integration tests, but not e2e tests (for pre-commit hook).</p>
<h3 id="using-or-logic">Using OR Logic</h3>
<p>Run tests that are EITHER unit OR integration:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">2</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">8</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment_records_transaction<span class="w"> </span>PASSED
test_payment_processor.py::test_refund_updates_transaction_status<span class="w"> </span>PASSED
test_fraud_detection.py::test_fraud_score_calculation<span class="w"> </span>PASSED
test_fraud_detection.py::test_fraud_detection_blocks_suspicious<span class="w"> </span>PASSED
test_reporting.py::test_generate_transaction_report<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">8</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">2</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span>.45s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Result</strong>: 8 tests ran (4 unit + 4 integration), 2 deselected (e2e tests).</p>
<h3 id="using-and-logic">Using AND Logic</h3>
<p>Run tests that are BOTH integration AND security:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;integration and security&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">9</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">1</span><span class="w"> </span>selected

test_fraud_detection.py::test_fraud_detection_blocks_suspicious<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">1</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">9</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span>.23s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Result</strong>: Only 1 test has both markers.</p>
<h3 id="using-not-logic">Using NOT Logic</h3>
<p>Run all tests EXCEPT slow ones:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not slow&quot;</span><span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">3</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">7</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span>PASSED
test_payment_processor.py::test_process_payment_records_transaction<span class="w"> </span>PASSED
test_fraud_detection.py::test_fraud_score_calculation<span class="w"> </span>PASSED
test_fraud_detection.py::test_fraud_detection_blocks_suspicious<span class="w"> </span>PASSED
test_reporting.py::test_generate_transaction_report<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">7</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">3</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">2</span>.15s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Result</strong>: 7 tests ran (all except the 3 marked as slow).</p>
<h2 id="iteration-3-complex-marker-expressions">Iteration 3: Complex Marker Expressions</h2>
<h3 id="the-scenario_13">The Scenario</h3>
<p>Your CI pipeline has different stages:</p>
<ol>
<li><strong>Fast feedback</strong>: Unit tests only</li>
<li><strong>Integration check</strong>: Integration tests that don't require network</li>
<li><strong>Security scan</strong>: All security tests</li>
<li><strong>Full suite</strong>: Everything except performance tests</li>
</ol>
<p>Let's build marker expressions for each stage.</p>
<h3 id="stage-1-fast-feedback-unit-tests-only">Stage 1: Fast Feedback (Unit Tests Only)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Simple: just unit tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>unit

<span class="c1"># More precise: unit tests that are also fast</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and fast&quot;</span>
</code></pre></div>

<h3 id="stage-2-integration-tests-without-network">Stage 2: Integration Tests Without Network</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Integration tests that don&#39;t require network</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;integration and not requires_network&quot;</span>
</code></pre></div>

<p><strong>Example test that matches</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_records_transaction</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This test runs (has integration, no requires_network).&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Example test that doesn't match</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_network</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_gateway_integration</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This test is skipped (has requires_network).&quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div>

<h3 id="stage-3-all-security-tests">Stage 3: All Security Tests</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># All security tests regardless of type</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>security
</code></pre></div>

<h3 id="stage-4-full-suite-except-performance">Stage 4: Full Suite Except Performance</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Everything except performance tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not performance&quot;</span>

<span class="c1"># More explicit: unit, integration, or e2e, but not performance</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;(unit or integration or e2e) and not performance&quot;</span>
</code></pre></div>

<h3 id="operator-precedence">Operator Precedence</h3>
<p>Marker expressions follow boolean logic precedence:</p>
<ol>
<li><strong><code>not</code></strong> (highest precedence)</li>
<li><strong><code>and</code></strong></li>
<li><strong><code>or</code></strong> (lowest precedence)</li>
</ol>
<p><strong>Example without parentheses</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># This expression:</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration and not slow&quot;</span>

<span class="c1"># Is evaluated as:</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or (integration and (not slow))&quot;</span>

<span class="c1"># Meaning: Run tests that are EITHER:</span>
<span class="c1"># - unit tests (any speed), OR</span>
<span class="c1"># - integration tests that are not slow</span>
</code></pre></div>

<p><strong>Example with parentheses for clarity</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># What you probably meant:</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;(unit or integration) and not slow&quot;</span>

<span class="c1"># Meaning: Run tests that are:</span>
<span class="c1"># - (unit OR integration) AND not slow</span>
</code></pre></div>

<p><strong>Best practice</strong>: Use parentheses for complex expressions to make intent clear.</p>
<h2 id="iteration-4-combining-markers-with-other-filters">Iteration 4: Combining Markers with Other Filters</h2>
<h3 id="the-scenario_14">The Scenario</h3>
<p>You want to run unit tests, but only for the payment processor module (not fraud detection or reporting).</p>
<h3 id="combining-m-with-k-keyword-filter">Combining -m with -k (Keyword Filter)</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run unit tests with &quot;payment&quot; in the test name</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>unit<span class="w"> </span>-k<span class="w"> </span>payment<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">8</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">2</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">8</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.05s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li>First filter: <code>-m unit</code> selected 4 tests (all unit tests)</li>
<li>Second filter: <code>-k payment</code> selected tests with "payment" in name</li>
<li>Result: 2 tests matched both filters</li>
</ol>
<h3 id="combining-m-with-filedirectory-selection">Combining -m with File/Directory Selection</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run unit tests only in test_payment_processor.py</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>unit<span class="w"> </span>test_payment_processor.py<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">6</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">3</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">3</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid<span class="w"> </span>PASSED
test_payment_processor.py::test_calculate_transaction_fee<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">3</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">3</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.05s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>What happened</strong>:</p>
<ol>
<li>First filter: <code>test_payment_processor.py</code> selected 6 tests from that file</li>
<li>Second filter: <code>-m unit</code> selected only unit tests</li>
<li>Result: 3 tests matched both filters</li>
</ol>
<h3 id="combining-multiple-filters">Combining Multiple Filters</h3>
<p>You can combine all filter types:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run fast unit tests with &quot;validate&quot; in name from payment processor file</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and fast&quot;</span><span class="w"> </span>-k<span class="w"> </span>validate<span class="w"> </span>test_payment_processor.py<span class="w"> </span>-v
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">6</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">4</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">2</span><span class="w"> </span>selected

test_payment_processor.py::test_validate_credit_card_accepts_valid<span class="w"> </span>PASSED
test_payment_processor.py::test_validate_credit_card_rejects_invalid<span class="w"> </span><span class="nv">PASSED</span>

<span class="o">===================</span><span class="w"> </span><span class="m">2</span><span class="w"> </span>passed,<span class="w"> </span><span class="m">4</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.03s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Filter order doesn't matter</strong>: Pytest applies all filters to the collected tests.</p>
<h2 id="iteration-5-practical-filtering-strategies">Iteration 5: Practical Filtering Strategies</h2>
<h3 id="development-workflow">Development Workflow</h3>
<p>Create shell aliases or scripts for common filter combinations:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ~/.bashrc or ~/.zshrc</span>

<span class="c1"># Fast feedback during development</span>
<span class="nb">alias</span><span class="w"> </span>pytest-fast<span class="o">=</span><span class="s2">&quot;pytest -m &#39;unit and fast&#39;&quot;</span>

<span class="c1"># Pre-commit checks</span>
<span class="nb">alias</span><span class="w"> </span>pytest-commit<span class="o">=</span><span class="s2">&quot;pytest -m &#39;unit or integration&#39;&quot;</span>

<span class="c1"># Security audit</span>
<span class="nb">alias</span><span class="w"> </span>pytest-security<span class="o">=</span><span class="s2">&quot;pytest -m security&quot;</span>

<span class="c1"># Full suite except slow tests</span>
<span class="nb">alias</span><span class="w"> </span>pytest-quick<span class="o">=</span><span class="s2">&quot;pytest -m &#39;not slow&#39;&quot;</span>
</code></pre></div>

<p><strong>Usage</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest-fast
<span class="c1"># Runs only fast unit tests</span>

$<span class="w"> </span>pytest-commit
<span class="c1"># Runs unit and integration tests</span>
</code></pre></div>

<h3 id="cicd-pipeline-configuration">CI/CD Pipeline Configuration</h3>
<p>Define marker expressions in your CI configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/test.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Test Suite</span>

<span class="nt">on</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">push</span><span class="p p-Indicator">,</span><span class="w"> </span><span class="nv">pull_request</span><span class="p p-Indicator">]</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">fast-tests</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run fast tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -m &quot;unit and fast&quot; --tb=short</span>

<span class="w">  </span><span class="nt">integration-tests</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run integration tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -m &quot;integration and not requires_network&quot;</span>

<span class="w">  </span><span class="nt">security-tests</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run security tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -m security</span>

<span class="w">  </span><span class="nt">full-suite</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">github.event_name == &#39;push&#39; &amp;&amp; github.ref == &#39;refs/heads/main&#39;</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run full test suite</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -m &quot;not performance&quot;</span>
</code></pre></div>

<p><strong>This configuration</strong>:</p>
<ol>
<li><strong>Fast tests</strong>: Run on every push (instant feedback)</li>
<li><strong>Integration tests</strong>: Run in parallel (faster CI)</li>
<li><strong>Security tests</strong>: Run separately (clear reporting)</li>
<li><strong>Full suite</strong>: Run only on main branch (comprehensive but slow)</li>
</ol>
<h3 id="make-configuration">Make Configuration</h3>
<p>Create a Makefile for common test commands:</p>
<div class="codehilite"><pre><span></span><code><span class="c"># Makefile</span>

<span class="nf">.PHONY</span><span class="o">:</span><span class="w"> </span><span class="n">test</span> <span class="n">test</span>-<span class="n">fast</span> <span class="n">test</span>-<span class="n">unit</span> <span class="n">test</span>-<span class="n">integration</span> <span class="n">test</span>-<span class="n">security</span> <span class="n">test</span>-<span class="n">all</span>

<span class="c"># Fast feedback during development</span>
<span class="nf">test-fast</span><span class="o">:</span>
<span class="w">    </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and fast&quot;</span><span class="w"> </span>-v

<span class="c"># Unit tests only</span>
<span class="nf">test-unit</span><span class="o">:</span>
<span class="w">    </span>pytest<span class="w"> </span>-m<span class="w"> </span>unit<span class="w"> </span>-v

<span class="c"># Integration tests only</span>
<span class="nf">test-integration</span><span class="o">:</span>
<span class="w">    </span>pytest<span class="w"> </span>-m<span class="w"> </span>integration<span class="w"> </span>-v

<span class="c"># Security tests</span>
<span class="nf">test-security</span><span class="o">:</span>
<span class="w">    </span>pytest<span class="w"> </span>-m<span class="w"> </span>security<span class="w"> </span>-v

<span class="c"># Pre-commit checks</span>
<span class="nf">test-commit</span><span class="o">:</span>
<span class="w">    </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration&quot;</span><span class="w"> </span>-v

<span class="c"># Full suite</span>
<span class="nf">test-all</span><span class="o">:</span>
<span class="w">    </span>pytest<span class="w"> </span>-v

<span class="c"># Default target</span>
<span class="nf">test</span><span class="o">:</span><span class="w"> </span><span class="n">test</span>-<span class="n">fast</span>
</code></pre></div>

<p><strong>Usage</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>make<span class="w"> </span><span class="nb">test</span><span class="w">          </span><span class="c1"># Runs fast tests (default)</span>
$<span class="w"> </span>make<span class="w"> </span>test-unit<span class="w">     </span><span class="c1"># Runs unit tests</span>
$<span class="w"> </span>make<span class="w"> </span>test-commit<span class="w">   </span><span class="c1"># Runs pre-commit checks</span>
$<span class="w"> </span>make<span class="w"> </span>test-all<span class="w">      </span><span class="c1"># Runs everything</span>
</code></pre></div>

<h2 id="diagnostic-analysis-filtering-issues">Diagnostic Analysis: Filtering Issues</h2>
<h3 id="issue-1-no-tests-selected">Issue 1: No Tests Selected</h3>
<p><strong>Symptom</strong>: Marker filter selects zero tests.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and security&quot;</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
collected<span class="w"> </span><span class="m">10</span><span class="w"> </span>items<span class="w"> </span>/<span class="w"> </span><span class="m">10</span><span class="w"> </span>deselected<span class="w"> </span>/<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="nv">selected</span>

<span class="o">===================</span><span class="w"> </span><span class="m">10</span><span class="w"> </span>deselected<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">0</span>.02s<span class="w"> </span><span class="o">===================</span>
</code></pre></div>

<p><strong>Diagnostic steps</strong>:</p>
<ol>
<li><strong>Check if any tests have both markers</strong>:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># List all tests with their markers</span>
$<span class="w"> </span>pytest<span class="w"> </span>--collect-only<span class="w"> </span>-m<span class="w"> </span>unit
$<span class="w"> </span>pytest<span class="w"> </span>--collect-only<span class="w"> </span>-m<span class="w"> </span>security
</code></pre></div>

<ol>
<li><strong>Verify marker names</strong>:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># Check registered markers</span>
$<span class="w"> </span>pytest<span class="w"> </span>--markers<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-E<span class="w"> </span><span class="s2">&quot;unit|security&quot;</span>
</code></pre></div>

<ol>
<li><strong>Check for typos</strong>:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># This won&#39;t match anything (typo: &quot;secuirty&quot;)</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and secuirty&quot;</span>
</code></pre></div>

<p><strong>Root cause</strong>: Either:</p>
<ul>
<li>No tests have both markers (use <code>or</code> instead of <code>and</code>)</li>
<li>Typo in marker name</li>
<li>Markers not applied to tests</li>
</ul>
<h3 id="issue-2-unexpected-tests-selected">Issue 2: Unexpected Tests Selected</h3>
<p><strong>Symptom</strong>: Marker filter selects more tests than expected.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration and not slow&quot;</span>
<span class="c1"># Selects more tests than you expected</span>
</code></pre></div>

<p><strong>Root cause</strong>: Operator precedence.</p>
<p><strong>What you wrote</strong>:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration and not slow&quot;</span>
</code></pre></div>

<p><strong>How pytest interprets it</strong>:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or (integration and (not slow))&quot;</span>
</code></pre></div>

<p><strong>What you probably meant</strong>:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;(unit or integration) and not slow&quot;</span>
</code></pre></div>

<p><strong>Solution</strong>: Use parentheses to make precedence explicit.</p>
<h3 id="issue-3-marker-expression-syntax-error">Issue 3: Marker Expression Syntax Error</h3>
<p><strong>Symptom</strong>: Pytest reports syntax error in marker expression.</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit &amp;&amp; integration&quot;</span>
ERROR:<span class="w"> </span>Wrong<span class="w"> </span>expression<span class="w"> </span>passed<span class="w"> </span>to<span class="w"> </span><span class="s1">&#39;-m&#39;</span>:<span class="w"> </span>unit<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>integration
</code></pre></div>

<p><strong>Root cause</strong>: Using wrong boolean operators.</p>
<p><strong>Wrong operators</strong> (from other languages):</p>
<ul>
<li><code>&amp;&amp;</code> (C/Java/JavaScript)</li>
<li><code>||</code> (C/Java/JavaScript)</li>
<li><code>!</code> (C/Java/JavaScript)</li>
</ul>
<p><strong>Correct operators</strong> (Python-style):</p>
<ul>
<li><code>and</code></li>
<li><code>or</code></li>
<li><code>not</code></li>
</ul>
<p><strong>Solution</strong>: Use Python boolean operators:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Correct</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and integration&quot;</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit or integration&quot;</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not slow&quot;</span>
</code></pre></div>

<h2 id="advanced-filtering-techniques">Advanced Filtering Techniques</h2>
<h3 id="technique-1-marker-expressions-in-pytestini">Technique 1: Marker Expressions in pytest.ini</h3>
<p>Define default marker expressions in configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;unit: Fast unit tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: Integration tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;slow: Slow tests&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Default: run everything except slow tests</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;-m &#39;not slow&#39;&quot;</span>
</code></pre></div>

<p><strong>Now</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># This runs &quot;not slow&quot; by default</span>
$<span class="w"> </span>pytest

<span class="c1"># Override default to run everything</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;&quot;</span>

<span class="c1"># Override default to run only slow tests</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>slow
</code></pre></div>

<h3 id="technique-2-custom-marker-expressions-via-environment-variables">Technique 2: Custom Marker Expressions via Environment Variables</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Set marker expression via environment variable</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PYTEST_MARKERS</span><span class="o">=</span><span class="s2">&quot;unit and fast&quot;</span>

<span class="c1"># Use in pytest command</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$PYTEST_MARKERS</span><span class="s2">&quot;</span>
</code></pre></div>

<p><strong>Use case</strong>: Different CI environments can set different marker expressions.</p>
<h3 id="technique-3-programmatic-marker-filtering">Technique 3: Programmatic Marker Filtering</h3>
<p>Use pytest hooks to filter tests programmatically:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># conftest.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pytest_collection_modifyitems</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">items</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Filter tests based on environment variable.&quot;&quot;&quot;</span>
    <span class="n">marker_expr</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;TEST_MARKERS&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">marker_expr</span><span class="p">:</span>
        <span class="c1"># Parse marker expression</span>
        <span class="n">selected</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">deselected</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
            <span class="c1"># Evaluate marker expression against test&#39;s markers</span>
            <span class="k">if</span> <span class="n">should_run_test</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">marker_expr</span><span class="p">):</span>
                <span class="n">selected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">deselected</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="c1"># Modify items list</span>
        <span class="n">items</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">selected</span>

        <span class="c1"># Report deselection</span>
        <span class="n">config</span><span class="o">.</span><span class="n">hook</span><span class="o">.</span><span class="n">pytest_deselected</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="n">deselected</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">should_run_test</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">marker_expr</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate if test should run based on marker expression.&quot;&quot;&quot;</span>
    <span class="c1"># This is simplified - real implementation would parse the expression</span>
    <span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="n">mark</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">mark</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">iter_markers</span><span class="p">()}</span>

    <span class="c1"># Example: &quot;unit and fast&quot;</span>
    <span class="k">if</span> <span class="n">marker_expr</span> <span class="o">==</span> <span class="s2">&quot;unit and fast&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;unit&quot;</span> <span class="ow">in</span> <span class="n">markers</span> <span class="ow">and</span> <span class="s2">&quot;fast&quot;</span> <span class="ow">in</span> <span class="n">markers</span>

    <span class="c1"># Add more expression parsing as needed</span>
    <span class="k">return</span> <span class="kc">True</span>
</code></pre></div>

<p><strong>Usage</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Set marker expression via environment</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TEST_MARKERS</span><span class="o">=</span><span class="s2">&quot;unit and fast&quot;</span>

<span class="c1"># Run tests (hook filters automatically)</span>
pytest
</code></pre></div>

<p><strong>Note</strong>: This is advanced usage. For most cases, use <code>-m</code> flag directly.</p>
<h2 id="filtering-best-practices">Filtering Best Practices</h2>
<h3 id="1-start-broad-then-narrow">1. Start Broad, Then Narrow</h3>
<p>When debugging, start with broad filters and progressively narrow:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Step 1: Run all tests to see failures</span>
$<span class="w"> </span>pytest

<span class="c1"># Step 2: Run only failing test type</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>integration

<span class="c1"># Step 3: Run only failing test file</span>
$<span class="w"> </span>pytest<span class="w"> </span>-m<span class="w"> </span>integration<span class="w"> </span>test_payment_processor.py

<span class="c1"># Step 4: Run only failing test</span>
$<span class="w"> </span>pytest<span class="w"> </span>test_payment_processor.py::test_process_payment
</code></pre></div>

<h3 id="2-use-descriptive-marker-names">2. Use Descriptive Marker Names</h3>
<p><strong>Bad</strong> (ambiguous):</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">db</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre></div>

<p><strong>Good</strong> (clear):</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">():</span>
    <span class="k">pass</span>
</code></pre></div>

<h3 id="3-document-common-filter-expressions">3. Document Common Filter Expressions</h3>
<p>Create a README or Makefile documenting common filters:</p>
<div class="codehilite"><pre><span></span><code><span class="gh"># Testing Guide</span>

<span class="gu">## Common Test Commands</span>

<span class="gu">### Development</span>
```bash
<span class="gh"># Fast feedback (&lt; 1 second)</span>
pytest -m &quot;unit and fast&quot;

<span class="gh"># Pre-commit checks (&lt; 5 seconds)</span>
pytest -m &quot;unit or integration&quot;
</code></pre></div>

<h3 id="cicd">CI/CD</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Pull request checks</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not performance&quot;</span>

<span class="c1"># Nightly builds</span>
pytest<span class="w">  </span><span class="c1"># Run everything</span>
</code></pre></div>

<h3 id="debugging">Debugging</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run only failing test type</span>
pytest<span class="w"> </span>-m<span class="w"> </span>integration<span class="w"> </span>--lf<span class="w">  </span><span class="c1"># --lf = last failed</span>

<span class="c1"># Run tests for specific module</span>
pytest<span class="w"> </span>-m<span class="w"> </span>unit<span class="w"> </span>-k<span class="w"> </span>payment
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="gu">##</span># 4. Avoid Over-Filtering

**Anti-pattern**: Too many marker combinations.

```bash
<span class="gh">#</span> This is too specific
pytest -m &quot;unit and fast and not requires_database and not requires_network and security&quot;
</code></pre></div>

<p><strong>Better</strong>: Simplify marker taxonomy.</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Simpler and clearer</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and security&quot;</span>
</code></pre></div>

<p><strong>Guideline</strong>: If you need more than 3 boolean operators, your marker taxonomy is too complex.</p>
<h2 id="what-youve-learned_4">What You've Learned</h2>
<p>Marker filtering provides precise control over test execution:</p>
<ol>
<li><strong>Basic filtering</strong>: <code>-m marker_name</code> runs tests with that marker</li>
<li><strong>Boolean logic</strong>: Use <code>and</code>, <code>or</code>, <code>not</code> to combine markers</li>
<li><strong>Operator precedence</strong>: <code>not</code> &gt; <code>and</code> &gt; <code>or</code> (use parentheses for clarity)</li>
<li><strong>Combine filters</strong>: Mix <code>-m</code> with <code>-k</code> and file selection</li>
<li><strong>Practical strategies</strong>: Shell aliases, CI configuration, Makefiles</li>
</ol>
<p><strong>Key insights</strong>:</p>
<ul>
<li>Marker expressions are evaluated against each test's markers</li>
<li>Complex expressions need parentheses for clarity</li>
<li>Filtering is composable (multiple filters combine)</li>
<li>Good marker taxonomy makes filtering intuitive</li>
</ul>
<p><strong>What's next</strong>: We've learned to filter tests by markers. The final section covers organizing entire test suites using markers‚Äîbuilding a comprehensive testing strategy that scales from solo development to large teams.</p>
<h2 id="organizing-tests-by-category">Organizing Tests by Category</h2>
<h2 id="the-problem-test-suite-chaos-at-scale">The Problem: Test Suite Chaos at Scale</h2>
<p>Your payment processor has grown to 500+ tests across 50 files. The test suite has become difficult to navigate:</p>
<ul>
<li>New developers don't know where to add tests</li>
<li>Related tests are scattered across multiple files</li>
<li>No clear testing strategy or standards</li>
<li>CI runs take 30+ minutes</li>
<li>Flaky tests hide real failures</li>
</ul>
<p><strong>What you need</strong>: A systematic approach to organizing tests that:</p>
<ol>
<li>Makes test structure intuitive</li>
<li>Enables efficient test execution</li>
<li>Scales with team size</li>
<li>Maintains test quality</li>
</ol>
<p>This is what marker-based test organization solves.</p>
<h2 id="iteration-1-establishing-a-test-organization-strategy">Iteration 1: Establishing a Test Organization Strategy</h2>
<h3 id="the-scenario_15">The Scenario</h3>
<p>You're restructuring your test suite. You need to decide:</p>
<ul>
<li>How to categorize tests</li>
<li>How to structure test files</li>
<li>How to use markers effectively</li>
<li>How to document the organization</li>
</ul>
<h3 id="step-1-define-your-test-taxonomy">Step 1: Define Your Test Taxonomy</h3>
<p>Start by identifying the dimensions that matter for your project:</p>
<div class="codehilite"><pre><span></span><code><span class="gh"># Test Organization Strategy</span>

<span class="gu">## Primary Dimensions</span>

<span class="gu">### 1. Test Type (Mutually Exclusive)</span>
<span class="k">-</span><span class="w"> </span><span class="gs">**unit**</span>: Isolated, fast, no external dependencies
<span class="k">-</span><span class="w"> </span><span class="gs">**integration**</span>: Tests component interactions (database, APIs)
<span class="k">-</span><span class="w"> </span><span class="gs">**e2e**</span>: Full user workflows, slowest

<span class="gu">### 2. Test Speed (Optional)</span>
<span class="k">-</span><span class="w"> </span><span class="gs">**fast**</span>: &lt; 100ms (for TDD workflow)
<span class="k">-</span><span class="w"> </span><span class="gs">**slow**</span>: &gt; 1 second (run less frequently)

<span class="gu">### 3. Functional Category (Multiple Allowed)</span>
<span class="k">-</span><span class="w"> </span><span class="gs">**security**</span>: Fraud detection, PCI compliance, vulnerability testing
<span class="k">-</span><span class="w"> </span><span class="gs">**performance**</span>: Benchmarks, load tests, stress tests
<span class="k">-</span><span class="w"> </span><span class="gs">**smoke**</span>: Critical path tests that must always pass

<span class="gu">### 4. Requirements (Multiple Allowed)</span>
<span class="k">-</span><span class="w"> </span><span class="gs">**requires_database**</span>: Needs database connection
<span class="k">-</span><span class="w"> </span><span class="gs">**requires_network**</span>: Needs network access
<span class="k">-</span><span class="w"> </span><span class="gs">**requires_auth**</span>: Needs authentication setup

<span class="gu">## Marker Application Rules</span>

<span class="k">1.</span> Every test MUST have exactly one test type marker (unit/integration/e2e)
<span class="k">2.</span> Tests SHOULD have a speed marker if they&#39;re notably fast or slow
<span class="k">3.</span> Tests MAY have functional category markers
<span class="k">4.</span> Tests SHOULD have requirement markers to document dependencies
</code></pre></div>

<h3 id="step-2-structure-test-files-by-feature">Step 2: Structure Test Files by Feature</h3>
<p>Organize test files to mirror your application structure:</p>
<div class="codehilite"><pre><span></span><code>payment-processor/
‚îú‚îÄ‚îÄ<span class="w"> </span>src/
‚îÇ<span class="w">   </span>‚îî‚îÄ‚îÄ<span class="w"> </span>payment_processor/
‚îÇ<span class="w">       </span>‚îú‚îÄ‚îÄ<span class="w"> </span>__init__.py
‚îÇ<span class="w">       </span>‚îú‚îÄ‚îÄ<span class="w"> </span>validation.py<span class="w">      </span><span class="c1"># Credit card validation</span>
‚îÇ<span class="w">       </span>‚îú‚îÄ‚îÄ<span class="w"> </span>processing.py<span class="w">      </span><span class="c1"># Payment processing</span>
‚îÇ<span class="w">       </span>‚îú‚îÄ‚îÄ<span class="w"> </span>fraud.py<span class="w">           </span><span class="c1"># Fraud detection</span>
‚îÇ<span class="w">       </span>‚îî‚îÄ‚îÄ<span class="w"> </span>reporting.py<span class="w">       </span><span class="c1"># Transaction reporting</span>
‚îÇ
‚îî‚îÄ‚îÄ<span class="w"> </span>tests/
<span class="w">    </span>‚îú‚îÄ‚îÄ<span class="w"> </span>conftest.py<span class="w">            </span><span class="c1"># Shared fixtures</span>
<span class="w">    </span>‚îú‚îÄ‚îÄ<span class="w"> </span>unit/<span class="w">                  </span><span class="c1"># Unit tests (fast, isolated)</span>
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>test_validation.py
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>test_processing.py
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>test_fraud.py
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îî‚îÄ‚îÄ<span class="w"> </span>test_reporting.py
<span class="w">    </span>‚îÇ
<span class="w">    </span>‚îú‚îÄ‚îÄ<span class="w"> </span>integration/<span class="w">           </span><span class="c1"># Integration tests (database, APIs)</span>
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>test_payment_flow.py
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>test_fraud_detection.py
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îî‚îÄ‚îÄ<span class="w"> </span>test_reporting_queries.py
<span class="w">    </span>‚îÇ
<span class="w">    </span>‚îú‚îÄ‚îÄ<span class="w"> </span>e2e/<span class="w">                   </span><span class="c1"># End-to-end tests (full workflows)</span>
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îú‚îÄ‚îÄ<span class="w"> </span>test_checkout_flow.py
<span class="w">    </span>‚îÇ<span class="w">   </span>‚îî‚îÄ‚îÄ<span class="w"> </span>test_refund_flow.py
<span class="w">    </span>‚îÇ
<span class="w">    </span>‚îî‚îÄ‚îÄ<span class="w"> </span>performance/<span class="w">           </span><span class="c1"># Performance tests (benchmarks)</span>
<span class="w">        </span>‚îî‚îÄ‚îÄ<span class="w"> </span>test_payment_benchmarks.py
</code></pre></div>

<p><strong>Benefits of this structure</strong>:</p>
<ol>
<li><strong>Clear separation</strong>: Test type is obvious from directory</li>
<li><strong>Easy navigation</strong>: Find tests by feature or type</li>
<li><strong>Parallel execution</strong>: Can run directories in parallel</li>
<li><strong>Selective execution</strong>: Can run entire directories</li>
</ol>
<h3 id="step-3-apply-markers-consistently">Step 3: Apply Markers Consistently</h3>
<p>Create a template for each test type:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/unit/test_validation.py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Unit tests for credit card validation.</span>

<span class="sd">All tests in this file should be:</span>
<span class="sd">- Marked as @pytest.mark.unit</span>
<span class="sd">- Marked as @pytest.mark.fast (they should be &lt; 100ms)</span>
<span class="sd">- Have no external dependencies</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payment_processor.validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">validate_credit_card</span><span class="p">,</span> <span class="n">validate_cvv</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_accepts_valid_visa</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validate Visa card using Luhn algorithm.&quot;&quot;&quot;</span>
    <span class="n">valid_visa</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">valid_visa</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_credit_card_rejects_invalid_checksum</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reject card with invalid Luhn checksum.&quot;&quot;&quot;</span>
    <span class="n">invalid_card</span> <span class="o">=</span> <span class="s2">&quot;4532015112830367&quot;</span>  <span class="c1"># Last digit wrong</span>
    <span class="k">assert</span> <span class="n">validate_credit_card</span><span class="p">(</span><span class="n">invalid_card</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_cvv_accepts_three_digits</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Accept valid 3-digit CVV.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">validate_cvv</span><span class="p">(</span><span class="s2">&quot;123&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_validate_cvv_rejects_non_numeric</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reject CVV with non-numeric characters.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">validate_cvv</span><span class="p">(</span><span class="s2">&quot;12A&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/integration/test_payment_flow.py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Integration tests for payment processing flow.</span>

<span class="sd">All tests in this file should be:</span>
<span class="sd">- Marked as @pytest.mark.integration</span>
<span class="sd">- Marked as @pytest.mark.slow (they use database)</span>
<span class="sd">- Marked as @pytest.mark.requires_database</span>
<span class="sd">- Use test_database fixture</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payment_processor.processing</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span><span class="p">,</span> <span class="n">refund_payment</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_records_transaction</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process payment and verify database record created.&quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>

    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>

    <span class="c1"># Verify transaction recorded</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">test_database</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="s2">&quot;SELECT * FROM transactions WHERE amount = ?&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mf">100.00</span><span class="p">,)</span>
    <span class="p">)</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">transaction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">transaction</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_refund_updates_transaction_status</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process refund and verify status updated in database.&quot;&quot;&quot;</span>
    <span class="c1"># First create a transaction</span>
    <span class="n">payment_result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
        <span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>
    <span class="n">transaction_id</span> <span class="o">=</span> <span class="n">payment_result</span><span class="p">[</span><span class="s2">&quot;transaction_id&quot;</span><span class="p">]</span>

    <span class="c1"># Then refund it</span>
    <span class="n">refund_result</span> <span class="o">=</span> <span class="n">refund_payment</span><span class="p">(</span>
        <span class="n">transaction_id</span><span class="o">=</span><span class="n">transaction_id</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>

    <span class="k">assert</span> <span class="n">refund_result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>

    <span class="c1"># Verify status updated</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">test_database</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="s2">&quot;SELECT status FROM transactions WHERE id = ?&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">transaction_id</span><span class="p">,)</span>
    <span class="p">)</span>
    <span class="n">status</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;refunded&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">security</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_fraud_detection_blocks_suspicious_pattern</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify fraud detection blocks suspicious transaction patterns.&quot;&quot;&quot;</span>
    <span class="n">card_number</span> <span class="o">=</span> <span class="s2">&quot;4532015112830366&quot;</span>

    <span class="c1"># Attempt 10 rapid transactions (suspicious pattern)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span>
            <span class="n">amount</span><span class="o">=</span><span class="mf">1000.00</span><span class="p">,</span>
            <span class="n">card_number</span><span class="o">=</span><span class="n">card_number</span><span class="p">,</span>
            <span class="n">database</span><span class="o">=</span><span class="n">test_database</span>
        <span class="p">)</span>

    <span class="c1"># 10th transaction should be blocked by fraud detection</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;blocked&quot;</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;reason&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;fraud_detection&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/e2e/test_checkout_flow.py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">End-to-end tests for complete checkout flow.</span>

<span class="sd">All tests in this file should be:</span>
<span class="sd">- Marked as @pytest.mark.e2e</span>
<span class="sd">- Marked as @pytest.mark.slow (full workflow)</span>
<span class="sd">- Marked with all required dependencies</span>
<span class="sd">- Test complete user workflows</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payment_processor</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_cart</span><span class="p">,</span> <span class="n">checkout</span><span class="p">,</span> <span class="n">confirm_order</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">e2e</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_network</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">smoke</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_complete_checkout_flow</span><span class="p">(</span><span class="n">test_database</span><span class="p">,</span> <span class="n">mock_payment_gateway</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test complete checkout flow from cart to confirmation.&quot;&quot;&quot;</span>
    <span class="c1"># 1. Create shopping cart</span>
    <span class="n">cart</span> <span class="o">=</span> <span class="n">create_cart</span><span class="p">(</span><span class="n">items</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;product_id&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;quantity&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;price&quot;</span><span class="p">:</span> <span class="mf">29.99</span><span class="p">},</span>
        <span class="p">{</span><span class="s2">&quot;product_id&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;quantity&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;price&quot;</span><span class="p">:</span> <span class="mf">49.99</span><span class="p">}</span>
    <span class="p">])</span>
    <span class="k">assert</span> <span class="n">cart</span><span class="o">.</span><span class="n">total</span> <span class="o">==</span> <span class="mf">109.97</span>

    <span class="c1"># 2. Process checkout</span>
    <span class="n">checkout_result</span> <span class="o">=</span> <span class="n">checkout</span><span class="p">(</span>
        <span class="n">cart</span><span class="o">=</span><span class="n">cart</span><span class="p">,</span>
        <span class="n">card_number</span><span class="o">=</span><span class="s2">&quot;4532015112830366&quot;</span><span class="p">,</span>
        <span class="n">cvv</span><span class="o">=</span><span class="s2">&quot;123&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">checkout_result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;success&quot;</span>

    <span class="c1"># 3. Verify payment gateway called</span>
    <span class="k">assert</span> <span class="n">mock_payment_gateway</span><span class="o">.</span><span class="n">was_called_with</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">109.97</span><span class="p">)</span>

    <span class="c1"># 4. Confirm order</span>
    <span class="n">order</span> <span class="o">=</span> <span class="n">confirm_order</span><span class="p">(</span>
        <span class="n">checkout_id</span><span class="o">=</span><span class="n">checkout_result</span><span class="p">[</span><span class="s2">&quot;checkout_id&quot;</span><span class="p">],</span>
        <span class="n">database</span><span class="o">=</span><span class="n">test_database</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">order</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="s2">&quot;confirmed&quot;</span>
    <span class="k">assert</span> <span class="n">order</span><span class="o">.</span><span class="n">total</span> <span class="o">==</span> <span class="mf">109.97</span>

    <span class="c1"># 5. Verify database state</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">test_database</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
        <span class="s2">&quot;SELECT * FROM orders WHERE id = ?&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">order</span><span class="o">.</span><span class="n">id</span><span class="p">,)</span>
    <span class="p">)</span>
    <span class="n">db_order</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">db_order</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;confirmed&quot;</span>
</code></pre></div>

<p><strong>Key patterns</strong>:</p>
<ol>
<li><strong>File-level docstring</strong>: Explains what markers should be used</li>
<li><strong>Consistent marker application</strong>: All tests in file follow same pattern</li>
<li><strong>Clear test names</strong>: Describe what's being tested</li>
<li><strong>Appropriate markers</strong>: Match test characteristics</li>
</ol>
<h2 id="iteration-2-enforcing-organization-standards">Iteration 2: Enforcing Organization Standards</h2>
<h3 id="the-scenario_16">The Scenario</h3>
<p>You want to ensure all tests follow your organization standards:</p>
<ul>
<li>Every test has a test type marker (unit/integration/e2e)</li>
<li>Tests in <code>tests/unit/</code> are marked as unit tests</li>
<li>Tests in <code>tests/integration/</code> are marked as integration tests</li>
<li>No test has conflicting markers (e.g., both unit and integration)</li>
</ul>
<h3 id="solution-pytest-hook-for-validation">Solution: Pytest Hook for Validation</h3>
<p>Create a conftest.py hook to enforce standards:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/conftest.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pytest_collection_modifyitems</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">items</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enforce test organization standards:</span>
<span class="sd">    1. Every test must have exactly one test type marker</span>
<span class="sd">    2. Test type marker must match directory structure</span>
<span class="sd">    3. Tests with requires_* markers must not be unit tests</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
        <span class="c1"># Get test file path</span>
        <span class="n">test_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">fspath</span><span class="p">)</span>

        <span class="c1"># Get all markers on this test</span>
        <span class="n">markers</span> <span class="o">=</span> <span class="p">{</span><span class="n">mark</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">mark</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">iter_markers</span><span class="p">()}</span>

        <span class="c1"># Check 1: Must have exactly one test type marker</span>
        <span class="n">test_type_markers</span> <span class="o">=</span> <span class="n">markers</span> <span class="o">&amp;</span> <span class="p">{</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="s2">&quot;integration&quot;</span><span class="p">,</span> <span class="s2">&quot;e2e&quot;</span><span class="p">}</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_type_markers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">nodeid</span><span class="si">}</span><span class="s2">: Missing test type marker (unit/integration/e2e)&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_type_markers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">nodeid</span><span class="si">}</span><span class="s2">: Multiple test type markers: </span><span class="si">{</span><span class="n">test_type_markers</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Check 2: Test type must match directory</span>
        <span class="k">if</span> <span class="s2">&quot;unit&quot;</span> <span class="ow">in</span> <span class="n">markers</span> <span class="ow">and</span> <span class="s2">&quot;tests/unit&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_path</span><span class="p">):</span>
            <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">nodeid</span><span class="si">}</span><span class="s2">: Unit test not in tests/unit/ directory&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;integration&quot;</span> <span class="ow">in</span> <span class="n">markers</span> <span class="ow">and</span> <span class="s2">&quot;tests/integration&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_path</span><span class="p">):</span>
            <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">nodeid</span><span class="si">}</span><span class="s2">: Integration test not in tests/integration/ directory&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;e2e&quot;</span> <span class="ow">in</span> <span class="n">markers</span> <span class="ow">and</span> <span class="s2">&quot;tests/e2e&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_path</span><span class="p">):</span>
            <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">nodeid</span><span class="si">}</span><span class="s2">: E2E test not in tests/e2e/ directory&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Check 3: Unit tests shouldn&#39;t have external dependencies</span>
        <span class="k">if</span> <span class="s2">&quot;unit&quot;</span> <span class="ow">in</span> <span class="n">markers</span><span class="p">:</span>
            <span class="n">dependency_markers</span> <span class="o">=</span> <span class="n">markers</span> <span class="o">&amp;</span> <span class="p">{</span>
                <span class="s2">&quot;requires_database&quot;</span><span class="p">,</span> <span class="s2">&quot;requires_network&quot;</span><span class="p">,</span> <span class="s2">&quot;requires_auth&quot;</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">dependency_markers</span><span class="p">:</span>
                <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">item</span><span class="o">.</span><span class="n">nodeid</span><span class="si">}</span><span class="s2">: Unit test has dependency markers: </span><span class="si">{</span><span class="n">dependency_markers</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

    <span class="c1"># Report all errors</span>
    <span class="k">if</span> <span class="n">errors</span><span class="p">:</span>
        <span class="n">error_message</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
            <span class="s2">&quot;Test organization violations found:&quot;</span><span class="p">,</span>
            <span class="o">*</span><span class="n">errors</span><span class="p">,</span>
            <span class="s2">&quot;&quot;</span><span class="p">,</span>
            <span class="s2">&quot;See tests/README.md for organization standards.&quot;</span>
        <span class="p">])</span>
        <span class="n">pytest</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="n">error_message</span><span class="p">,</span> <span class="n">returncode</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p><strong>Run tests with violations</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span><span class="nv">pytest</span>
<span class="o">========================</span><span class="w"> </span><span class="nb">test</span><span class="w"> </span>session<span class="w"> </span><span class="nv">starts</span><span class="w"> </span><span class="o">========================</span>
Test<span class="w"> </span>organization<span class="w"> </span>violations<span class="w"> </span>found:
tests/unit/test_validation.py::test_validate_with_database:<span class="w"> </span>Unit<span class="w"> </span><span class="nb">test</span><span class="w"> </span>has<span class="w"> </span>dependency<span class="w"> </span>markers:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;requires_database&#39;</span><span class="o">}</span>
tests/integration/test_payment.py::test_process_payment:<span class="w"> </span>Missing<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="nb">type</span><span class="w"> </span>marker<span class="w"> </span><span class="o">(</span>unit/integration/e2e<span class="o">)</span>
tests/unit/test_fraud.py::test_fraud_detection:<span class="w"> </span>Multiple<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="nb">type</span><span class="w"> </span>markers:<span class="w"> </span><span class="o">{</span><span class="s1">&#39;unit&#39;</span>,<span class="w"> </span><span class="s1">&#39;integration&#39;</span><span class="o">}</span>

See<span class="w"> </span>tests/README.md<span class="w"> </span><span class="k">for</span><span class="w"> </span>organization<span class="w"> </span>standards.
</code></pre></div>

<p><strong>What this achieves</strong>:</p>
<ol>
<li>‚úÖ Catches organization violations immediately</li>
<li>‚úÖ Prevents tests from being committed with wrong markers</li>
<li>‚úÖ Enforces consistency across the team</li>
<li>‚úÖ Self-documenting (error messages explain the rules)</li>
</ol>
<h2 id="iteration-3-building-test-execution-strategies">Iteration 3: Building Test Execution Strategies</h2>
<h3 id="the-scenario_17">The Scenario</h3>
<p>Different contexts need different test execution strategies:</p>
<ol>
<li><strong>Local development</strong>: Fast feedback (&lt; 1 second)</li>
<li><strong>Pre-commit hook</strong>: Confidence before committing (&lt; 10 seconds)</li>
<li><strong>CI pull request</strong>: Thorough but fast (&lt; 5 minutes)</li>
<li><strong>CI main branch</strong>: Comprehensive (&lt; 30 minutes)</li>
<li><strong>Nightly build</strong>: Everything including performance (unlimited time)</li>
</ol>
<h3 id="strategy-1-local-development-tdd-workflow">Strategy 1: Local Development (TDD Workflow)</h3>
<p><strong>Goal</strong>: Instant feedback while coding.</p>
<p><strong>Marker expression</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run only fast unit tests</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;unit and fast&quot;</span>
</code></pre></div>

<p><strong>Expected runtime</strong>: &lt; 1 second for 100+ tests</p>
<p><strong>Create a shell alias</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ~/.bashrc or ~/.zshrc</span>
<span class="nb">alias</span><span class="w"> </span><span class="nv">pt</span><span class="o">=</span><span class="s2">&quot;pytest -m &#39;unit and fast&#39; -x&quot;</span><span class="w">  </span><span class="c1"># -x stops on first failure</span>
</code></pre></div>

<p><strong>Usage during TDD</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Write test</span>
$<span class="w"> </span>vim<span class="w"> </span>tests/unit/test_validation.py

<span class="c1"># Run tests (instant feedback)</span>
$<span class="w"> </span>pt

<span class="c1"># Fix code</span>
$<span class="w"> </span>vim<span class="w"> </span>src/payment_processor/validation.py

<span class="c1"># Run tests again</span>
$<span class="w"> </span>pt
</code></pre></div>

<h3 id="strategy-2-pre-commit-hook">Strategy 2: Pre-Commit Hook</h3>
<p><strong>Goal</strong>: Catch issues before committing.</p>
<p><strong>Marker expression</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run unit and integration tests, skip slow e2e</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;(unit or integration) and not slow&quot;</span>
</code></pre></div>

<p><strong>Expected runtime</strong>: 5-10 seconds</p>
<p><strong>Create a git pre-commit hook</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .git/hooks/pre-commit</span>
<span class="c1">#!/bin/bash</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Running pre-commit tests...&quot;</span>

<span class="c1"># Run unit and integration tests</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;(unit or integration) and not slow&quot;</span><span class="w"> </span>--tb<span class="o">=</span>short<span class="w"> </span>-q

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$?</span><span class="w"> </span>-ne<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Tests failed. Commit aborted.&quot;</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Run &#39;pytest -m \&quot;(unit or integration) and not slow\&quot;&#39; to see failures.&quot;</span>
<span class="w">    </span><span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;All tests passed!&quot;</span>
</code></pre></div>

<p><strong>Make it executable</strong>:</p>
<div class="codehilite"><pre><span></span><code>chmod<span class="w"> </span>+x<span class="w"> </span>.git/hooks/pre-commit
</code></pre></div>

<h3 id="strategy-3-ci-pull-request">Strategy 3: CI Pull Request</h3>
<p><strong>Goal</strong>: Thorough testing without performance tests.</p>
<p><strong>Marker expression</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run everything except performance tests</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not performance&quot;</span>
</code></pre></div>

<p><strong>Expected runtime</strong>: 3-5 minutes</p>
<p><strong>GitHub Actions configuration</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/pull-request.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Pull Request Tests</span>

<span class="nt">on</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">pull_request</span><span class="p p-Indicator">]</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">test</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install -e .</span>
<span class="w">          </span><span class="no">pip install pytest pytest-cov</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pytest -m &quot;not performance&quot; \</span>
<span class="w">                 </span><span class="no">--cov=payment_processor \</span>
<span class="w">                 </span><span class="no">--cov-report=xml \</span>
<span class="w">                 </span><span class="no">--cov-report=term-missing \</span>
<span class="w">                 </span><span class="no">-v</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload coverage</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">codecov/codecov-action@v3</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./coverage.xml</span>
</code></pre></div>

<h3 id="strategy-4-ci-main-branch">Strategy 4: CI Main Branch</h3>
<p><strong>Goal</strong>: Comprehensive testing including smoke tests.</p>
<p><strong>Marker expression</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run everything except performance tests, but ensure smoke tests pass first</span>
pytest<span class="w"> </span>-m<span class="w"> </span>smoke<span class="w"> </span>--tb<span class="o">=</span>short<span class="w"> </span>-x<span class="w">  </span><span class="c1"># Stop on first smoke test failure</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not performance&quot;</span><span class="w">     </span><span class="c1"># Then run everything else</span>
</code></pre></div>

<p><strong>Expected runtime</strong>: 10-30 minutes</p>
<p><strong>GitHub Actions configuration</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/main.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Main Branch Tests</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="nv">main</span><span class="p p-Indicator">]</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">smoke-tests</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pip install -e .</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run smoke tests</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -m smoke --tb=short -x</span>

<span class="w">  </span><span class="nt">full-suite</span><span class="p">:</span>
<span class="w">    </span><span class="nt">needs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">smoke-tests</span><span class="w">  </span><span class="c1"># Only run if smoke tests pass</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pip install -e .</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run full test suite</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -m &quot;not performance&quot; -v</span>
</code></pre></div>

<h3 id="strategy-5-nightly-build">Strategy 5: Nightly Build</h3>
<p><strong>Goal</strong>: Run everything including performance tests.</p>
<p><strong>Marker expression</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run absolutely everything</span>
pytest<span class="w"> </span>-v
</code></pre></div>

<p><strong>Expected runtime</strong>: Unlimited (could be hours for performance tests)</p>
<p><strong>GitHub Actions configuration</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/nightly.yml</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Nightly Build</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">schedule</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">cron</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;0</span><span class="nv"> </span><span class="s">2</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*</span><span class="nv"> </span><span class="s">*&#39;</span><span class="w">  </span><span class="c1"># Run at 2 AM UTC every day</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">full-suite-with-performance</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">timeout-minutes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">120</span><span class="w">  </span><span class="c1"># 2 hour timeout</span>

<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/checkout@v3</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Python</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/setup-python@v4</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">python-version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.11&#39;</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pip install -e .</span>
<span class="w">          </span><span class="no">pip install pytest pytest-benchmark</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run all tests including performance</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest -v --benchmark-only</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Generate test report</span>
<span class="w">        </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">always()</span>
<span class="w">        </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">          </span><span class="no">pytest --html=report.html --self-contained-html</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Upload test report</span>
<span class="w">        </span><span class="nt">if</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">always()</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">actions/upload-artifact@v3</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">test-report</span>
<span class="w">          </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">report.html</span>
</code></pre></div>

<h2 id="iteration-4-documentation-and-onboarding">Iteration 4: Documentation and Onboarding</h2>
<h3 id="the-scenario_18">The Scenario</h3>
<p>A new developer joins your team. They need to understand:</p>
<ul>
<li>How tests are organized</li>
<li>Which markers to use</li>
<li>How to run tests locally</li>
<li>How CI works</li>
</ul>
<h3 id="solution-comprehensive-testing-documentation">Solution: Comprehensive Testing Documentation</h3>
<p>Create a testing guide:</p>
<div class="codehilite"><pre><span></span><code><span class="gh"># Testing Guide</span>

<span class="gu">## Test Organization</span>

Our test suite is organized by test type and feature:
</code></pre></div>

<p>tests/
‚îú‚îÄ‚îÄ unit/           # Fast, isolated tests (&lt; 100ms)
‚îú‚îÄ‚îÄ integration/    # Tests with database/API (1-5s)
‚îú‚îÄ‚îÄ e2e/           # Full workflow tests (5-30s)
‚îî‚îÄ‚îÄ performance/   # Benchmarks and load tests (30s+)</p>
<div class="codehilite"><pre><span></span><code><span class="err">##</span><span class="w"> </span><span class="n">Marker</span><span class="w"> </span><span class="n">Taxonomy</span>

<span class="err">###</span><span class="w"> </span><span class="n">Test</span><span class="w"> </span><span class="n">Types</span><span class="w"> </span><span class="p">(</span><span class="n">Required</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nf">Choose</span><span class="w"> </span><span class="n">One</span><span class="p">)</span>

<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">unit</span><span class="err">`:</span><span class="w"> </span><span class="n">Fast</span><span class="w"> </span><span class="n">unit</span><span class="w"> </span><span class="n">tests</span><span class="p">,</span><span class="w"> </span><span class="k">no</span><span class="w"> </span><span class="k">external</span><span class="w"> </span><span class="n">dependencies</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">integration</span><span class="err">`:</span><span class="w"> </span><span class="n">Integration</span><span class="w"> </span><span class="n">tests</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="k">database</span><span class="o">/</span><span class="n">APIs</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">e2e</span><span class="err">`:</span><span class="w"> </span><span class="k">End</span><span class="o">-</span><span class="k">to</span><span class="o">-</span><span class="k">end</span><span class="w"> </span><span class="n">workflow</span><span class="w"> </span><span class="n">tests</span>

<span class="err">###</span><span class="w"> </span><span class="n">Speed</span><span class="w"> </span><span class="p">(</span><span class="n">Optional</span><span class="p">)</span>

<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">fast</span><span class="err">`:</span><span class="w"> </span><span class="n">Tests</span><span class="w"> </span><span class="k">under</span><span class="w"> </span><span class="mi">100</span><span class="n">ms</span><span class="w"> </span><span class="p">(</span><span class="k">for</span><span class="w"> </span><span class="n">TDD</span><span class="w"> </span><span class="n">workflow</span><span class="p">)</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">slow</span><span class="err">`:</span><span class="w"> </span><span class="n">Tests</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">second</span>

<span class="err">###</span><span class="w"> </span><span class="n">Categories</span><span class="w"> </span><span class="p">(</span><span class="n">Optional</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Multiple</span><span class="w"> </span><span class="n">Allowed</span><span class="p">)</span>

<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">security</span><span class="err">`:</span><span class="w"> </span><span class="n">Security</span><span class="o">-</span><span class="n">related</span><span class="w"> </span><span class="n">tests</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">performance</span><span class="err">`:</span><span class="w"> </span><span class="n">Performance</span><span class="w"> </span><span class="n">benchmarks</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">smoke</span><span class="err">`:</span><span class="w"> </span><span class="n">Critical</span><span class="w"> </span><span class="k">path</span><span class="w"> </span><span class="n">tests</span>

<span class="err">###</span><span class="w"> </span><span class="n">Requirements</span><span class="w"> </span><span class="p">(</span><span class="n">Optional</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Multiple</span><span class="w"> </span><span class="n">Allowed</span><span class="p">)</span>

<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">requires_database</span><span class="err">`:</span><span class="w"> </span><span class="n">Needs</span><span class="w"> </span><span class="k">database</span><span class="w"> </span><span class="k">connection</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">requires_network</span><span class="err">`:</span><span class="w"> </span><span class="n">Needs</span><span class="w"> </span><span class="n">network</span><span class="w"> </span><span class="n">access</span>
<span class="o">-</span><span class="w"> </span><span class="err">`</span><span class="nv">@pytest</span><span class="p">.</span><span class="n">mark</span><span class="p">.</span><span class="n">requires_auth</span><span class="err">`:</span><span class="w"> </span><span class="n">Needs</span><span class="w"> </span><span class="n">authentication</span>

<span class="err">##</span><span class="w"> </span><span class="n">Running</span><span class="w"> </span><span class="n">Tests</span>

<span class="err">###</span><span class="w"> </span><span class="n">During</span><span class="w"> </span><span class="n">Development</span><span class="w"> </span><span class="p">(</span><span class="n">TDD</span><span class="p">)</span>

<span class="err">```</span><span class="n">bash</span>
<span class="err">#</span><span class="w"> </span><span class="n">Fast</span><span class="w"> </span><span class="n">feedback</span><span class="w"> </span><span class="p">(</span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">second</span><span class="p">)</span>
<span class="n">pytest</span><span class="w"> </span><span class="o">-</span><span class="n">m</span><span class="w"> </span><span class="ss">&quot;unit and fast&quot;</span>

<span class="err">#</span><span class="w"> </span><span class="ow">Or</span><span class="w"> </span><span class="k">use</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">alias</span>
<span class="n">pt</span>
</code></pre></div>

<h3 id="before-committing">Before Committing</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Run unit and integration tests (5-10 seconds)</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;(unit or integration) and not slow&quot;</span>

<span class="c1"># Or use the Makefile</span>
make<span class="w"> </span>test-commit
</code></pre></div>

<h3 id="running-specific-test-types">Running Specific Test Types</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Unit tests only</span>
pytest<span class="w"> </span>-m<span class="w"> </span>unit

<span class="c1"># Integration tests only</span>
pytest<span class="w"> </span>-m<span class="w"> </span>integration

<span class="c1"># Security tests only</span>
pytest<span class="w"> </span>-m<span class="w"> </span>security

<span class="c1"># Everything except performance</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not performance&quot;</span>
</code></pre></div>

<h3 id="running-tests-for-specific-features">Running Tests for Specific Features</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># All tests for payment processing</span>
pytest<span class="w"> </span>tests/unit/test_processing.py<span class="w"> </span>tests/integration/test_payment_flow.py

<span class="c1"># Or use keyword filter</span>
pytest<span class="w"> </span>-k<span class="w"> </span>payment
</code></pre></div>

<h2 id="writing-new-tests">Writing New Tests</h2>
<h3 id="1-choose-the-right-test-type">1. Choose the Right Test Type</h3>
<p><strong>Unit Test</strong> if:
- Testing a single function/method
- No external dependencies
- Should run in &lt; 100ms</p>
<p><strong>Integration Test</strong> if:
- Testing component interactions
- Uses database or external APIs
- Takes 1-5 seconds</p>
<p><strong>E2E Test</strong> if:
- Testing complete user workflow
- Involves multiple components
- Takes 5+ seconds</p>
<h3 id="2-place-test-in-correct-directory">2. Place Test in Correct Directory</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Unit test ‚Üí tests/unit/test_feature.py</span>
<span class="c1"># Integration test ‚Üí tests/integration/test_feature.py</span>
<span class="c1"># E2E test ‚Üí tests/e2e/test_feature.py</span>
</code></pre></div>

<h3 id="3-apply-correct-markers">3. Apply Correct Markers</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># Unit test template</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">fast</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">():</span>
    <span class="k">pass</span>

<span class="c1"># Integration test template</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">integration</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="c1"># E2E test template</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">e2e</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_database</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">requires_network</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_something</span><span class="p">(</span><span class="n">test_database</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div>

<h3 id="4-follow-naming-conventions">4. Follow Naming Conventions</h3>
<ul>
<li>Test files: <code>test_*.py</code></li>
<li>Test functions: <code>test_*</code></li>
<li>Test names should describe what's being tested:</li>
<li>‚úÖ <code>test_validate_credit_card_rejects_invalid_checksum</code></li>
<li>‚ùå <code>test_validation_1</code></li>
</ul>
<h2 id="cicd-pipeline">CI/CD Pipeline</h2>
<h3 id="pull-requests">Pull Requests</h3>
<ul>
<li>Runs all tests except performance tests</li>
<li>Must pass before merging</li>
<li>Runtime: ~5 minutes</li>
</ul>
<h3 id="main-branch">Main Branch</h3>
<ul>
<li>Runs smoke tests first (fail fast)</li>
<li>Then runs full suite except performance</li>
<li>Runtime: ~15 minutes</li>
</ul>
<h3 id="nightly-builds">Nightly Builds</h3>
<ul>
<li>Runs everything including performance tests</li>
<li>Generates detailed test reports</li>
<li>Runtime: ~2 hours</li>
</ul>
<h2 id="troubleshooting">Troubleshooting</h2>
<h3 id="tests-fail-locally-but-pass-in-ci">Tests Fail Locally But Pass in CI</h3>
<ol>
<li>Check if you have all dependencies installed</li>
<li>Verify database is running (for integration tests)</li>
<li>Check environment variables</li>
</ol>
<h3 id="tests-are-slow">Tests Are Slow</h3>
<ol>
<li>Check if test has correct markers (should it be marked <code>slow</code>?)</li>
<li>Consider if test should be unit test instead of integration</li>
<li>Look for unnecessary database operations</li>
</ol>
<h3 id="test-organization-violations">Test Organization Violations</h3>
<p>If you see errors like "Unit test has dependency markers", it means:</p>
<ol>
<li>Test is marked as <code>unit</code> but uses external dependencies</li>
<li>Either change test to <code>integration</code> or remove dependencies</li>
<li>See conftest.py for full validation rules</li>
</ol>
<h2 id="getting-help">Getting Help</h2>
<ul>
<li>Read this guide first</li>
<li>Check existing tests for examples</li>
<li>Ask in #testing Slack channel</li>
<li>Review test organization standards in conftest.py</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="c1">## Iteration 5: Measuring and Improving Test Organization</span>

<span class="c1">### The Scenario</span>

<span class="n">You</span> <span class="n">want</span> <span class="n">to</span> <span class="n">track</span> <span class="n">test</span> <span class="n">organization</span> <span class="n">metrics</span><span class="p">:</span>

<span class="o">-</span> <span class="n">How</span> <span class="n">many</span> <span class="n">tests</span> <span class="n">of</span> <span class="n">each</span> <span class="nb">type</span><span class="err">?</span>
<span class="o">-</span> <span class="n">What</span><span class="s1">&#39;s the average test runtime by type?</span>
<span class="o">-</span> <span class="n">Are</span> <span class="n">tests</span> <span class="n">properly</span> <span class="n">categorized</span><span class="err">?</span>
<span class="o">-</span> <span class="n">Which</span> <span class="n">tests</span> <span class="n">are</span> <span class="n">slowest</span><span class="err">?</span>

<span class="c1">### Solution: Test Metrics Collection</span>

<span class="n">Create</span> <span class="n">a</span> <span class="n">script</span> <span class="n">to</span> <span class="n">analyze</span> <span class="n">test</span> <span class="n">organization</span><span class="p">:</span>

<span class="err">```</span><span class="n">python</span>
<span class="c1"># scripts/analyze_tests.py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Analyze test suite organization and generate metrics.</span>

<span class="sd">Usage:</span>
<span class="sd">    python scripts/analyze_tests.py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span><span class="w"> </span><span class="nf">collect_test_info</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Collect information about all tests using pytest.&quot;&quot;&quot;</span>
    <span class="c1"># Run pytest with JSON report</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="p">[</span><span class="s2">&quot;pytest&quot;</span><span class="p">,</span> <span class="s2">&quot;--collect-only&quot;</span><span class="p">,</span> <span class="s2">&quot;-q&quot;</span><span class="p">,</span> <span class="s2">&quot;--json-report&quot;</span><span class="p">,</span> <span class="s2">&quot;--json-report-file=test_report.json&quot;</span><span class="p">],</span>
        <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">text</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Parse JSON report</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;test_report.json&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">report</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">report</span><span class="p">[</span><span class="s2">&quot;tests&quot;</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">analyze_markers</span><span class="p">(</span><span class="n">tests</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Analyze marker usage across tests.&quot;&quot;&quot;</span>
    <span class="n">marker_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">test_type_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">tests_by_type</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">tests</span><span class="p">:</span>
        <span class="n">markers</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span> <span class="p">[])</span>

        <span class="c1"># Count all markers</span>
        <span class="k">for</span> <span class="n">marker</span> <span class="ow">in</span> <span class="n">markers</span><span class="p">:</span>
            <span class="n">marker_counts</span><span class="p">[</span><span class="n">marker</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Count test types</span>
        <span class="n">test_types</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="s2">&quot;integration&quot;</span><span class="p">,</span> <span class="s2">&quot;e2e&quot;</span><span class="p">}</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">markers</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_types</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">test_type</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_types</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">test_type_counts</span><span class="p">[</span><span class="n">test_type</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">tests_by_type</span><span class="p">[</span><span class="n">test_type</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s2">&quot;nodeid&quot;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_types</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">test_type_counts</span><span class="p">[</span><span class="s2">&quot;untyped&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">test_type_counts</span><span class="p">[</span><span class="s2">&quot;multiple_types&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;marker_counts&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">marker_counts</span><span class="p">),</span>
        <span class="s2">&quot;test_type_counts&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">test_type_counts</span><span class="p">),</span>
        <span class="s2">&quot;tests_by_type&quot;</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tests_by_type</span><span class="p">)</span>
    <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">analyze_directory_structure</span><span class="p">(</span><span class="n">tests</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Analyze test distribution across directories.&quot;&quot;&quot;</span>
    <span class="n">dir_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">tests</span><span class="p">:</span>
        <span class="n">test_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s2">&quot;nodeid&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">directory</span> <span class="o">=</span> <span class="n">test_path</span><span class="o">.</span><span class="n">parent</span>
        <span class="n">dir_counts</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">directory</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">dir_counts</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">generate_report</span><span class="p">(</span><span class="n">analysis</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate human-readable report.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TEST SUITE ORGANIZATION REPORT&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## Test Type Distribution&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">test_type_counts</span> <span class="o">=</span> <span class="n">analysis</span><span class="p">[</span><span class="s2">&quot;test_type_counts&quot;</span><span class="p">]</span>
    <span class="n">total_tests</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">test_type_counts</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">test_type</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">test_type_counts</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="n">percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">count</span> <span class="o">/</span> <span class="n">total_tests</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">test_type</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">percentage</span><span class="si">:</span><span class="s2">5.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;Total&#39;</span><span class="si">:</span><span class="s2">20s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">total_tests</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## Marker Usage&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">marker_counts</span> <span class="o">=</span> <span class="n">analysis</span><span class="p">[</span><span class="s2">&quot;marker_counts&quot;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">marker</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">marker_counts</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">marker</span><span class="si">:</span><span class="s2">30s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## Directory Distribution&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">dir_counts</span> <span class="o">=</span> <span class="n">analysis</span><span class="p">[</span><span class="s2">&quot;directory_distribution&quot;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">directory</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dir_counts</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">directory</span><span class="si">:</span><span class="s2">40s</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Warnings</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">## Warnings&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">test_type_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;untyped&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚ö†Ô∏è  </span><span class="si">{</span><span class="n">test_type_counts</span><span class="p">[</span><span class="s1">&#39;untyped&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> tests missing test type marker&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">test_type_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;multiple_types&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;‚ö†Ô∏è  </span><span class="si">{</span><span class="n">test_type_counts</span><span class="p">[</span><span class="s1">&#39;multiple_types&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> tests have multiple type markers&quot;</span><span class="p">)</span>

    <span class="c1"># Calculate test pyramid ratio</span>
    <span class="n">unit_count</span> <span class="o">=</span> <span class="n">test_type_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;unit&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">integration_count</span> <span class="o">=</span> <span class="n">test_type_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;integration&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">e2e_count</span> <span class="o">=</span> <span class="n">test_type_counts</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;e2e&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">e2e_count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">pyramid_ratio</span> <span class="o">=</span> <span class="n">unit_count</span> <span class="o">/</span> <span class="n">e2e_count</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìä Test Pyramid Ratio (unit:e2e): </span><span class="si">{</span><span class="n">pyramid_ratio</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">:1&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pyramid_ratio</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   ‚ö†Ô∏è  Consider adding more unit tests (recommended ratio: 10:1)&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">pyramid_ratio</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   ‚úÖ Good test pyramid shape&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Collecting test information...&quot;</span><span class="p">)</span>
    <span class="n">tests</span> <span class="o">=</span> <span class="n">collect_test_info</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Analyzing markers...&quot;</span><span class="p">)</span>
    <span class="n">marker_analysis</span> <span class="o">=</span> <span class="n">analyze_markers</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Analyzing directory structure...&quot;</span><span class="p">)</span>
    <span class="n">dir_analysis</span> <span class="o">=</span> <span class="n">analyze_directory_structure</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

    <span class="n">analysis</span> <span class="o">=</span> <span class="p">{</span>
        <span class="o">**</span><span class="n">marker_analysis</span><span class="p">,</span>
        <span class="s2">&quot;directory_distribution&quot;</span><span class="p">:</span> <span class="n">dir_analysis</span>
    <span class="p">}</span>

    <span class="n">generate_report</span><span class="p">(</span><span class="n">analysis</span><span class="p">)</span>
</code></pre></div>

<p><strong>Run the analysis</strong>:</p>
<div class="codehilite"><pre><span></span><code>$<span class="w"> </span>python<span class="w"> </span>scripts/analyze_tests.py
Collecting<span class="w"> </span><span class="nb">test</span><span class="w"> </span>information...
Analyzing<span class="w"> </span>markers...
Analyzing<span class="w"> </span>directory<span class="w"> </span>structure...
<span class="o">============================================================</span>
TEST<span class="w"> </span>SUITE<span class="w"> </span>ORGANIZATION<span class="w"> </span><span class="nv">REPORT</span>
<span class="o">============================================================</span>

<span class="c1">## Test Type Distribution</span>
------------------------------------------------------------
unit<span class="w">                </span>:<span class="w">  </span><span class="m">320</span><span class="w"> </span><span class="o">(</span><span class="w"> </span><span class="m">64</span>.0%<span class="o">)</span>
integration<span class="w">         </span>:<span class="w">  </span><span class="m">150</span><span class="w"> </span><span class="o">(</span><span class="w"> </span><span class="m">30</span>.0%<span class="o">)</span>
e2e<span class="w">                 </span>:<span class="w">   </span><span class="m">25</span><span class="w"> </span><span class="o">(</span><span class="w">  </span><span class="m">5</span>.0%<span class="o">)</span>
untyped<span class="w">             </span>:<span class="w">    </span><span class="m">5</span><span class="w"> </span><span class="o">(</span><span class="w">  </span><span class="m">1</span>.0%<span class="o">)</span>

Total<span class="w">               </span>:<span class="w">  </span><span class="m">500</span>

<span class="c1">## Marker Usage</span>
------------------------------------------------------------
unit<span class="w">                              </span>:<span class="w">  </span><span class="m">320</span>
integration<span class="w">                       </span>:<span class="w">  </span><span class="m">150</span>
fast<span class="w">                              </span>:<span class="w">  </span><span class="m">280</span>
slow<span class="w">                              </span>:<span class="w">  </span><span class="m">120</span>
requires_database<span class="w">                 </span>:<span class="w">  </span><span class="m">175</span>
security<span class="w">                          </span>:<span class="w">   </span><span class="m">45</span>
smoke<span class="w">                             </span>:<span class="w">   </span><span class="m">15</span>
e2e<span class="w">                               </span>:<span class="w">   </span><span class="m">25</span>
requires_network<span class="w">                  </span>:<span class="w">   </span><span class="m">30</span>
performance<span class="w">                       </span>:<span class="w">   </span><span class="m">10</span>

<span class="c1">## Directory Distribution</span>
------------------------------------------------------------
tests/unit<span class="w">                        </span>:<span class="w">  </span><span class="m">320</span>
tests/integration<span class="w">                 </span>:<span class="w">  </span><span class="m">150</span>
tests/e2e<span class="w">                         </span>:<span class="w">   </span><span class="m">25</span>
tests/performance<span class="w">                 </span>:<span class="w">   </span><span class="m">10</span>

<span class="c1">## Warnings</span>
------------------------------------------------------------
‚ö†Ô∏è<span class="w">  </span><span class="m">5</span><span class="w"> </span>tests<span class="w"> </span>missing<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="nb">type</span><span class="w"> </span>marker

üìä<span class="w"> </span>Test<span class="w"> </span>Pyramid<span class="w"> </span>Ratio<span class="w"> </span><span class="o">(</span>unit:e2e<span class="o">)</span>:<span class="w"> </span><span class="m">12</span>.8:1
<span class="w">   </span>‚úÖ<span class="w"> </span>Good<span class="w"> </span><span class="nb">test</span><span class="w"> </span>pyramid<span class="w"> </span>shape
</code></pre></div>

<p><strong>What this reveals</strong>:</p>
<ol>
<li><strong>Test distribution</strong>: 64% unit, 30% integration, 5% e2e (healthy pyramid)</li>
<li><strong>Marker usage</strong>: Most common markers and their frequency</li>
<li><strong>Directory alignment</strong>: Tests are in correct directories</li>
<li><strong>Issues</strong>: 5 tests need type markers</li>
<li><strong>Test pyramid</strong>: Good ratio of unit to e2e tests</li>
</ol>
<h2 id="best-practices-summary">Best Practices Summary</h2>
<h3 id="1-establish-clear-categories">1. Establish Clear Categories</h3>
<p><strong>Do</strong>:
- Define 2-3 primary dimensions (type, speed, category)
- Make test types mutually exclusive
- Document what each marker means</p>
<p><strong>Don't</strong>:
- Create too many markers (causes confusion)
- Use ambiguous marker names
- Let markers overlap in meaning</p>
<h3 id="2-align-structure-with-markers">2. Align Structure with Markers</h3>
<p><strong>Do</strong>:
- Organize files by test type (unit/, integration/, e2e/)
- Use markers to add cross-cutting concerns (security, performance)
- Keep related tests together</p>
<p><strong>Don't</strong>:
- Put unit tests in integration/ directory
- Scatter related tests across many files
- Rely solely on markers for organization</p>
<h3 id="3-enforce-standards">3. Enforce Standards</h3>
<p><strong>Do</strong>:
- Use pytest hooks to validate marker usage
- Fail CI if standards violated
- Document standards clearly</p>
<p><strong>Don't</strong>:
- Let standards drift over time
- Make standards too strict (blocks productivity)
- Enforce without documentation</p>
<h3 id="4-optimize-for-common-workflows">4. Optimize for Common Workflows</h3>
<p><strong>Do</strong>:
- Create aliases for common test runs
- Configure CI for different contexts
- Measure and optimize slow tests</p>
<p><strong>Don't</strong>:
- Run full suite for every change
- Ignore slow tests (they accumulate)
- Make developers wait for feedback</p>
<h3 id="5-measure-and-improve">5. Measure and Improve</h3>
<p><strong>Do</strong>:
- Track test metrics over time
- Review test organization regularly
- Refactor tests as project evolves</p>
<p><strong>Don't</strong>:
- Let test suite grow without review
- Ignore test pyramid violations
- Keep obsolete tests</p>
<h2 id="what-youve-learned_5">What You've Learned</h2>
<p>Marker-based test organization provides a scalable framework for managing large test suites:</p>
<ol>
<li><strong>Test taxonomy</strong>: Define clear categories (type, speed, category, requirements)</li>
<li><strong>File structure</strong>: Organize by test type, use markers for cross-cutting concerns</li>
<li><strong>Enforcement</strong>: Use pytest hooks to validate standards</li>
<li><strong>Execution strategies</strong>: Different contexts need different test subsets</li>
<li><strong>Documentation</strong>: Comprehensive guides help team members</li>
<li><strong>Metrics</strong>: Track organization health over time</li>
</ol>
<p><strong>Key insights</strong>:</p>
<ul>
<li>Good organization scales from 10 to 10,000 tests</li>
<li>Markers complement (don't replace) file structure</li>
<li>Enforcement prevents drift over time</li>
<li>Different contexts need different test execution strategies</li>
<li>Measurement reveals organization issues</li>
</ul>
<p><strong>The journey complete</strong>: You've learned to use markers to organize tests from simple categorization to comprehensive test suite management. This foundation enables efficient testing at any scale.</p>
        </div>
        <div class="footer">
            Generated on 2025-12-03 10:37:00 | Made with ‚ù§Ô∏è by GitHub Pages Generator
        </div>
    </div>
    <script>
        // Syntax highlighting for code blocks
        document.addEventListener('DOMContentLoaded', (event) => {
            // Highlight code blocks
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightElement(block);
            });
            
            // Add copy buttons to code blocks
            document.querySelectorAll('pre').forEach((pre) => {
                const button = document.createElement('button');
                button.className = 'copy-btn';
                button.textContent = 'Copy';
                
                button.addEventListener('click', () => {
                    const code = pre.querySelector('code').textContent;
                    navigator.clipboard.writeText(code).then(() => {
                        button.textContent = 'Copied!';
                        button.classList.add('copied');
                        setTimeout(() => {
                            button.textContent = 'Copy';
                            button.classList.remove('copied');
                        }, 2000);
                    }).catch(err => {
                        console.error('Failed to copy:', err);
                        button.textContent = 'Error';
                        setTimeout(() => {
                            button.textContent = 'Copy';
                        }, 2000);
                    });
                });
                
                pre.appendChild(button);
            });
        });
    </script>
</body>
</html>