<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>03 Setting Up Your Testing Environment</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <style>
        :root {
            --primary: #6366f1;
            --primary-dark: #4f46e5;
            --secondary: #8b5cf6;
            --bg-main: #0f172a;
            --bg-card: #1e293b;
            --bg-code: #0f172a;
            --text-primary: #f1f5f9;
            --text-secondary: #94a3b8;
            --border: #334155;
            --accent: #06b6d4;
            --success: #10b981;
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body { 
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            line-height: 1.7; 
            color: var(--text-primary); 
            background: var(--bg-main);
        }
        
        .container { 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px; 
        }
        
        .home-btn { 
            position: fixed; 
            top: 20px; 
            right: 20px; 
            background: var(--accent);
            color: white; 
            width: 50px;
            height: 50px;
            border-radius: 50%;
            text-decoration: none; 
            z-index: 1000;
            box-shadow: 0 4px 20px rgba(6, 182, 212, 0.4);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            font-size: 24px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .home-btn:hover { 
            background: #0891b2;
            transform: translateY(-2px);
            box-shadow: 0 8px 30px rgba(6, 182, 212, 0.5);
        }
        
        .breadcrumb { 
            background: var(--bg-card);
            padding: 12px 0; 
            margin-bottom: 24px; 
            font-size: 14px;
            border-radius: 8px;
            border: 1px solid var(--border);
        }
        
        .breadcrumb a { 
            color: var(--accent);
            text-decoration: none;
            transition: color 0.2s;
        }
        
        .breadcrumb a:hover { 
            color: var(--primary);
            text-decoration: underline;
        }
        
        .content { 
            background: var(--bg-card);
            padding: 3rem; 
            border-radius: 16px; 
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            border: 1px solid var(--border);
        }
        
        .file-list { 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); 
            gap: 1.5rem; 
            margin: 2rem 0; 
        }
        
        .file-item { 
            padding: 1.5rem; 
            border: 1px solid var(--border);
            border-radius: 12px; 
            background: var(--bg-main);
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            position: relative;
            overflow: hidden;
        }
        
        .file-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 3px;
            background: linear-gradient(90deg, var(--primary), var(--secondary));
            opacity: 0;
            transition: opacity 0.3s;
        }
        
        .file-item:hover { 
            transform: translateY(-4px); 
            box-shadow: 0 8px 30px rgba(99, 102, 241, 0.3);
            border-color: var(--primary);
        }
        
        .file-item:hover::before {
            opacity: 1;
        }
        
        .file-item a { 
            color: var(--text-primary);
            text-decoration: none; 
            font-weight: 600; 
            display: block;
            font-size: 1.1rem;
        }
        
        .file-item a:hover { 
            color: var(--primary);
        }
        
        .file-type { 
            font-size: 13px; 
            color: var(--text-secondary);
            margin-top: 8px; 
            font-weight: 500;
        }
        
        /* Code Blocks */
        pre { 
            background: var(--bg-code);
            padding: 1.5rem; 
            border-radius: 12px; 
            overflow-x: auto;
            border: 1px solid var(--border);
            margin: 1.5rem 0;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
            position: relative;
        }
        
        pre code { 
            background: none;
            padding: 0;
            font-family: 'Fira Code', 'Consolas', monospace;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        /* Copy Button */
        .copy-btn {
            position: absolute;
            top: 8px;
            right: 8px;
            background: var(--primary);
            color: white;
            border: none;
            padding: 6px 12px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 12px;
            font-weight: 600;
            transition: all 0.2s;
            opacity: 0.7;
            z-index: 10;
        }
        
        .copy-btn:hover {
            opacity: 1;
            background: var(--primary-dark);
            transform: translateY(-1px);
        }
        
        .copy-btn.copied {
            background: var(--success);
        }
        
        pre:hover .copy-btn {
            opacity: 1;
        }
        
        /* Inline Code */
        code { 
            background: var(--bg-code);
            color: #8b5cf6;
            padding: 3px 8px; 
            border-radius: 6px; 
            font-size: 1.1em;
            font-family: 'Fira Code', 'Consolas', monospace;
            border: 1px solid var(--border);
        }
        
        /* Headings */
        h1, h2, h3, h4, h5, h6 { 
            color: var(--text-primary);
            margin: 2rem 0 1rem 0;
            font-weight: 700;
            letter-spacing: -0.5px;
        }
        
        h1 { 
            font-size: 2.5rem;
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            -webkit-background-clip: text;
            border-bottom: 3px solid var(--primary);
            padding-bottom: 12px;
            margin-bottom: 1.5rem;
        }
        
        h2 { 
            font-size: 2rem;
            color: var(--primary);
            border-bottom: 2px solid var(--border);
            padding-bottom: 8px;
        }
        
        h3 { 
            font-size: 1.5rem;
            color: var(--accent);
        }
        
        /* Links */
        a { 
            color: var(--accent);
            transition: color 0.2s;
        }
        
        a:hover { 
            color: var(--primary);
        }
        
        /* Paragraphs */
        p {
            margin: 1rem 0;
            color: var(--text-secondary);
        }
        
        /* Lists */
        ul, ol {
            margin: 1rem 0;
            padding-left: 2rem;
            color: var(--text-secondary);
        }
        
        li {
            margin: 0.5rem 0;
        }
        
        /* Tables */
        table { 
            border-collapse: collapse;
            width: 100%;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        }
        
        th, td { 
            border: 1px solid var(--border);
            padding: 12px 16px;
            text-align: left;
        }
        
        th { 
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: white;
            font-weight: 600;
        }
        
        tr:hover {
            background: var(--bg-card);
        }
        
        /* Blockquotes */
        blockquote {
            border-left: 4px solid var(--primary);
            padding: 1rem 1.5rem;
            margin: 1.5rem 0;
            background: var(--bg-main);
            border-radius: 0 8px 8px 0;
            color: var(--text-secondary);
            font-style: italic;
        }
        
        /* Horizontal Rule */
        hr {
            border: none;
            border-top: 2px solid var(--border);
            margin: 2rem 0;
        }
        
        .footer { 
            text-align: center; 
            padding: 2rem; 
            color: var(--text-secondary);
            border-top: 1px solid var(--border);
            margin-top: 3rem; 
            font-size: 14px;
        }
        
        /* Scrollbar */
        ::-webkit-scrollbar {
            width: 12px;
            height: 12px;
        }
        
        ::-webkit-scrollbar-track {
            background: var(--bg-main);
        }
        
        ::-webkit-scrollbar-thumb {
            background: var(--border);
            border-radius: 6px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: var(--primary);
        }
        
        @media (max-width: 768px) {
            .container { padding: 10px; }
            .file-list { grid-template-columns: 1fr; }
            .content { padding: 1.5rem; }
            h1 { font-size: 2rem; }
            h2 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>
    <a href="../index.html" class="home-btn">ğŸ </a>
    <div class="container">
        <div class="breadcrumb">
            <div style="padding: 0 20px;">
                <a href="../index.html">ğŸ  Home</a> <span style="color: #64748b;">/</span> <a href="index.html">01 Getting Started</a>
            </div>
        </div>
        <div class="content">
            <h1 id="chapter-3-setting-up-your-testing-environment">Chapter 3: Setting Up Your Testing Environment</h1>
<h2 id="project-structure-best-practices">Project Structure Best Practices</h2>
<h2 id="the-foundation-why-structure-matters">The Foundation: Why Structure Matters</h2>
<p>Before writing a single test, you need to answer a deceptively simple question: <strong>Where do the tests go?</strong></p>
<p>This isn't just about organizationâ€”it's about making pytest work effortlessly. A well-structured project means pytest finds your tests automatically, imports work without path manipulation, and your team can navigate the codebase intuitively.</p>
<p>Let's build a real project structure from scratch and see how each decision affects our testing workflow.</p>
<h2 id="the-reference-project-a-payment-processing-system">The Reference Project: A Payment Processing System</h2>
<p>We'll use a concrete example throughout this chapter: a payment processing library called <code>payflow</code>. This is substantial enough to demonstrate real-world structure challenges but simple enough to understand immediately.</p>
<p>Our <code>payflow</code> library will have:
- Core payment processing logic
- Database models
- API client for external payment gateways
- Utility functions for validation</p>
<p>Here's what most beginners try first:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow.py          # Everything in one file
â””â”€â”€ test_payflow.py     # All tests in one file
</code></pre></div>

<p>This works for exactly one day. Then you add a second module, and suddenly:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># test_payflow.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>  <span class="c1"># Works fine</span>

<span class="c1"># But now you add database.py...</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">database</span><span class="w"> </span><span class="kn">import</span> <span class="n">save_transaction</span>  <span class="c1"># ModuleNotFoundError!</span>
</code></pre></div>

<h3 id="the-problem-pythons-import-system">The Problem: Python's Import System</h3>
<p>Python needs to know where to find your modules. When you run <code>pytest</code>, it doesn't automatically know that <code>database.py</code> is part of your project. You need a <strong>package structure</strong>.</p>
<h2 id="iteration-1-creating-a-package-structure">Iteration 1: Creating a Package Structure</h2>
<p>Let's transform our flat structure into a proper Python package:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/                 # Package directory
â”‚   â”œâ”€â”€ __init__.py         # Makes it a package
â”‚   â”œâ”€â”€ core.py             # Payment processing
â”‚   â”œâ”€â”€ database.py         # Database operations
â”‚   â”œâ”€â”€ api_client.py       # External API calls
â”‚   â””â”€â”€ validators.py       # Input validation
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_core.py
</code></pre></div>

<p>The <code>__init__.py</code> files are crucialâ€”they tell Python "this directory is a package." Even if they're empty, they must exist.</p>
<p>Let's create this structure and write our first test:</p>
<div class="codehilite"><pre><span></span><code>mkdir<span class="w"> </span>-p<span class="w"> </span>payflow_project/payflow
mkdir<span class="w"> </span>-p<span class="w"> </span>payflow_project/tests
<span class="nb">cd</span><span class="w"> </span>payflow_project
touch<span class="w"> </span>payflow/__init__.py<span class="w"> </span>tests/__init__.py
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># payflow/core.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">process_payment</span><span class="p">(</span><span class="n">amount</span><span class="p">,</span> <span class="n">currency</span><span class="o">=</span><span class="s2">&quot;USD&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process a payment transaction.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">amount</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Amount must be positive&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">currency</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;USD&quot;</span><span class="p">,</span> <span class="s2">&quot;EUR&quot;</span><span class="p">,</span> <span class="s2">&quot;GBP&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported currency: </span><span class="si">{</span><span class="n">currency</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Simulate payment processing</span>
    <span class="n">transaction_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;TXN-</span><span class="si">{</span><span class="n">amount</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">currency</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;transaction_id&quot;</span><span class="p">:</span> <span class="n">transaction_id</span><span class="p">,</span>
        <span class="s2">&quot;amount&quot;</span><span class="p">:</span> <span class="n">amount</span><span class="p">,</span>
        <span class="s2">&quot;currency&quot;</span><span class="p">:</span> <span class="n">currency</span><span class="p">,</span>
        <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;completed&quot;</span>
    <span class="p">}</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_successful_payment</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;USD&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
</code></pre></div>

<p>Now run pytest from the project root:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>payflow_project
pytest
</code></pre></div>

<p><strong>Expected output</strong>:</p>
<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 1 item

tests/test_core.py .                                                     [100%]

============================== 1 passed in 0.01s ===============================
</code></pre></div>

<h3 id="what-just-happened">What Just Happened?</h3>
<p>Pytest automatically:
1. Found the <code>tests/</code> directory
2. Discovered <code>test_core.py</code> (starts with <code>test_</code>)
3. Found <code>test_successful_payment()</code> (starts with <code>test_</code>)
4. Imported <code>payflow.core</code> successfully because we're running from the project root</p>
<h2 id="iteration-2-mirroring-source-structure-in-tests">Iteration 2: Mirroring Source Structure in Tests</h2>
<p>As our project grows, we add more modules. Our tests should mirror this structure:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ api_client.py
â”‚   â””â”€â”€ validators.py
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_core.py          # Tests for core.py
    â”œâ”€â”€ test_database.py      # Tests for database.py
    â”œâ”€â”€ test_api_client.py    # Tests for api_client.py
    â””â”€â”€ test_validators.py    # Tests for validators.py
</code></pre></div>

<p><strong>Why mirror the structure?</strong></p>
<ol>
<li><strong>Discoverability</strong>: Finding tests for <code>payflow/database.py</code> is instantâ€”look in <code>tests/test_database.py</code></li>
<li><strong>Maintenance</strong>: When you refactor <code>core.py</code>, you know exactly which test file to update</li>
<li><strong>Team coordination</strong>: No confusion about where new tests should go</li>
</ol>
<p>Let's add a database module and its tests:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># payflow/database.py</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TransactionDB</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simple in-memory transaction storage.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transactions</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save_transaction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transaction_id</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save a transaction to the database.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">transaction_id</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Transaction ID cannot be empty&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transactions</span><span class="p">[</span><span class="n">transaction_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">return</span> <span class="n">transaction_id</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_transaction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transaction_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Retrieve a transaction by ID.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">transaction_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transactions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transaction </span><span class="si">{</span><span class="n">transaction_id</span><span class="si">}</span><span class="s2"> not found&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transactions</span><span class="p">[</span><span class="n">transaction_id</span><span class="p">]</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_database.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.database</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransactionDB</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_save_and_retrieve_transaction</span><span class="p">():</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">TransactionDB</span><span class="p">()</span>

    <span class="n">transaction_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;amount&quot;</span><span class="p">:</span> <span class="mf">100.00</span><span class="p">,</span>
        <span class="s2">&quot;currency&quot;</span><span class="p">:</span> <span class="s2">&quot;USD&quot;</span><span class="p">,</span>
        <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;completed&quot;</span>
    <span class="p">}</span>

    <span class="n">txn_id</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">save_transaction</span><span class="p">(</span><span class="s2">&quot;TXN-001&quot;</span><span class="p">,</span> <span class="n">transaction_data</span><span class="p">)</span>
    <span class="n">retrieved</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">get_transaction</span><span class="p">(</span><span class="n">txn_id</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">retrieved</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
    <span class="k">assert</span> <span class="n">retrieved</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>
</code></pre></div>

<p>Run pytest again:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

tests/test_core.py .                                                     [ 50%]
tests/test_database.py .                                                 [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<p>Pytest found both test files automatically. No configuration needed.</p>
<h2 id="iteration-3-organizing-tests-by-type">Iteration 3: Organizing Tests by Type</h2>
<p>Real projects have different kinds of tests:
- <strong>Unit tests</strong>: Test individual functions in isolation
- <strong>Integration tests</strong>: Test how components work together
- <strong>End-to-end tests</strong>: Test complete workflows</p>
<p>Let's organize by test type:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/
â”‚   â””â”€â”€ ...
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_core.py
    â”‚   â”œâ”€â”€ test_database.py
    â”‚   â””â”€â”€ test_validators.py
    â”œâ”€â”€ integration/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_payment_flow.py
    â”‚   â””â”€â”€ test_database_integration.py
    â””â”€â”€ e2e/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ test_complete_payment.py
</code></pre></div>

<p>Now we can run specific test categories:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>tests/unit/<span class="w">              </span><span class="c1"># Only unit tests</span>
pytest<span class="w"> </span>tests/integration/<span class="w">       </span><span class="c1"># Only integration tests</span>
pytest<span class="w"> </span>tests/e2e/<span class="w">              </span><span class="c1"># Only end-to-end tests</span>
</code></pre></div>

<p>Let's create an integration test that combines our core and database modules:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/integration/test_payment_flow.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.database</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransactionDB</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_is_saved_to_database</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Integration test: payment processing + database storage.&quot;&quot;&quot;</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">TransactionDB</span><span class="p">()</span>

    <span class="c1"># Process payment</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">150.00</span><span class="p">,</span> <span class="s2">&quot;EUR&quot;</span><span class="p">)</span>

    <span class="c1"># Save to database</span>
    <span class="n">txn_id</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;transaction_id&quot;</span><span class="p">]</span>
    <span class="n">db</span><span class="o">.</span><span class="n">save_transaction</span><span class="p">(</span><span class="n">txn_id</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>

    <span class="c1"># Verify it&#39;s retrievable</span>
    <span class="n">saved</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">get_transaction</span><span class="p">(</span><span class="n">txn_id</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">saved</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">150.00</span>
    <span class="k">assert</span> <span class="n">saved</span><span class="p">[</span><span class="s2">&quot;currency&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;EUR&quot;</span>
    <span class="k">assert</span> <span class="n">saved</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>
</code></pre></div>

<p>Run just the integration tests:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>tests/integration/<span class="w"> </span>-v
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 1 item

tests/integration/test_payment_flow.py::test_payment_is_saved_to_database PASSED [100%]

============================== 1 passed in 0.01s ===============================
</code></pre></div>

<h2 id="iteration-4-adding-shared-test-utilities">Iteration 4: Adding Shared Test Utilities</h2>
<p>As tests grow, you'll need shared utilitiesâ€”test data builders, custom assertions, helper functions. Where do these go?</p>
<p><strong>Anti-pattern</strong>: Putting them in test files leads to duplication.</p>
<p><strong>Solution</strong>: Create a <code>tests/helpers/</code> or <code>tests/conftest.py</code> (we'll cover conftest.py in detail in Chapter 4).</p>
<p>For now, let's add shared test data:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/
â”‚   â””â”€â”€ ...
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ helpers/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ builders.py      # Test data builders
    â”œâ”€â”€ unit/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ integration/
        â””â”€â”€ ...
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/helpers/builders.py</span>
<span class="sd">&quot;&quot;&quot;Test data builders for consistent test data creation.&quot;&quot;&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_transaction</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span> <span class="n">currency</span><span class="o">=</span><span class="s2">&quot;USD&quot;</span><span class="p">,</span> <span class="n">status</span><span class="o">=</span><span class="s2">&quot;completed&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build a transaction dictionary with sensible defaults.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;transaction_id&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;TXN-</span><span class="si">{</span><span class="n">amount</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">currency</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="s2">&quot;amount&quot;</span><span class="p">:</span> <span class="n">amount</span><span class="p">,</span>
        <span class="s2">&quot;currency&quot;</span><span class="p">:</span> <span class="n">currency</span><span class="p">,</span>
        <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="n">status</span>
    <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_failed_transaction</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">100.00</span><span class="p">,</span> <span class="n">currency</span><span class="o">=</span><span class="s2">&quot;USD&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build a failed transaction for error testing.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">build_transaction</span><span class="p">(</span><span class="n">amount</span><span class="p">,</span> <span class="n">currency</span><span class="p">,</span> <span class="n">status</span><span class="o">=</span><span class="s2">&quot;failed&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Now tests can use these builders:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/unit/test_database.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.database</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransactionDB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tests.helpers.builders</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_transaction</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_save_transaction_with_builder</span><span class="p">():</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">TransactionDB</span><span class="p">()</span>
    <span class="n">transaction</span> <span class="o">=</span> <span class="n">build_transaction</span><span class="p">(</span><span class="n">amount</span><span class="o">=</span><span class="mf">200.00</span><span class="p">,</span> <span class="n">currency</span><span class="o">=</span><span class="s2">&quot;GBP&quot;</span><span class="p">)</span>

    <span class="n">txn_id</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">save_transaction</span><span class="p">(</span><span class="n">transaction</span><span class="p">[</span><span class="s2">&quot;transaction_id&quot;</span><span class="p">],</span> <span class="n">transaction</span><span class="p">)</span>
    <span class="n">retrieved</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">get_transaction</span><span class="p">(</span><span class="n">txn_id</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">retrieved</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">200.00</span>
    <span class="k">assert</span> <span class="n">retrieved</span><span class="p">[</span><span class="s2">&quot;currency&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;GBP&quot;</span>
</code></pre></div>

<h2 id="the-complete-structure-production-ready">The Complete Structure: Production-Ready</h2>
<p>Here's the final, production-ready structure:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py                 # Package installation (we&#39;ll add this in 3.3)
â”œâ”€â”€ requirements.txt         # Production dependencies
â”œâ”€â”€ requirements-dev.txt     # Development dependencies (pytest, etc.)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ payflow/                 # Source package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ api_client.py
â”‚   â””â”€â”€ validators.py
â””â”€â”€ tests/                   # Test package
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py          # Shared fixtures (Chapter 4)
    â”œâ”€â”€ helpers/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ builders.py
    â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_core.py
    â”‚   â”œâ”€â”€ test_database.py
    â”‚   â”œâ”€â”€ test_api_client.py
    â”‚   â””â”€â”€ test_validators.py
    â”œâ”€â”€ integration/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_payment_flow.py
    â”‚   â””â”€â”€ test_database_integration.py
    â””â”€â”€ e2e/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ test_complete_payment.py
</code></pre></div>

<h2 id="decision-framework-choosing-your-structure">Decision Framework: Choosing Your Structure</h2>
<table>
<thead>
<tr>
<th>Project Size</th>
<th>Recommended Structure</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>Single module (&lt;500 lines)</td>
<td>Flat: <code>project.py</code> + <code>test_project.py</code></td>
<td>Simplicity wins</td>
</tr>
<tr>
<td>Small library (2-5 modules)</td>
<td>Package + mirrored tests</td>
<td>Discoverability matters</td>
</tr>
<tr>
<td>Medium project (6-20 modules)</td>
<td>Package + tests by type</td>
<td>Need to run test categories separately</td>
</tr>
<tr>
<td>Large project (20+ modules)</td>
<td>Package + tests by type + helpers</td>
<td>Shared utilities become essential</td>
</tr>
</tbody>
</table>
<h2 id="key-principles">Key Principles</h2>
<ol>
<li><strong>Mirror source structure in tests</strong>: <code>payflow/core.py</code> â†’ <code>tests/test_core.py</code> or <code>tests/unit/test_core.py</code></li>
<li><strong>Use <code>__init__.py</code> everywhere</strong>: Makes directories importable</li>
<li><strong>Run pytest from project root</strong>: Ensures imports work consistently</li>
<li><strong>Organize by test type when needed</strong>: Unit, integration, e2e</li>
<li><strong>Create helpers for shared utilities</strong>: Avoid duplication across test files</li>
</ol>
<h2 id="common-failure-mode-import-errors">Common Failure Mode: Import Errors</h2>
<p><strong>Symptom</strong>: <code>ModuleNotFoundError: No module named 'payflow'</code></p>
<p><strong>Diagnostic clues</strong>:
- You're running pytest from the wrong directory
- Missing <code>__init__.py</code> files
- Package not installed in development mode (see Section 3.3)</p>
<p><strong>Solution</strong>: Always run pytest from the project root where your package directory is visible.</p>
<h2 id="creating-a-tests-directory">Creating a tests/ Directory</h2>
<h2 id="the-question-where-exactly-do-tests-live">The Question: Where Exactly Do Tests Live?</h2>
<p>You've decided to create a <code>tests/</code> directory. But should it be:
- Inside your package? (<code>payflow/tests/</code>)
- Next to your package? (<code>tests/</code> at project root)
- Somewhere else entirely?</p>
<p>This isn't just aestheticsâ€”it affects imports, packaging, and deployment.</p>
<h2 id="the-reference-implementation-tests-inside-the-package">The Reference Implementation: Tests Inside the Package</h2>
<p>Let's start with what seems intuitiveâ€”putting tests inside the package:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â””â”€â”€ payflow/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ core.py
    â”œâ”€â”€ database.py
    â””â”€â”€ tests/              # Tests inside package
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ test_core.py
        â””â”€â”€ test_database.py
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># payflow/tests/test_core.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>
</code></pre></div>

<p>Run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 1 item

payflow/tests/test_core.py .                                             [100%]

============================== 1 passed in 0.01s ===============================
</code></pre></div>

<p>This works! Tests run successfully. So what's the problem?</p>
<h3 id="the-hidden-problem-tests-in-production">The Hidden Problem: Tests in Production</h3>
<p>Let's package this for distribution:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># setup.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">setuptools</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">find_packages</span>

<span class="n">setup</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;payflow&quot;</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
    <span class="n">packages</span><span class="o">=</span><span class="n">find_packages</span><span class="p">(),</span>  <span class="c1"># Finds all packages</span>
<span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>setup.py<span class="w"> </span>sdist
tar<span class="w"> </span>-tzf<span class="w"> </span>dist/payflow-1.0.0.tar.gz
</code></pre></div>

<div class="codehilite"><pre><span></span><code>payflow-1.0.0/
payflow-1.0.0/payflow/
payflow-1.0.0/payflow/__init__.py
payflow-1.0.0/payflow/core.py
payflow-1.0.0/payflow/database.py
payflow-1.0.0/payflow/tests/          # âš ï¸ Tests included!
payflow-1.0.0/payflow/tests/__init__.py
payflow-1.0.0/payflow/tests/test_core.py
payflow-1.0.0/payflow/tests/test_database.py
</code></pre></div>

<h3 id="diagnostic-analysis-why-this-is-problematic">Diagnostic Analysis: Why This Is Problematic</h3>
<p><strong>The issue</strong>: Your tests are now part of the installed package. When users install <code>payflow</code>, they get:
- Your production code (good)
- Your entire test suite (bad)
- Test dependencies like pytest (bad)
- Test data files (bad)</p>
<p><strong>Consequences</strong>:
1. <strong>Bloated installations</strong>: Users download unnecessary test code
2. <strong>Namespace pollution</strong>: <code>from payflow.tests import ...</code> is possible but meaningless
3. <strong>Dependency confusion</strong>: Test dependencies might conflict with user code
4. <strong>Security concerns</strong>: Test code might contain credentials or test data</p>
<p><strong>What we need</strong>: Tests that run during development but don't ship to users.</p>
<h2 id="iteration-1-tests-outside-the-package">Iteration 1: Tests Outside the Package</h2>
<p>Move tests to the project root, next to the package:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/                # Source package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â””â”€â”€ database.py
â””â”€â”€ tests/                  # Tests outside package
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_core.py
    â””â”€â”€ test_database.py
</code></pre></div>

<p>The imports remain identical:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>  <span class="c1"># Same import!</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>
</code></pre></div>

<p>Now package it:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>setup.py<span class="w"> </span>sdist
tar<span class="w"> </span>-tzf<span class="w"> </span>dist/payflow-1.0.0.tar.gz
</code></pre></div>

<div class="codehilite"><pre><span></span><code>payflow-1.0.0/
payflow-1.0.0/payflow/
payflow-1.0.0/payflow/__init__.py
payflow-1.0.0/payflow/core.py
payflow-1.0.0/payflow/database.py
# âœ… No tests/ directory!
</code></pre></div>

<p><strong>Perfect</strong>. Tests are excluded from the distribution automatically because <code>find_packages()</code> only finds packages inside the source directory.</p>
<h3 id="when-to-use-each-approach">When to Use Each Approach</h3>
<table>
<thead>
<tr>
<th>Approach</th>
<th>Use When</th>
<th>Avoid When</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tests inside package (<code>payflow/tests/</code>)</td>
<td>Never recommended</td>
<td>Alwaysâ€”tests shouldn't ship to users</td>
</tr>
<tr>
<td>Tests outside package (<code>tests/</code> at root)</td>
<td>Alwaysâ€”this is the standard</td>
<td>You're building a single-file script</td>
</tr>
</tbody>
</table>
<h2 id="iteration-2-the-__init__py-question">Iteration 2: The <code>__init__.py</code> Question</h2>
<p>Should <code>tests/__init__.py</code> exist?</p>
<p><strong>Two schools of thought</strong>:</p>
<ol>
<li><strong>With <code>__init__.py</code></strong>: Makes <code>tests/</code> a package</li>
<li><strong>Without <code>__init__.py</code></strong>: Keeps <code>tests/</code> as a simple directory</li>
</ol>
<p>Let's test both:</p>
<div class="codehilite"><pre><span></span><code># Approach 1: tests/ is a package
tests/
â”œâ”€â”€ __init__.py          # Present
â”œâ”€â”€ test_core.py
â””â”€â”€ helpers/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ builders.py
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tests.helpers.builders</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_transaction</span>  <span class="c1"># Works</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_with_builder</span><span class="p">():</span>
    <span class="n">txn</span> <span class="o">=</span> <span class="n">build_transaction</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">txn</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code># Approach 2: tests/ is just a directory
tests/
â”œâ”€â”€ test_core.py         # No __init__.py
â””â”€â”€ helpers/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ builders.py
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">helpers.builders</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_transaction</span>  <span class="c1"># Also works</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_with_builder</span><span class="p">():</span>
    <span class="n">txn</span> <span class="o">=</span> <span class="n">build_transaction</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">txn</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
</code></pre></div>

<p>Both work! Pytest adds the <code>tests/</code> directory to <code>sys.path</code> automatically.</p>
<h3 id="the-recommendation-skip-tests__init__py">The Recommendation: Skip <code>tests/__init__.py</code></h3>
<p><strong>Why?</strong>
1. <strong>Simpler imports</strong>: <code>from helpers.builders import ...</code> instead of <code>from tests.helpers.builders import ...</code>
2. <strong>Clearer intent</strong>: Tests aren't meant to be imported as a package
3. <strong>Less confusion</strong>: New developers don't wonder why tests are a package</p>
<p><strong>Exception</strong>: Keep <code>__init__.py</code> in subdirectories like <code>tests/helpers/</code> if you want to import from them.</p>
<h2 id="iteration-3-handling-test-data-files">Iteration 3: Handling Test Data Files</h2>
<p>Real tests need data filesâ€”JSON fixtures, CSV files, images. Where do these go?</p>
<div class="codehilite"><pre><span></span><code>tests/
â”œâ”€â”€ test_core.py
â”œâ”€â”€ test_database.py
â”œâ”€â”€ data/                    # Test data directory
â”‚   â”œâ”€â”€ valid_transaction.json
â”‚   â”œâ”€â”€ invalid_transaction.json
â”‚   â””â”€â”€ sample_users.csv
â””â”€â”€ helpers/
    â””â”€â”€ builders.py
</code></pre></div>

<p>Loading test data:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_process_payment_from_file</span><span class="p">():</span>
    <span class="c1"># Get the directory containing this test file</span>
    <span class="n">test_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span>
    <span class="n">data_file</span> <span class="o">=</span> <span class="n">test_dir</span> <span class="o">/</span> <span class="s2">&quot;data&quot;</span> <span class="o">/</span> <span class="s2">&quot;valid_transaction.json&quot;</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">transaction_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

    <span class="c1"># Use the data in your test</span>
    <span class="k">assert</span> <span class="n">transaction_data</span><span class="p">[</span><span class="s2">&quot;amount&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mf">100.00</span>
</code></pre></div>

<p><strong>Key technique</strong>: Use <code>Path(__file__).parent</code> to locate files relative to the test file. This works regardless of where pytest is run from.</p>
<h3 id="test-data-organization">Test Data Organization</h3>
<div class="codehilite"><pre><span></span><code>tests/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ transactions/        # Organized by domain
â”‚   â”‚   â”œâ”€â”€ valid.json
â”‚   â”‚   â””â”€â”€ invalid.json
â”‚   â”œâ”€â”€ users/
â”‚   â”‚   â””â”€â”€ sample_users.csv
â”‚   â””â”€â”€ fixtures/            # Reusable test fixtures
â”‚       â””â”€â”€ database_seed.sql
â”œâ”€â”€ unit/
â”‚   â””â”€â”€ test_core.py
â””â”€â”€ integration/
    â””â”€â”€ test_payment_flow.py
</code></pre></div>

<h2 id="the-complete-tests-directory-structure">The Complete tests/ Directory Structure</h2>
<p>Here's the production-ready structure:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/                 # Source package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â””â”€â”€ database.py
â””â”€â”€ tests/                   # Tests directory (NOT a package)
    â”œâ”€â”€ conftest.py          # Shared fixtures (Chapter 4)
    â”œâ”€â”€ data/                # Test data files
    â”‚   â”œâ”€â”€ transactions/
    â”‚   â”‚   â”œâ”€â”€ valid.json
    â”‚   â”‚   â””â”€â”€ invalid.json
    â”‚   â””â”€â”€ users/
    â”‚       â””â”€â”€ sample_users.csv
    â”œâ”€â”€ helpers/             # Test utilities (IS a package)
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ builders.py
    â”œâ”€â”€ unit/
    â”‚   â”œâ”€â”€ test_core.py
    â”‚   â””â”€â”€ test_database.py
    â””â”€â”€ integration/
        â””â”€â”€ test_payment_flow.py
</code></pre></div>

<h2 id="decision-framework-tests-directory-placement">Decision Framework: tests/ Directory Placement</h2>
<table>
<thead>
<tr>
<th>Question</th>
<th>Answer</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inside or outside package?</td>
<td>Outside (at project root)</td>
<td>Tests shouldn't ship to users</td>
</tr>
<tr>
<td>Should tests/ have <code>__init__.py</code>?</td>
<td>No</td>
<td>Simpler imports, clearer intent</td>
</tr>
<tr>
<td>Should subdirectories have <code>__init__.py</code>?</td>
<td>Yes, if you import from them</td>
<td>Makes them importable packages</td>
</tr>
<tr>
<td>Where do test data files go?</td>
<td><code>tests/data/</code></td>
<td>Keeps test files separate from code</td>
</tr>
<tr>
<td>How to reference test data?</td>
<td><code>Path(__file__).parent / "data"</code></td>
<td>Works from any directory</td>
</tr>
</tbody>
</table>
<h2 id="common-failure-modes">Common Failure Modes</h2>
<h3 id="symptom-tests-run-but-arent-included-in-coverage">Symptom: Tests run but aren't included in coverage</h3>
<p><strong>Pytest output</strong>:</p>
<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 0 items

============================ no tests ran in 0.01s =============================
</code></pre></div>

<p><strong>Diagnostic clues</strong>:
- Pytest found no test files
- You might be running pytest from the wrong directory
- Test files might not follow naming conventions</p>
<p><strong>Solution</strong>: Run pytest from project root, ensure test files start with <code>test_</code>.</p>
<h3 id="symptom-import-errors-when-loading-test-data">Symptom: Import errors when loading test data</h3>
<p><strong>Error</strong>:</p>
<div class="codehilite"><pre><span></span><code>FileNotFoundError: [Errno 2] No such file or directory: &#39;data/valid.json&#39;
</code></pre></div>

<p><strong>Root cause</strong>: Using relative paths that depend on current working directory.</p>
<p><strong>Solution</strong>: Use <code>Path(__file__).parent</code> for test-file-relative paths.</p>
<h2 id="key-principles_1">Key Principles</h2>
<ol>
<li><strong>Tests outside the package</strong>: Never ship tests to users</li>
<li><strong>No <code>tests/__init__.py</code></strong>: Tests aren't a package</li>
<li><strong>Subdirectories can be packages</strong>: If you need to import from them</li>
<li><strong>Test data in <code>tests/data/</code></strong>: Separate data from code</li>
<li><strong>Use <code>Path(__file__).parent</code></strong>: For reliable file references</li>
</ol>
<h2 id="using-virtual-environments">Using Virtual Environments</h2>
<h2 id="the-problem-dependency-chaos">The Problem: Dependency Chaos</h2>
<p>You're working on two Python projects:
- <strong>Project A</strong> needs <code>pytest==7.4.0</code>
- <strong>Project B</strong> needs <code>pytest==6.2.5</code></p>
<p>Install pytest for Project A:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">pytest</span><span class="o">==</span><span class="m">7</span>.4.0
</code></pre></div>

<p>Now switch to Project B:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>../project_b
pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>ERROR: This version of pytest requires pytest-7.4.0, but you have pytest-6.2.5
</code></pre></div>

<p><strong>The conflict</strong>: You can't have two versions of the same package installed globally. Every project shares the same Python environment.</p>
<h3 id="diagnostic-analysis-why-global-installation-fails">Diagnostic Analysis: Why Global Installation Fails</h3>
<p>When you run <code>pip install</code>, packages go into Python's global <code>site-packages</code> directory:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import site; print(site.getsitepackages())&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>[&#39;/usr/local/lib/python3.11/site-packages&#39;]
</code></pre></div>

<p><strong>The problem</strong>:
1. All projects share this directory
2. Only one version of each package can exist
3. Installing a new version overwrites the old one
4. Different projects can't have different dependencies</p>
<p><strong>What we need</strong>: Isolated environments where each project has its own dependencies.</p>
<h2 id="the-solution-virtual-environments">The Solution: Virtual Environments</h2>
<p>A <strong>virtual environment</strong> is an isolated Python installation. Each project gets its own:
- Python interpreter (linked to the system Python)
- <code>site-packages</code> directory (independent package storage)
- <code>pip</code> installation (project-specific package manager)</p>
<h2 id="iteration-1-creating-your-first-virtual-environment">Iteration 1: Creating Your First Virtual Environment</h2>
<p>Let's create a virtual environment for our <code>payflow</code> project:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>payflow_project
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>venv
</code></pre></div>

<p><strong>What just happened?</strong></p>
<p>The <code>python -m venv venv</code> command:
1. Created a <code>venv/</code> directory
2. Copied the Python interpreter into it
3. Created an isolated <code>site-packages</code> directory
4. Installed <code>pip</code> and <code>setuptools</code> in the isolated environment</p>
<p>Let's examine the structure:</p>
<div class="codehilite"><pre><span></span><code>ls<span class="w"> </span>-la<span class="w"> </span>venv/
</code></pre></div>

<div class="codehilite"><pre><span></span><code>venv/
â”œâ”€â”€ bin/                    # Executables (Linux/Mac)
â”‚   â”œâ”€â”€ python             # Isolated Python interpreter
â”‚   â”œâ”€â”€ pip                # Isolated pip
â”‚   â””â”€â”€ activate           # Activation script
â”œâ”€â”€ include/               # C headers
â”œâ”€â”€ lib/                   # Isolated packages
â”‚   â””â”€â”€ python3.11/
â”‚       â””â”€â”€ site-packages/ # Project-specific packages
â””â”€â”€ pyvenv.cfg            # Configuration
</code></pre></div>

<p>The environment exists but isn't active yet. Check which Python you're using:</p>
<div class="codehilite"><pre><span></span><code>which<span class="w"> </span>python
</code></pre></div>

<div class="codehilite"><pre><span></span><code>/usr/bin/python              # Still using system Python
</code></pre></div>

<h3 id="activating-the-virtual-environment">Activating the Virtual Environment</h3>
<p>To use the isolated environment, you must <strong>activate</strong> it:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">source</span><span class="w"> </span>venv/bin/activate<span class="w">     </span><span class="c1"># Linux/Mac</span>
<span class="c1"># or</span>
venv<span class="se">\S</span>cripts<span class="se">\a</span>ctivate<span class="w">        </span><span class="c1"># Windows</span>
</code></pre></div>

<p>Your prompt changes to show the active environment:</p>
<div class="codehilite"><pre><span></span><code>(venv) user@machine:~/payflow_project$
</code></pre></div>

<p>Now check which Python you're using:</p>
<div class="codehilite"><pre><span></span><code>which<span class="w"> </span>python
</code></pre></div>

<div class="codehilite"><pre><span></span><code>/home/user/payflow_project/venv/bin/python  # Using virtual environment!
</code></pre></div>

<h3 id="installing-packages-in-the-virtual-environment">Installing Packages in the Virtual Environment</h3>
<p>With the environment activated, install pytest:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>Collecting pytest
  Downloading pytest-7.4.3-py3-none-any.whl (325 kB)
Installing collected packages: pytest
Successfully installed pytest-7.4.3
</code></pre></div>

<p>Where did it install?</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>show<span class="w"> </span>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>Name: pytest
Version: 7.4.3
Location: /home/user/payflow_project/venv/lib/python3.11/site-packages
</code></pre></div>

<p><strong>Perfect</strong>. Pytest is installed in the project's isolated environment, not globally.</p>
<h3 id="verifying-isolation">Verifying Isolation</h3>
<p>Let's prove the environments are truly isolated. Deactivate the virtual environment:</p>
<div class="codehilite"><pre><span></span><code>deactivate
</code></pre></div>

<p>Your prompt returns to normal:</p>
<div class="codehilite"><pre><span></span><code>user@machine:~/payflow_project$
</code></pre></div>

<p>Try to run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>bash: pytest: command not found
</code></pre></div>

<p><strong>Excellent</strong>. Pytest only exists inside the virtual environment. Reactivate to use it:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">source</span><span class="w"> </span>venv/bin/activate
pytest<span class="w"> </span>--version
</code></pre></div>

<div class="codehilite"><pre><span></span><code>pytest 7.4.3
</code></pre></div>

<h2 id="iteration-2-managing-dependencies-with-requirementstxt">Iteration 2: Managing Dependencies with requirements.txt</h2>
<p>You've installed pytest, but how do other developers know what to install? How do you remember six months from now?</p>
<p><strong>Solution</strong>: Document dependencies in <code>requirements.txt</code>.</p>
<h3 id="creating-requirementstxt">Creating requirements.txt</h3>
<p>List your current packages:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>freeze
</code></pre></div>

<div class="codehilite"><pre><span></span><code>iniconfig==2.0.0
packaging==23.2
pluggy==1.3.0
pytest==7.4.3
</code></pre></div>

<p>Save this to a file:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>freeze<span class="w"> </span>&gt;<span class="w"> </span>requirements.txt
</code></pre></div>

<p>Now <code>requirements.txt</code> contains:</p>
<div class="codehilite"><pre><span></span><code>iniconfig==2.0.0
packaging==23.2
pluggy==1.3.0
pytest==7.4.3
</code></pre></div>

<h3 id="installing-from-requirementstxt">Installing from requirements.txt</h3>
<p>A new developer clones your project:</p>
<div class="codehilite"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/yourname/payflow.git
<span class="nb">cd</span><span class="w"> </span>payflow
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>venv
<span class="nb">source</span><span class="w"> </span>venv/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</code></pre></div>

<p><strong>Result</strong>: They get exactly the same package versions you used.</p>
<h3 id="separating-development-and-production-dependencies">Separating Development and Production Dependencies</h3>
<p>Your project needs:
- <strong>Production dependencies</strong>: Required to run the code (e.g., <code>requests</code>, <code>sqlalchemy</code>)
- <strong>Development dependencies</strong>: Required to develop/test (e.g., <code>pytest</code>, <code>black</code>, <code>mypy</code>)</p>
<p>Users who install your package shouldn't need pytest. Create two files:</p>
<div class="codehilite"><pre><span></span><code># requirements.txt (production)
requests==2.31.0
sqlalchemy==2.0.23
</code></pre></div>

<div class="codehilite"><pre><span></span><code># requirements-dev.txt (development)
-r requirements.txt          # Include production dependencies
pytest==7.4.3
pytest-cov==4.1.0
black==23.11.0
mypy==1.7.1
</code></pre></div>

<p>The <code>-r requirements.txt</code> line includes production dependencies in the development file.</p>
<p>Install development dependencies:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements-dev.txt
</code></pre></div>

<p>This installs both production and development packages.</p>
<h2 id="iteration-3-installing-your-package-in-development-mode">Iteration 3: Installing Your Package in Development Mode</h2>
<p>Right now, to import <code>payflow</code>, pytest must be run from the project root. This is fragile. Let's make <code>payflow</code> properly installable.</p>
<h3 id="creating-setuppy">Creating setup.py</h3>
<p>Create a minimal <code>setup.py</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># setup.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">setuptools</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup</span><span class="p">,</span> <span class="n">find_packages</span>

<span class="n">setup</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;payflow&quot;</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
    <span class="n">packages</span><span class="o">=</span><span class="n">find_packages</span><span class="p">(),</span>
    <span class="n">install_requires</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;requests&gt;=2.31.0&quot;</span><span class="p">,</span>
        <span class="s2">&quot;sqlalchemy&gt;=2.0.23&quot;</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">extras_require</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;dev&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;pytest&gt;=7.4.3&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pytest-cov&gt;=4.1.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;black&gt;=23.11.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;mypy&gt;=1.7.1&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div>

<h3 id="installing-in-editable-mode">Installing in Editable Mode</h3>
<p>Install your package in <strong>editable mode</strong> (also called <strong>development mode</strong>):</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</code></pre></div>

<p>The <code>-e</code> flag means "editable"â€”changes to your source code are immediately reflected without reinstalling.</p>
<p><strong>What this does</strong>:
1. Creates a link from <code>site-packages</code> to your source directory
2. Makes <code>payflow</code> importable from anywhere
3. Allows you to edit code and see changes immediately</p>
<p>Verify it worked:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import payflow; print(payflow.__file__)&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>/home/user/payflow_project/payflow/__init__.py
</code></pre></div>

<p>Now you can run pytest from any directory:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>/tmp
pytest<span class="w"> </span>/home/user/payflow_project/tests/
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

/home/user/payflow_project/tests/test_core.py .                         [ 50%]
/home/user/payflow_project/tests/test_database.py .                     [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<p><strong>Why this matters</strong>: CI/CD systems often run tests from different directories. Editable installation ensures imports always work.</p>
<h3 id="installing-with-development-dependencies">Installing with Development Dependencies</h3>
<p>Install your package with development extras:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;.[dev]&quot;</span>
</code></pre></div>

<p>This installs:
1. Your package in editable mode
2. Production dependencies from <code>install_requires</code>
3. Development dependencies from <code>extras_require["dev"]</code></p>
<h2 id="the-complete-workflow-from-clone-to-test">The Complete Workflow: From Clone to Test</h2>
<p>Here's the complete workflow a new developer follows:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 1. Clone the repository</span>
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/yourname/payflow.git
<span class="nb">cd</span><span class="w"> </span>payflow

<span class="c1"># 2. Create virtual environment</span>
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>venv

<span class="c1"># 3. Activate virtual environment</span>
<span class="nb">source</span><span class="w"> </span>venv/bin/activate<span class="w">  </span><span class="c1"># Linux/Mac</span>
<span class="c1"># or</span>
venv<span class="se">\S</span>cripts<span class="se">\a</span>ctivate<span class="w">     </span><span class="c1"># Windows</span>

<span class="c1"># 4. Install package with development dependencies</span>
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;.[dev]&quot;</span>

<span class="c1"># 5. Run tests</span>
pytest

<span class="c1"># 6. Start developing</span>
<span class="c1"># Edit code, run tests, repeat</span>
</code></pre></div>

<h2 id="project-structure-with-virtual-environment">Project Structure with Virtual Environment</h2>
<p>Your complete project now looks like:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ venv/                    # Virtual environment (gitignored)
â”‚   â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ payflow/                 # Source package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â””â”€â”€ database.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_core.py
â”‚   â””â”€â”€ test_database.py
â”œâ”€â”€ setup.py                 # Package configuration
â”œâ”€â”€ requirements.txt         # Production dependencies
â”œâ”€â”€ requirements-dev.txt     # Development dependencies
â”œâ”€â”€ .gitignore              # Ignore venv/
â””â”€â”€ README.md
</code></pre></div>

<h3 id="critical-add-venv-to-gitignore">Critical: Add venv/ to .gitignore</h3>
<p>Never commit your virtual environment to version control:</p>
<div class="codehilite"><pre><span></span><code># .gitignore
venv/
*.pyc
__pycache__/
.pytest_cache/
*.egg-info/
dist/
build/
</code></pre></div>

<p><strong>Why?</strong>
1. Virtual environments are large (100+ MB)
2. They're platform-specific (Linux venv won't work on Windows)
3. They're easily recreated from <code>requirements.txt</code></p>
<h2 id="decision-framework-virtual-environment-choices">Decision Framework: Virtual Environment Choices</h2>
<table>
<thead>
<tr>
<th>Question</th>
<th>Recommendation</th>
<th>Alternative</th>
</tr>
</thead>
<tbody>
<tr>
<td>Which tool to use?</td>
<td><code>venv</code> (built-in)</td>
<td><code>virtualenv</code>, <code>conda</code>, <code>poetry</code></td>
</tr>
<tr>
<td>Where to create it?</td>
<td>Project root (<code>venv/</code>)</td>
<td>Anywhere, but document it</td>
</tr>
<tr>
<td>What to name it?</td>
<td><code>venv</code> or <code>.venv</code></td>
<td>Any name, but be consistent</td>
</tr>
<tr>
<td>Commit to git?</td>
<td>Never</td>
<td>N/A</td>
</tr>
<tr>
<td>One venv per project?</td>
<td>Yes</td>
<td>Shared venvs cause conflicts</td>
</tr>
</tbody>
</table>
<h2 id="common-failure-modes_1">Common Failure Modes</h2>
<h3 id="symptom-pytest-command-not-found-after-creating-venv">Symptom: "pytest: command not found" after creating venv</h3>
<p><strong>Diagnostic clues</strong>:
- Virtual environment exists but isn't activated
- Prompt doesn't show <code>(venv)</code></p>
<p><strong>Solution</strong>: Run <code>source venv/bin/activate</code> (Linux/Mac) or <code>venv\Scripts\activate</code> (Windows)</p>
<h3 id="symptom-tests-pass-locally-but-fail-in-ci">Symptom: Tests pass locally but fail in CI</h3>
<p><strong>Pytest output in CI</strong>:</p>
<div class="codehilite"><pre><span></span><code>ModuleNotFoundError: No module named &#39;payflow&#39;
</code></pre></div>

<p><strong>Root cause</strong>: Package not installed in CI environment</p>
<p><strong>Solution</strong>: Add installation step to CI configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/test.yml</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Install dependencies</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">    </span><span class="no">python -m pip install --upgrade pip</span>
<span class="w">    </span><span class="no">pip install -e &quot;.[dev]&quot;</span>
</code></pre></div>

<h3 id="symptom-import-works-in-one-terminal-but-not-another">Symptom: Import works in one terminal but not another</h3>
<p><strong>Diagnostic clues</strong>:
- Different terminals show different <code>which python</code> output
- One terminal has <code>(venv)</code> in prompt, other doesn't</p>
<p><strong>Root cause</strong>: Virtual environment activated in one terminal but not the other</p>
<p><strong>Solution</strong>: Each terminal session needs its own activation. Consider using tools like <code>direnv</code> for automatic activation.</p>
<h2 id="key-principles_2">Key Principles</h2>
<ol>
<li><strong>One virtual environment per project</strong>: Isolate dependencies</li>
<li><strong>Always activate before working</strong>: <code>source venv/bin/activate</code></li>
<li><strong>Document dependencies</strong>: Use <code>requirements.txt</code> or <code>setup.py</code></li>
<li><strong>Install in editable mode</strong>: <code>pip install -e .</code> for development</li>
<li><strong>Never commit venv/</strong>: Add to <code>.gitignore</code></li>
<li><strong>Separate dev and prod dependencies</strong>: Use <code>requirements-dev.txt</code> or <code>extras_require</code></li>
</ol>
<h2 id="pytest-configuration-files-pytestini-setupcfg-pyprojecttoml">Pytest Configuration Files (pytest.ini, setup.cfg, pyproject.toml)</h2>
<h2 id="the-problem-repeating-command-line-options">The Problem: Repeating Command-Line Options</h2>
<p>You're running pytest with the same options every time:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-v<span class="w"> </span>--tb<span class="o">=</span>short<span class="w"> </span>--strict-markers<span class="w"> </span>tests/
</code></pre></div>

<p>This gets tedious. You want these options to be the default. But how?</p>
<p><strong>The solution</strong>: Configuration files. Pytest reads settings from configuration files, so you type less and ensure consistency across your team.</p>
<h2 id="the-three-configuration-file-options">The Three Configuration File Options</h2>
<p>Pytest supports three configuration file formats:</p>
<ol>
<li><strong><code>pytest.ini</code></strong>: Pytest-specific, INI format</li>
<li><strong><code>setup.cfg</code></strong>: Shared with setuptools, INI format</li>
<li><strong><code>pyproject.toml</code></strong>: Modern Python standard, TOML format</li>
</ol>
<p>Let's explore each with our <code>payflow</code> project.</p>
<h2 id="iteration-1-using-pytestini">Iteration 1: Using pytest.ini</h2>
<p>Create <code>pytest.ini</code> in your project root:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="na">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">tests</span>
<span class="na">python_files</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">test_*.py</span>
<span class="na">python_classes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">Test*</span>
<span class="na">python_functions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">test_*</span>
</code></pre></div>

<p>Now run pytest without arguments:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

tests/test_core.py .                                                     [ 50%]
tests/test_database.py .                                                 [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<p><strong>What happened?</strong></p>
<p>Pytest read <code>pytest.ini</code> and applied the configuration:
- <code>testpaths = tests</code>: Only look for tests in the <code>tests/</code> directory
- <code>python_files = test_*.py</code>: Only collect files starting with <code>test_</code>
- <code>python_classes = Test*</code>: Only collect classes starting with <code>Test</code>
- <code>python_functions = test_*</code>: Only collect functions starting with <code>test_</code></p>
<p>These are actually pytest's defaults, but now they're explicit and documented.</p>
<h3 id="adding-useful-options">Adding Useful Options</h3>
<p>Let's add options we use frequently:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pytest.ini</span>
<span class="k">[pytest]</span>
<span class="c1"># Test discovery</span>
<span class="na">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">tests</span>
<span class="na">python_files</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">test_*.py</span>
<span class="na">python_classes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">Test*</span>
<span class="na">python_functions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">test_*</span>

<span class="c1"># Output options</span>
<span class="na">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>
<span class="w">    </span><span class="na">-v</span>
<span class="w">    </span><span class="na">--tb</span><span class="o">=</span><span class="s">short</span>
<span class="w">    </span><span class="na">--strict-markers</span>
<span class="w">    </span><span class="na">--strict-config</span>

<span class="c1"># Markers</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">slow</span><span class="o">:</span><span class="w"> </span><span class="s">marks tests as slow (deselect with &#39;-m &quot;not slow&quot;&#39;)</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">marks tests as integration tests</span>
<span class="w">    </span><span class="na">unit</span><span class="o">:</span><span class="w"> </span><span class="s">marks tests as unit tests</span>
</code></pre></div>

<p>Now run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

tests/test_core.py::test_successful_payment PASSED                       [ 50%]
tests/test_database.py::test_save_and_retrieve_transaction PASSED        [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<p>Notice the output is now verbose (<code>-v</code>) automaticallyâ€”we didn't type it!</p>
<h3 id="understanding-addopts">Understanding addopts</h3>
<p>The <code>addopts</code> option adds command-line arguments automatically. Let's break down what we added:</p>
<ul>
<li><strong><code>-v</code></strong>: Verbose output (show test names)</li>
<li><strong><code>--tb=short</code></strong>: Shorter tracebacks (less noise on failures)</li>
<li><strong><code>--strict-markers</code></strong>: Fail if undefined markers are used</li>
<li><strong><code>--strict-config</code></strong>: Fail if configuration has errors</li>
</ul>
<p>These options now apply to every pytest run.</p>
<h2 id="iteration-2-using-setupcfg">Iteration 2: Using setup.cfg</h2>
<p>If you already have <code>setup.cfg</code> for setuptools, you can add pytest configuration there:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># setup.cfg</span>
<span class="k">[metadata]</span>
<span class="na">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">payflow</span>
<span class="na">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">1.0.0</span>

<span class="k">[options]</span>
<span class="na">packages</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">find:</span>
<span class="na">install_requires</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">requests&gt;</span><span class="o">=</span><span class="s">2.31.0</span>

<span class="k">[options.extras_require]</span>
<span class="na">dev</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">pytest&gt;</span><span class="o">=</span><span class="s">7.4.3</span>
<span class="w">    </span><span class="na">pytest-cov&gt;</span><span class="o">=</span><span class="s">4.1.0</span>

<span class="k">[tool:pytest]</span>
<span class="na">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">tests</span>
<span class="na">addopts</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">-v</span>
<span class="w">    </span><span class="na">--tb</span><span class="o">=</span><span class="s">short</span>
<span class="w">    </span><span class="na">--strict-markers</span>
<span class="na">markers</span><span class="w"> </span><span class="o">=</span>
<span class="w">    </span><span class="na">slow</span><span class="o">:</span><span class="w"> </span><span class="s">marks tests as slow</span>
<span class="w">    </span><span class="na">integration</span><span class="o">:</span><span class="w"> </span><span class="s">marks tests as integration tests</span>
</code></pre></div>

<p><strong>Key difference</strong>: The section is <code>[tool:pytest]</code> instead of <code>[pytest]</code>.</p>
<p>Run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

tests/test_core.py::test_successful_payment PASSED                       [ 50%]
tests/test_database.py::test_save_and_retrieve_transaction PASSED        [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<p>Works identically to <code>pytest.ini</code>.</p>
<h3 id="when-to-use-setupcfg">When to Use setup.cfg</h3>
<p><strong>Use <code>setup.cfg</code> when</strong>:
- You already have it for package configuration
- You want all configuration in one file
- You're using setuptools</p>
<p><strong>Avoid <code>setup.cfg</code> when</strong>:
- You're using modern <code>pyproject.toml</code> for packaging
- You want pytest-specific configuration to be obvious</p>
<h2 id="iteration-3-using-pyprojecttoml-modern-standard">Iteration 3: Using pyproject.toml (Modern Standard)</h2>
<p><code>pyproject.toml</code> is the modern Python standard (PEP 518). It uses TOML format, which is more readable than INI:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[build-system]</span>
<span class="n">requires</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;setuptools&gt;=61.0&quot;</span><span class="p">]</span>
<span class="n">build-backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;setuptools.build_meta&quot;</span>

<span class="k">[project]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;payflow&quot;</span>
<span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;1.0.0&quot;</span>
<span class="n">dependencies</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;requests&gt;=2.31.0&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[project.optional-dependencies]</span>
<span class="n">dev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;pytest&gt;=7.4.3&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;pytest-cov&gt;=4.1.0&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[tool.pytest.ini_options]</span>
<span class="n">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;tests&quot;</span><span class="p">]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-v&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--tb=short&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--strict-markers&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;slow: marks tests as slow (deselect with &#39;-m </span><span class="se">\&quot;</span><span class="s2">not slow</span><span class="se">\&quot;</span><span class="s2">&#39;)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: marks tests as integration tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;unit: marks tests as unit tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>Key differences from INI format</strong>:
- Section is <code>[tool.pytest.ini_options]</code>
- Lists use array syntax: <code>["item1", "item2"]</code>
- Strings are quoted
- More structured and readable</p>
<p>Run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

tests/test_core.py::test_successful_payment PASSED                       [ 50%]
tests/test_database.py::test_save_and_retrieve_transaction PASSED        [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<p>Identical behavior, cleaner syntax.</p>
<h2 id="iteration-4-demonstrating-configuration-in-action">Iteration 4: Demonstrating Configuration in Action</h2>
<p>Let's add a marker to a test and see configuration enforcement:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_successful_payment</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;USD&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">typo_marker</span>  <span class="c1"># Intentional typo</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_invalid_currency</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;INVALID&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

ERROR: Unknown pytest.mark.typo_marker - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
</code></pre></div>

<h3 id="diagnostic-analysis-configuration-enforcement">Diagnostic Analysis: Configuration Enforcement</h3>
<p><strong>What happened?</strong></p>
<p>The <code>--strict-markers</code> option (from our configuration) caught the typo. Without it, pytest would silently ignore the unknown marker.</p>
<p><strong>The error tells us</strong>:
1. <strong>Unknown marker detected</strong>: <code>typo_marker</code> isn't registered
2. <strong>Suggestion</strong>: Register it in configuration
3. <strong>Documentation link</strong>: How to fix it</p>
<p><strong>Fix the typo</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/test_core.py</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">unit</span>  <span class="c1"># Fixed: using registered marker</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_invalid_currency</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;INVALID&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Now it works:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 2 items

tests/test_core.py::test_successful_payment PASSED                       [ 50%]
tests/test_core.py::test_invalid_currency PASSED                         [100%]

============================== 2 passed in 0.02s ===============================
</code></pre></div>

<h2 id="configuration-priority-which-file-wins">Configuration Priority: Which File Wins?</h2>
<p>If multiple configuration files exist, pytest uses this priority order:</p>
<ol>
<li><strong><code>pytest.ini</code></strong> (highest priority)</li>
<li><strong><code>pyproject.toml</code></strong></li>
<li><strong><code>tox.ini</code></strong></li>
<li><strong><code>setup.cfg</code></strong> (lowest priority)</li>
</ol>
<p><strong>Recommendation</strong>: Use only one configuration file to avoid confusion.</p>
<h2 id="the-complete-configuration-production-ready">The Complete Configuration: Production-Ready</h2>
<p>Here's a comprehensive <code>pyproject.toml</code> for a real project:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[build-system]</span>
<span class="n">requires</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;setuptools&gt;=61.0&quot;</span><span class="p">]</span>
<span class="n">build-backend</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;setuptools.build_meta&quot;</span>

<span class="k">[project]</span>
<span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;payflow&quot;</span>
<span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;1.0.0&quot;</span>
<span class="n">description</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Payment processing library&quot;</span>
<span class="n">requires-python</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;&gt;=3.8&quot;</span>
<span class="n">dependencies</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;requests&gt;=2.31.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;sqlalchemy&gt;=2.0.23&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[project.optional-dependencies]</span>
<span class="n">dev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;pytest&gt;=7.4.3&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;pytest-cov&gt;=4.1.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;pytest-asyncio&gt;=0.21.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;black&gt;=23.11.0&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;mypy&gt;=1.7.1&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[tool.pytest.ini_options]</span>
<span class="c1"># Test discovery</span>
<span class="n">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;tests&quot;</span><span class="p">]</span>
<span class="n">python_files</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;test_*.py&quot;</span><span class="p">]</span>
<span class="n">python_classes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Test*&quot;</span><span class="p">]</span>
<span class="n">python_functions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;test_*&quot;</span><span class="p">]</span>

<span class="c1"># Output and behavior</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-v&quot;</span><span class="p">,</span><span class="w">                      </span><span class="c1"># Verbose output</span>
<span class="w">    </span><span class="s2">&quot;--tb=short&quot;</span><span class="p">,</span><span class="w">              </span><span class="c1"># Shorter tracebacks</span>
<span class="w">    </span><span class="s2">&quot;--strict-markers&quot;</span><span class="p">,</span><span class="w">        </span><span class="c1"># Fail on unknown markers</span>
<span class="w">    </span><span class="s2">&quot;--strict-config&quot;</span><span class="p">,</span><span class="w">         </span><span class="c1"># Fail on config errors</span>
<span class="w">    </span><span class="s2">&quot;-ra&quot;</span><span class="p">,</span><span class="w">                     </span><span class="c1"># Show summary of all test outcomes</span>
<span class="w">    </span><span class="s2">&quot;--cov=payflow&quot;</span><span class="p">,</span><span class="w">          </span><span class="c1"># Coverage for payflow package</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=term-missing&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1"># Show missing lines</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=html&quot;</span><span class="p">,</span><span class="w">      </span><span class="c1"># Generate HTML coverage report</span>
<span class="p">]</span>

<span class="c1"># Markers</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;slow: marks tests as slow (deselect with &#39;-m </span><span class="se">\&quot;</span><span class="s2">not slow</span><span class="se">\&quot;</span><span class="s2">&#39;)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: marks tests requiring external services&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;unit: marks tests as unit tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;asyncio: marks tests as async&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Asyncio configuration</span>
<span class="n">asyncio_mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>

<span class="c1"># Minimum coverage threshold</span>
<span class="k">[tool.coverage.run]</span>
<span class="n">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;payflow&quot;</span><span class="p">]</span>
<span class="n">omit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;tests/*&quot;</span><span class="p">]</span>

<span class="k">[tool.coverage.report]</span>
<span class="n">fail_under</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">80</span>
<span class="n">show_missing</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span>
</code></pre></div>

<h2 id="decision-framework-which-configuration-file">Decision Framework: Which Configuration File?</h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Recommended File</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>New project (2024+)</td>
<td><code>pyproject.toml</code></td>
<td>Modern standard, cleaner syntax</td>
</tr>
<tr>
<td>Existing project with <code>setup.cfg</code></td>
<td><code>setup.cfg</code></td>
<td>Consistency with existing config</td>
</tr>
<tr>
<td>Pytest-only configuration</td>
<td><code>pytest.ini</code></td>
<td>Explicit, pytest-specific</td>
</tr>
<tr>
<td>Legacy project</td>
<td><code>setup.cfg</code> or <code>pytest.ini</code></td>
<td>Depends on existing tooling</td>
</tr>
</tbody>
</table>
<h2 id="common-configuration-options-reference">Common Configuration Options Reference</h2>
<h3 id="test-discovery">Test Discovery</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;tests&quot;</span><span class="p">]</span><span class="w">              </span><span class="c1"># Where to look for tests</span>
<span class="n">python_files</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;test_*.py&quot;</span><span class="p">]</span><span class="w">       </span><span class="c1"># Test file patterns</span>
<span class="n">python_classes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Test*&quot;</span><span class="p">]</span><span class="w">         </span><span class="c1"># Test class patterns</span>
<span class="n">python_functions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;test_*&quot;</span><span class="p">]</span><span class="w">      </span><span class="c1"># Test function patterns</span>
</code></pre></div>

<h3 id="output-control">Output Control</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-v&quot;</span><span class="p">,</span><span class="w">              </span><span class="c1"># Verbose: show test names</span>
<span class="w">    </span><span class="s2">&quot;-vv&quot;</span><span class="p">,</span><span class="w">             </span><span class="c1"># Extra verbose: show more details</span>
<span class="w">    </span><span class="s2">&quot;-q&quot;</span><span class="p">,</span><span class="w">              </span><span class="c1"># Quiet: minimal output</span>
<span class="w">    </span><span class="s2">&quot;--tb=short&quot;</span><span class="p">,</span><span class="w">      </span><span class="c1"># Short tracebacks</span>
<span class="w">    </span><span class="s2">&quot;--tb=long&quot;</span><span class="p">,</span><span class="w">       </span><span class="c1"># Long tracebacks (default)</span>
<span class="w">    </span><span class="s2">&quot;--tb=no&quot;</span><span class="p">,</span><span class="w">         </span><span class="c1"># No tracebacks</span>
<span class="w">    </span><span class="s2">&quot;-ra&quot;</span><span class="p">,</span><span class="w">             </span><span class="c1"># Show summary of all outcomes</span>
<span class="w">    </span><span class="s2">&quot;-rA&quot;</span><span class="p">,</span><span class="w">             </span><span class="c1"># Show summary with passed tests too</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="marker-configuration">Marker Configuration</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;slow: marks tests as slow&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: integration tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;unit: unit tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;--strict-markers&quot;</span><span class="p">]</span><span class="w">  </span><span class="c1"># Enforce marker registration</span>
</code></pre></div>

<h3 id="coverage-integration">Coverage Integration</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;--cov=mypackage&quot;</span><span class="p">,</span><span class="w">           </span><span class="c1"># Measure coverage</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=term-missing&quot;</span><span class="p">,</span><span class="w"> </span><span class="c1"># Show missing lines</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=html&quot;</span><span class="p">,</span><span class="w">         </span><span class="c1"># Generate HTML report</span>
<span class="w">    </span><span class="s2">&quot;--cov-fail-under=80&quot;</span><span class="p">,</span><span class="w">       </span><span class="c1"># Fail if coverage &lt; 80%</span>
<span class="p">]</span>
</code></pre></div>

<h2 id="common-failure-modes_2">Common Failure Modes</h2>
<h3 id="symptom-configuration-not-being-applied">Symptom: Configuration not being applied</h3>
<p><strong>Diagnostic clues</strong>:
- Options in config file don't take effect
- Pytest seems to ignore the configuration</p>
<p><strong>Root cause</strong>: Multiple configuration files exist, and pytest is using a different one</p>
<p><strong>Solution</strong>: Check which config file pytest is using:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>--version<span class="w"> </span>-v
</code></pre></div>

<div class="codehilite"><pre><span></span><code>pytest 7.4.3
configfile: /home/user/payflow_project/pytest.ini
</code></pre></div>

<p>Delete or rename conflicting configuration files.</p>
<h3 id="symptom-error-unknown-pytestmarkx">Symptom: "ERROR: Unknown pytest.mark.X"</h3>
<p><strong>Pytest output</strong>:</p>
<div class="codehilite"><pre><span></span><code>ERROR: Unknown pytest.mark.integration - is this a typo?
</code></pre></div>

<p><strong>Root cause</strong>: Marker used but not registered, and <code>--strict-markers</code> is enabled</p>
<p><strong>Solution</strong>: Add marker to configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;integration: marks tests as integration tests&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<h3 id="symptom-configuration-syntax-error">Symptom: Configuration syntax error</h3>
<p><strong>Pytest output</strong>:</p>
<div class="codehilite"><pre><span></span><code>ERROR: configuration error: could not load pyproject.toml
</code></pre></div>

<p><strong>Root cause</strong>: Invalid TOML syntax</p>
<p><strong>Solution</strong>: Validate TOML syntax. Common issues:
- Missing quotes around strings
- Incorrect array syntax
- Mismatched brackets</p>
<p>Use a TOML validator or IDE with TOML support.</p>
<h2 id="key-principles_3">Key Principles</h2>
<ol>
<li><strong>Use one configuration file</strong>: Avoid conflicts between multiple files</li>
<li><strong>Prefer <code>pyproject.toml</code></strong>: Modern standard, cleaner syntax</li>
<li><strong>Register all markers</strong>: Use <code>--strict-markers</code> to catch typos</li>
<li><strong>Document options</strong>: Add comments explaining why each option exists</li>
<li><strong>Share configuration</strong>: Commit config file to version control</li>
<li><strong>Start minimal</strong>: Add options as needed, don't copy-paste everything</li>
</ol>
<h2 id="common-configuration-options">Common Configuration Options</h2>
<h2 id="beyond-the-basics-powerful-configuration-patterns">Beyond the Basics: Powerful Configuration Patterns</h2>
<p>You've seen basic configurationâ€”test discovery, output formatting, markers. Now let's explore configuration options that solve real problems in professional projects.</p>
<p>We'll continue with our <code>payflow</code> project and progressively add configuration as we encounter specific challenges.</p>
<h2 id="the-reference-scenario-a-growing-test-suite">The Reference Scenario: A Growing Test Suite</h2>
<p>Our <code>payflow</code> project now has:
- 50+ unit tests (fast, isolated)
- 20+ integration tests (slower, use database)
- 10+ end-to-end tests (slowest, full system)</p>
<p>Running all tests takes 2 minutes. During development, we want fast feedback. Let's configure pytest to handle this.</p>
<h2 id="iteration-1-controlling-test-output-verbosity">Iteration 1: Controlling Test Output Verbosity</h2>
<h3 id="the-problem-too-much-or-too-little-information">The Problem: Too Much or Too Little Information</h3>
<p>Run tests with default output:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 80 items

tests/unit/test_core.py ........                                         [ 10%]
tests/unit/test_database.py .....                                        [ 16%]
tests/integration/test_payment_flow.py ....                              [ 21%]
...
============================== 80 passed in 45.23s =============================
</code></pre></div>

<p><strong>Problem</strong>: When a test fails, you want details. When all pass, you want minimal output.</p>
<h3 id="solution-conditional-verbosity">Solution: Conditional Verbosity</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-ra&quot;</span><span class="p">,</span><span class="w">              </span><span class="c1"># Show summary of all test outcomes</span>
<span class="w">    </span><span class="s2">&quot;--tb=short&quot;</span><span class="p">,</span><span class="w">       </span><span class="c1"># Short tracebacks on failure</span>
<span class="p">]</span>
</code></pre></div>

<p>The <code>-ra</code> flag shows a summary of all outcomes:
- <strong>r</strong>: Show summary
- <strong>a</strong>: All outcomes (passed, failed, skipped, xfailed, etc.)</p>
<p>Run tests:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 80 items

tests/unit/test_core.py ........                                         [ 10%]
...
============================== 80 passed in 45.23s =============================
========================= short test summary info ==============================
PASSED tests/unit/test_core.py::test_successful_payment
PASSED tests/unit/test_core.py::test_invalid_currency
...
</code></pre></div>

<p>Now you see which tests passed without verbose output during execution.</p>
<h3 id="advanced-show-only-failures">Advanced: Show Only Failures</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-rfE&quot;</span><span class="p">,</span><span class="w">             </span><span class="c1"># Show only failed and error tests</span>
<span class="w">    </span><span class="s2">&quot;--tb=short&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<ul>
<li><strong>r</strong>: Show summary</li>
<li><strong>f</strong>: Failed tests</li>
<li><strong>E</strong>: Error tests</li>
</ul>
<p>When all tests pass, output is minimal. When tests fail, you see exactly which ones.</p>
<h2 id="iteration-2-filtering-tests-by-duration">Iteration 2: Filtering Tests by Duration</h2>
<h3 id="the-problem-slow-tests-block-fast-feedback">The Problem: Slow Tests Block Fast Feedback</h3>
<p>Some tests are slow by nature (database operations, API calls). During development, you want to run only fast tests.</p>
<p>First, mark slow tests:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/integration/test_payment_flow.py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.core</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_payment</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">payflow.database</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransactionDB</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">slow</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_payment_with_database_commit</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This test is slow because it commits to a real database.&quot;&quot;&quot;</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">TransactionDB</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">)</span>
    <span class="n">db</span><span class="o">.</span><span class="n">save_transaction</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;transaction_id&quot;</span><span class="p">],</span> <span class="n">result</span><span class="p">)</span>
    <span class="n">db</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>  <span class="c1"># Slow operation</span>
    <span class="k">assert</span> <span class="n">db</span><span class="o">.</span><span class="n">get_transaction</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;transaction_id&quot;</span><span class="p">])</span>
</code></pre></div>

<p>Configure markers:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;slow: marks tests as slow (deselect with &#39;-m </span><span class="se">\&quot;</span><span class="s2">not slow</span><span class="se">\&quot;</span><span class="s2">&#39;)&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p>Now run only fast tests:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not slow&quot;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 80 items / 10 deselected / 70 selected

tests/unit/test_core.py ........                                         [ 11%]
...
==================== 70 passed, 10 deselected in 5.23s =========================
</code></pre></div>

<p><strong>Result</strong>: Tests run in 5 seconds instead of 45 seconds.</p>
<h3 id="making-this-the-default">Making This the Default</h3>
<p>Add to configuration:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-m&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;not slow&quot;</span><span class="p">,</span><span class="w">   </span><span class="c1"># Skip slow tests by default</span>
<span class="p">]</span>
</code></pre></div>

<p>Now <code>pytest</code> runs fast tests by default. To run all tests:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;&quot;</span><span class="w">  </span><span class="c1"># Empty marker expression = run all</span>
</code></pre></div>

<h2 id="iteration-3-configuring-test-timeouts">Iteration 3: Configuring Test Timeouts</h2>
<h3 id="the-problem-hanging-tests">The Problem: Hanging Tests</h3>
<p>A test with an infinite loop or deadlock hangs forever:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/unit/test_core.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_infinite_loop</span><span class="p">():</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>  <span class="c1"># Oops!</span>
        <span class="k">pass</span>
</code></pre></div>

<p>Run pytest:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>tests/unit/test_core.py::test_infinite_loop
</code></pre></div>

<p><strong>Result</strong>: Pytest hangs. You must manually kill it (Ctrl+C).</p>
<h3 id="solution-pytest-timeout-plugin">Solution: pytest-timeout Plugin</h3>
<p>Install the plugin:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>pytest-timeout
</code></pre></div>

<p>Configure a global timeout:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="w">  </span><span class="c1"># All tests must complete within 10 seconds</span>
</code></pre></div>

<p>Run the hanging test:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>tests/unit/test_core.py::test_infinite_loop
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 1 item

tests/unit/test_core.py::test_infinite_loop FAILED                       [100%]

================================== FAILURES ====================================
__________________________ test_infinite_loop __________________________________
+++ Timeout +++
</code></pre></div>

<h3 id="diagnostic-analysis-timeout-failure">Diagnostic Analysis: Timeout Failure</h3>
<p><strong>The output tells us</strong>:
1. <strong>Test failed</strong>: Not passed or skipped
2. <strong>Reason</strong>: <code>+++ Timeout +++</code>
3. <strong>Duration</strong>: Exceeded 10 seconds</p>
<p><strong>Root cause</strong>: Infinite loop or deadlock</p>
<p><strong>Solution</strong>: Fix the test logic or increase timeout for specific tests:</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">timeout</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>  <span class="c1"># This test needs 30 seconds</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_slow_operation</span><span class="p">():</span>
    <span class="c1"># Long-running operation</span>
    <span class="k">pass</span>
</code></pre></div>

<h2 id="iteration-4-parallel-test-execution">Iteration 4: Parallel Test Execution</h2>
<h3 id="the-problem-sequential-execution-is-slow">The Problem: Sequential Execution is Slow</h3>
<p>Even fast tests take time when you have hundreds of them. Running sequentially wastes CPU cores.</p>
<p>Install pytest-xdist:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>pytest-xdist
</code></pre></div>

<p>Run tests in parallel:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-n<span class="w"> </span>auto
</code></pre></div>

<p>The <code>-n auto</code> flag uses all available CPU cores.</p>
<p><strong>Result</strong>: Tests run 4x faster on a 4-core machine.</p>
<h3 id="making-parallel-execution-the-default">Making Parallel Execution the Default</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;-n&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span><span class="w">       </span><span class="c1"># Parallel execution</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>Warning</strong>: Parallel execution requires tests to be independent. Tests that share state (files, database) may fail randomly.</p>
<h3 id="disabling-parallel-execution-for-specific-tests">Disabling Parallel Execution for Specific Tests</h3>
<p>Some tests can't run in parallel (e.g., tests that modify global state):</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">serial</span>  <span class="c1"># Custom marker</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_modifies_global_state</span><span class="p">():</span>
    <span class="n">global_config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">global_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;value&quot;</span>
</code></pre></div>

<p>Configure pytest-xdist to respect this marker:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;serial: marks tests that must run serially&quot;</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div>

<p>Run serial tests separately:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>-m<span class="w"> </span>serial<span class="w"> </span>-n<span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c1"># No parallelization</span>
pytest<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;not serial&quot;</span><span class="w"> </span>-n<span class="w"> </span>auto<span class="w">  </span><span class="c1"># Parallelize the rest</span>
</code></pre></div>

<h2 id="iteration-5-configuring-coverage-thresholds">Iteration 5: Configuring Coverage Thresholds</h2>
<h3 id="the-problem-coverage-regression">The Problem: Coverage Regression</h3>
<p>Your project has 85% test coverage. A new developer adds code without tests, dropping coverage to 75%.</p>
<p>Configure coverage to fail below a threshold:</p>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;--cov=payflow&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=term-missing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--cov-fail-under=80&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1"># Fail if coverage &lt; 80%</span>
<span class="p">]</span>
</code></pre></div>

<p>Add untested code:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># payflow/core.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">new_feature</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function has no tests.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="s2">&quot;untested&quot;</span>
</code></pre></div>

<p>Run tests:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 80 items

tests/unit/test_core.py ........                                         [ 10%]
...
============================== 80 passed in 5.23s ===============================

---------- coverage: platform linux, python 3.11.6 -----------
Name                    Stmts   Miss  Cover   Missing
-----------------------------------------------------
payflow/__init__.py         0      0   100%
payflow/core.py            45      5    89%   78-82
payflow/database.py        32      0   100%
-----------------------------------------------------
TOTAL                      77      5    94%

FAIL Required test coverage of 80% not reached. Total coverage: 75.32%
</code></pre></div>

<h3 id="diagnostic-analysis-coverage-failure">Diagnostic Analysis: Coverage Failure</h3>
<p><strong>The output tells us</strong>:
1. <strong>All tests passed</strong>: 80 passed
2. <strong>Coverage measured</strong>: 75.32%
3. <strong>Threshold not met</strong>: Required 80%
4. <strong>Missing lines</strong>: Lines 78-82 in <code>core.py</code></p>
<p><strong>Root cause</strong>: New code added without tests</p>
<p><strong>Solution</strong>: Write tests for the new feature or adjust the threshold temporarily.</p>
<h2 id="iteration-6-configuring-warning-filters">Iteration 6: Configuring Warning Filters</h2>
<h3 id="the-problem-deprecation-warnings-clutter-output">The Problem: Deprecation Warnings Clutter Output</h3>
<p>Third-party libraries emit deprecation warnings:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 80 items

tests/unit/test_core.py ........
/usr/lib/python3.11/site-packages/requests/api.py:123: DeprecationWarning: 
  The &#39;verify&#39; parameter is deprecated. Use &#39;ssl_context&#39; instead.
...
============================== 80 passed in 5.23s ===============================
</code></pre></div>

<h3 id="solution-filter-warnings">Solution: Filter Warnings</h3>
<div class="codehilite"><pre><span></span><code><span class="k">[tool.pytest.ini_options]</span>
<span class="n">filterwarnings</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;error&quot;</span><span class="p">,</span><span class="w">                                    </span><span class="c1"># Treat warnings as errors</span>
<span class="w">    </span><span class="s2">&quot;ignore::DeprecationWarning:requests.*&quot;</span><span class="p">,</span><span class="w">   </span><span class="c1"># Ignore requests deprecations</span>
<span class="w">    </span><span class="s2">&quot;ignore::PendingDeprecationWarning&quot;</span><span class="p">,</span><span class="w">       </span><span class="c1"># Ignore pending deprecations</span>
<span class="p">]</span>
</code></pre></div>

<p><strong>Explanation</strong>:
- <code>"error"</code>: Convert all warnings to errors (strict mode)
- <code>"ignore::DeprecationWarning:requests.*"</code>: Ignore deprecation warnings from the <code>requests</code> library
- <code>"ignore::PendingDeprecationWarning"</code>: Ignore pending deprecations globally</p>
<p>Run tests:</p>
<div class="codehilite"><pre><span></span><code>pytest
</code></pre></div>

<div class="codehilite"><pre><span></span><code>============================= test session starts ==============================
collected 80 items

tests/unit/test_core.py ........                                         [ 10%]
...
============================== 80 passed in 5.23s ===============================
</code></pre></div>

<p>Clean outputâ€”no warnings.</p>
<h2 id="the-complete-configuration-production-ready_1">The Complete Configuration: Production-Ready</h2>
<p>Here's a comprehensive configuration incorporating all patterns:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># pyproject.toml</span>
<span class="k">[tool.pytest.ini_options]</span>
<span class="c1"># Test discovery</span>
<span class="n">testpaths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;tests&quot;</span><span class="p">]</span>
<span class="n">python_files</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;test_*.py&quot;</span><span class="p">]</span>
<span class="n">python_classes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;Test*&quot;</span><span class="p">]</span>
<span class="n">python_functions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;test_*&quot;</span><span class="p">]</span>

<span class="c1"># Output control</span>
<span class="n">addopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="c1"># Verbosity</span>
<span class="w">    </span><span class="s2">&quot;-ra&quot;</span><span class="p">,</span><span class="w">                      </span><span class="c1"># Show summary of all outcomes</span>
<span class="w">    </span><span class="s2">&quot;--tb=short&quot;</span><span class="p">,</span><span class="w">               </span><span class="c1"># Short tracebacks</span>

<span class="w">    </span><span class="c1"># Performance</span>
<span class="w">    </span><span class="s2">&quot;-n&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span><span class="w">               </span><span class="c1"># Parallel execution</span>
<span class="w">    </span><span class="s2">&quot;--timeout=10&quot;</span><span class="p">,</span><span class="w">             </span><span class="c1"># Global timeout</span>

<span class="w">    </span><span class="c1"># Coverage</span>
<span class="w">    </span><span class="s2">&quot;--cov=payflow&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=term-missing&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--cov-report=html&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;--cov-fail-under=80&quot;</span><span class="p">,</span>

<span class="w">    </span><span class="c1"># Quality gates</span>
<span class="w">    </span><span class="s2">&quot;--strict-markers&quot;</span><span class="p">,</span><span class="w">         </span><span class="c1"># Fail on unknown markers</span>
<span class="w">    </span><span class="s2">&quot;--strict-config&quot;</span><span class="p">,</span><span class="w">          </span><span class="c1"># Fail on config errors</span>
<span class="p">]</span>

<span class="c1"># Markers</span>
<span class="n">markers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;slow: marks tests as slow (deselect with &#39;-m </span><span class="se">\&quot;</span><span class="s2">not slow</span><span class="se">\&quot;</span><span class="s2">&#39;)&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;integration: integration tests requiring external services&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;unit: unit tests&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;serial: tests that must run serially&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Warning filters</span>
<span class="n">filterwarnings</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;error&quot;</span><span class="p">,</span><span class="w">                                    </span><span class="c1"># Warnings as errors</span>
<span class="w">    </span><span class="s2">&quot;ignore::DeprecationWarning:requests.*&quot;</span><span class="p">,</span><span class="w">   </span><span class="c1"># Ignore requests warnings</span>
<span class="p">]</span>

<span class="c1"># Timeout configuration</span>
<span class="n">timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span>
<span class="n">timeout_method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;thread&quot;</span>

<span class="c1"># Coverage configuration</span>
<span class="k">[tool.coverage.run]</span>
<span class="n">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;payflow&quot;</span><span class="p">]</span>
<span class="n">omit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="s2">&quot;tests/*&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s2">&quot;*/migrations/*&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">[tool.coverage.report]</span>
<span class="n">fail_under</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">80</span>
<span class="n">show_missing</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span>
<span class="n">skip_covered</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">false</span>
</code></pre></div>

<h2 id="configuration-options-reference">Configuration Options Reference</h2>
<h3 id="test-selection">Test Selection</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>testpaths</code></td>
<td>Where to look for tests</td>
<td><code>testpaths = ["tests"]</code></td>
</tr>
<tr>
<td><code>python_files</code></td>
<td>Test file patterns</td>
<td><code>python_files = ["test_*.py"]</code></td>
</tr>
<tr>
<td><code>python_classes</code></td>
<td>Test class patterns</td>
<td><code>python_classes = ["Test*"]</code></td>
</tr>
<tr>
<td><code>python_functions</code></td>
<td>Test function patterns</td>
<td><code>python_functions = ["test_*"]</code></td>
</tr>
</tbody>
</table>
<h3 id="output-control_1">Output Control</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-v</code></td>
<td>Verbose output</td>
<td>Show test names</td>
</tr>
<tr>
<td><code>-q</code></td>
<td>Quiet output</td>
<td>Minimal output</td>
</tr>
<tr>
<td><code>--tb=short</code></td>
<td>Short tracebacks</td>
<td>Less noise on failure</td>
</tr>
<tr>
<td><code>-ra</code></td>
<td>Show all outcomes</td>
<td>Summary of all tests</td>
</tr>
<tr>
<td><code>-rfE</code></td>
<td>Show only failures</td>
<td>Minimal when passing</td>
</tr>
</tbody>
</table>
<h3 id="performance">Performance</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-n auto</code></td>
<td>Parallel execution</td>
<td>Use all CPU cores</td>
</tr>
<tr>
<td><code>--timeout=N</code></td>
<td>Global timeout</td>
<td>Fail after N seconds</td>
</tr>
<tr>
<td><code>-x</code></td>
<td>Stop on first failure</td>
<td>Fast feedback</td>
</tr>
<tr>
<td><code>--maxfail=N</code></td>
<td>Stop after N failures</td>
<td>Limit failure cascade</td>
</tr>
</tbody>
</table>
<h3 id="coverage">Coverage</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--cov=PKG</code></td>
<td>Measure coverage</td>
<td><code>--cov=payflow</code></td>
</tr>
<tr>
<td><code>--cov-report=term</code></td>
<td>Terminal report</td>
<td>Show in console</td>
</tr>
<tr>
<td><code>--cov-report=html</code></td>
<td>HTML report</td>
<td>Generate HTML</td>
</tr>
<tr>
<td><code>--cov-fail-under=N</code></td>
<td>Minimum coverage</td>
<td>Fail if below N%</td>
</tr>
</tbody>
</table>
<h3 id="quality-gates">Quality Gates</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--strict-markers</code></td>
<td>Fail on unknown markers</td>
<td>Catch typos</td>
</tr>
<tr>
<td><code>--strict-config</code></td>
<td>Fail on config errors</td>
<td>Validate config</td>
</tr>
<tr>
<td><code>--lf</code></td>
<td>Run last failed</td>
<td>Rerun failures</td>
</tr>
<tr>
<td><code>--ff</code></td>
<td>Failed first</td>
<td>Prioritize failures</td>
</tr>
</tbody>
</table>
<h2 id="decision-framework-which-options-to-use">Decision Framework: Which Options to Use?</h2>
<table>
<thead>
<tr>
<th>Project Stage</th>
<th>Recommended Options</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>Early development</td>
<td><code>-v</code>, <code>--tb=short</code></td>
<td>Clear feedback</td>
</tr>
<tr>
<td>Growing test suite</td>
<td><code>-n auto</code>, <code>-m "not slow"</code></td>
<td>Fast feedback</td>
</tr>
<tr>
<td>CI/CD pipeline</td>
<td><code>--cov-fail-under=80</code>, <code>--strict-markers</code></td>
<td>Quality gates</td>
</tr>
<tr>
<td>Production-ready</td>
<td>All of the above</td>
<td>Comprehensive</td>
</tr>
</tbody>
</table>
<h2 id="common-failure-modes_3">Common Failure Modes</h2>
<h3 id="symptom-tests-pass-locally-but-fail-in-ci_1">Symptom: Tests pass locally but fail in CI</h3>
<p><strong>Diagnostic clues</strong>:
- Local: <code>pytest</code> passes
- CI: <code>pytest</code> fails with timeout</p>
<p><strong>Root cause</strong>: Different timeout configuration</p>
<p><strong>Solution</strong>: Ensure CI uses the same configuration file:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># .github/workflows/test.yml</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Run tests</span>
<span class="w">  </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytest</span><span class="w">  </span><span class="c1"># Uses pyproject.toml automatically</span>
</code></pre></div>

<h3 id="symptom-parallel-tests-fail-randomly">Symptom: Parallel tests fail randomly</h3>
<p><strong>Pytest output</strong>:</p>
<div class="codehilite"><pre><span></span><code>tests/integration/test_database.py::test_transaction FAILED
tests/integration/test_database.py::test_transaction PASSED  # Flaky!
</code></pre></div>

<p><strong>Root cause</strong>: Tests share state (database, files)</p>
<p><strong>Solution</strong>: Disable parallel execution for integration tests:</p>
<div class="codehilite"><pre><span></span><code>pytest<span class="w"> </span>tests/unit/<span class="w"> </span>-n<span class="w"> </span>auto<span class="w">          </span><span class="c1"># Parallel</span>
pytest<span class="w"> </span>tests/integration/<span class="w"> </span>-n<span class="w"> </span><span class="m">0</span><span class="w">      </span><span class="c1"># Serial</span>
</code></pre></div>

<h2 id="key-principles_4">Key Principles</h2>
<ol>
<li><strong>Start minimal</strong>: Add options as problems arise</li>
<li><strong>Document choices</strong>: Comment why each option exists</li>
<li><strong>Test configuration</strong>: Verify options work as expected</li>
<li><strong>Share configuration</strong>: Commit to version control</li>
<li><strong>Use quality gates</strong>: Enforce standards automatically</li>
<li><strong>Optimize for feedback speed</strong>: Fast tests during development, comprehensive in CI</li>
</ol>
<h2 id="setting-up-your-ide-for-testing">Setting Up Your IDE for Testing</h2>
<h2 id="the-problem-manual-test-execution-is-slow">The Problem: Manual Test Execution is Slow</h2>
<p>You're developing a feature. Your workflow looks like this:</p>
<ol>
<li>Write code</li>
<li>Switch to terminal</li>
<li>Type <code>pytest tests/test_feature.py::test_specific_case</code></li>
<li>Read output</li>
<li>Switch back to editor</li>
<li>Repeat</li>
</ol>
<p>This context switching kills productivity. What if you could run tests directly from your editor?</p>
<h2 id="the-solution-ide-integration">The Solution: IDE Integration</h2>
<p>Modern IDEs integrate pytest directly into the development environment. You can:
- Run tests with a keyboard shortcut
- See test results inline
- Debug failing tests with breakpoints
- Navigate to failing lines instantly</p>
<p>Let's set this up for the three most popular Python IDEs.</p>
<h2 id="reference-project-our-payflow-test-suite">Reference Project: Our payflow Test Suite</h2>
<p>We'll use our <code>payflow</code> project with this structure:</p>
<div class="codehilite"><pre><span></span><code>payflow_project/
â”œâ”€â”€ payflow/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py
â”‚   â””â”€â”€ database.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_core.py
â”‚   â”‚   â””â”€â”€ test_database.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_payment_flow.py
â”œâ”€â”€ pyproject.toml
â””â”€â”€ venv/
</code></pre></div>

<h2 id="iteration-1-vs-code-setup">Iteration 1: VS Code Setup</h2>
<h3 id="installing-the-python-extension">Installing the Python Extension</h3>
<ol>
<li>Open VS Code</li>
<li>Press <code>Ctrl+Shift+X</code> (Extensions)</li>
<li>Search for "Python"</li>
<li>Install the official Microsoft Python extension</li>
</ol>
<h3 id="configuring-pytest-discovery">Configuring Pytest Discovery</h3>
<p>VS Code needs to know you're using pytest. Create <code>.vscode/settings.json</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;python.testing.pytestEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;python.testing.unittestEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;python.testing.pytestArgs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="s2">&quot;tests&quot;</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;python.testing.autoTestDiscoverOnSaveEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>What this does</strong>:
- <code>pytestEnabled</code>: Use pytest (not unittest)
- <code>pytestArgs</code>: Look for tests in <code>tests/</code> directory
- <code>autoTestDiscoverOnSaveEnabled</code>: Discover tests automatically when you save</p>
<h3 id="discovering-tests">Discovering Tests</h3>
<ol>
<li>Open the Testing sidebar (flask icon on the left)</li>
<li>Click "Configure Python Tests"</li>
<li>Select "pytest"</li>
<li>Select "tests" as the test directory</li>
</ol>
<p>VS Code scans your project and displays all tests in a tree view:</p>
<div class="codehilite"><pre><span></span><code>TESTS
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_core.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_successful_payment âœ“
â”‚   â”‚   â”‚   â””â”€â”€ test_invalid_currency âœ“
â”‚   â”‚   â””â”€â”€ test_database.py
â”‚   â”‚       â””â”€â”€ test_save_and_retrieve_transaction âœ“
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_payment_flow.py
â”‚           â””â”€â”€ test_payment_is_saved_to_database âœ“
</code></pre></div>

<h3 id="running-tests-from-the-ide">Running Tests from the IDE</h3>
<p><strong>Run a single test</strong>:
1. Click the play button next to the test name
2. Or right-click â†’ "Run Test"</p>
<p><strong>Run all tests in a file</strong>:
1. Click the play button next to the file name</p>
<p><strong>Run all tests</strong>:
1. Click the play button at the top of the test tree</p>
<h3 id="viewing-test-results">Viewing Test Results</h3>
<p>When tests run, VS Code shows results inline:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/unit/test_core.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_successful_payment</span><span class="p">():</span>  <span class="c1"># âœ“ Passed (0.01s)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;USD&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_invalid_currency</span><span class="p">():</span>  <span class="c1"># âœ— Failed (0.02s)</span>
    <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;INVALID&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Failed tests show a red X. Click it to see the failure details in the terminal.</p>
<h3 id="debugging-tests">Debugging Tests</h3>
<p>Set a breakpoint in your test:
1. Click in the gutter next to a line number (red dot appears)
2. Right-click the test â†’ "Debug Test"
3. Execution pauses at the breakpoint
4. Use the debug toolbar to step through code</p>
<p>Example debugging session:</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># tests/unit/test_core.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_successful_payment</span><span class="p">():</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">process_payment</span><span class="p">(</span><span class="mf">100.00</span><span class="p">,</span> <span class="s2">&quot;USD&quot;</span><span class="p">)</span>  <span class="c1"># â† Breakpoint here</span>
    <span class="c1"># Execution pauses, you can inspect &#39;result&#39; in the debug console</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;completed&quot;</span>
</code></pre></div>

<h3 id="keyboard-shortcuts">Keyboard Shortcuts</h3>
<p>Add these to <code>.vscode/keybindings.json</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ctrl+shift+t&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;command&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;python.runCurrentTestFile&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;key&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ctrl+shift+r&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;command&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;python.runTestAtCursor&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
</code></pre></div>

<p>Now:
- <code>Ctrl+Shift+T</code>: Run all tests in current file
- <code>Ctrl+Shift+R</code>: Run test under cursor</p>
<h2 id="iteration-2-pycharm-setup">Iteration 2: PyCharm Setup</h2>
<p>PyCharm has built-in pytest supportâ€”no plugins needed.</p>
<h3 id="configuring-pytest-as-the-default-test-runner">Configuring Pytest as the Default Test Runner</h3>
<ol>
<li>Open Settings (<code>Ctrl+Alt+S</code>)</li>
<li>Navigate to: Tools â†’ Python Integrated Tools</li>
<li>Under "Testing", select "pytest" as the default test runner</li>
<li>Click "OK"</li>
</ol>
<h3 id="running-tests">Running Tests</h3>
<p><strong>Run a single test</strong>:
1. Right-click the test function
2. Select "Run 'pytest in test_core.py::test_successful_payment'"</p>
<p><strong>Run all tests in a file</strong>:
1. Right-click the file in the project tree
2. Select "Run 'pytest in test_core.py'"</p>
<p><strong>Run all tests</strong>:
1. Right-click the <code>tests/</code> directory
2. Select "Run 'pytest in tests'"</p>
<h3 id="viewing-test-results_1">Viewing Test Results</h3>
<p>PyCharm shows a dedicated test runner window:</p>
<div class="codehilite"><pre><span></span><code>Test Results
â”œâ”€â”€ tests/unit/test_core.py
â”‚   â”œâ”€â”€ âœ“ test_successful_payment (0.01s)
â”‚   â””â”€â”€ âœ— test_invalid_currency (0.02s)
â”‚       AssertionError: Expected ValueError but got None
â”‚       Click to see full traceback â†’
</code></pre></div>

<p>Click a failed test to see:
- Full traceback
- Expected vs. actual values
- Link to the failing line</p>
<h3 id="debugging-tests_1">Debugging Tests</h3>
<ol>
<li>Set a breakpoint (click in the gutter)</li>
<li>Right-click the test</li>
<li>Select "Debug 'pytest in test_core.py::test_successful_payment'"</li>
<li>Use the debugger toolbar to step through</li>
</ol>
<h3 id="running-tests-with-coverage">Running Tests with Coverage</h3>
<ol>
<li>Right-click the test/file/directory</li>
<li>Select "Run 'pytest in ...' with Coverage"</li>
<li>PyCharm shows coverage inline:</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># payflow/core.py</span>
<span class="k">def</span><span class="w"> </span><span class="nf">process_payment</span><span class="p">(</span><span class="n">amount</span><span class="p">,</span> <span class="n">currency</span><span class="o">=</span><span class="s2">&quot;USD&quot;</span><span class="p">):</span>  <span class="c1"># âœ“ Covered</span>
    <span class="k">if</span> <span class="n">amount</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>                           <span class="c1"># âœ“ Covered</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Amount must be positive&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">currency</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;USD&quot;</span><span class="p">,</span> <span class="s2">&quot;EUR&quot;</span><span class="p">,</span> <span class="s2">&quot;GBP&quot;</span><span class="p">]:</span> <span class="c1"># âœ“ Covered</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported currency: </span><span class="si">{</span><span class="n">currency</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">transaction_id</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;TXN-</span><span class="si">{</span><span class="n">amount</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">currency</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># âœ— Not covered</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;transaction_id&quot;</span><span class="p">:</span> <span class="n">transaction_id</span><span class="p">,</span>
        <span class="s2">&quot;amount&quot;</span><span class="p">:</span> <span class="n">amount</span><span class="p">,</span>
        <span class="s2">&quot;currency&quot;</span><span class="p">:</span> <span class="n">currency</span><span class="p">,</span>
        <span class="s2">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;completed&quot;</span>
    <span class="p">}</span>
</code></pre></div>

<p>Green highlights = covered, red highlights = not covered.</p>
<h3 id="keyboard-shortcuts_1">Keyboard Shortcuts</h3>
<p>PyCharm's default shortcuts:
- <code>Ctrl+Shift+F10</code>: Run test at cursor
- <code>Shift+F10</code>: Rerun last test
- <code>Ctrl+Shift+F9</code>: Debug test at cursor
- <code>Shift+F9</code>: Debug last test</p>
<h3 id="configuring-pytest-options">Configuring Pytest Options</h3>
<ol>
<li>Open Run/Debug Configurations</li>
<li>Edit the pytest configuration</li>
<li>Add options in "Additional Arguments":</li>
</ol>
<div class="codehilite"><pre><span></span><code>-v --tb=short -m &quot;not slow&quot;
</code></pre></div>

<p>These options apply to all test runs from PyCharm.</p>
<h2 id="iteration-3-vimneovim-setup">Iteration 3: Vim/Neovim Setup</h2>
<p>For terminal-based editors, we'll use <code>vim-test</code> plugin.</p>
<h3 id="installing-vim-test">Installing vim-test</h3>
<p>Add to your <code>.vimrc</code> or <code>init.vim</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="c">&quot; Using vim-plug</span>
Plug <span class="s1">&#39;vim-test/vim-test&#39;</span>

<span class="c">&quot; Configure test strategy</span>
<span class="k">let</span> test#strategy <span class="p">=</span> <span class="s2">&quot;neovim&quot;</span>  <span class="s2">&quot; or &quot;</span>vimterminal&quot; <span class="k">for</span> Vim <span class="m">8</span><span class="p">+</span>
<span class="k">let</span> test#python#runner <span class="p">=</span> <span class="s1">&#39;pytest&#39;</span>
</code></pre></div>

<p>Install plugins:</p>
<div class="codehilite"><pre><span></span><code><span class="p">:</span>PlugInstall
</code></pre></div>

<h3 id="running-tests_1">Running Tests</h3>
<p><strong>Run nearest test</strong> (cursor on test function):</p>
<div class="codehilite"><pre><span></span><code><span class="p">:</span>TestNearest
</code></pre></div>

<p><strong>Run all tests in file</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">:</span>TestFile
</code></pre></div>

<p><strong>Run all tests</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">:</span>TestSuite
</code></pre></div>

<p><strong>Rerun last test</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">:</span>TestLast
</code></pre></div>

<h3 id="keyboard-mappings">Keyboard Mappings</h3>
<p>Add to <code>.vimrc</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="c">&quot; Test mappings</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">tn</span> :TestNearest<span class="p">&lt;</span>CR<span class="p">&gt;</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">tf</span> :TestFile<span class="p">&lt;</span>CR<span class="p">&gt;</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">ts</span> :TestSuite<span class="p">&lt;</span>CR<span class="p">&gt;</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">tl</span> :TestLast<span class="p">&lt;</span>CR<span class="p">&gt;</span>
</code></pre></div>

<p>Now:
- <code>&lt;leader&gt;tn</code>: Run nearest test
- <code>&lt;leader&gt;tf</code>: Run file tests
- <code>&lt;leader&gt;ts</code>: Run all tests
- <code>&lt;leader&gt;tl</code>: Rerun last test</p>
<h3 id="viewing-results-in-split-window">Viewing Results in Split Window</h3>
<p>Configure vim-test to show results in a split:</p>
<div class="codehilite"><pre><span></span><code><span class="k">let</span> test#strategy <span class="p">=</span> <span class="s2">&quot;neovim&quot;</span>
<span class="k">let</span> test#neovim#term_position <span class="p">=</span> <span class="s2">&quot;vertical&quot;</span>  <span class="c">&quot; Vertical split</span>
</code></pre></div>

<p>Tests run in a vertical split, showing pytest output in real-time.</p>
<h3 id="advanced-async-test-execution">Advanced: Async Test Execution</h3>
<p>For Neovim with async support:</p>
<div class="codehilite"><pre><span></span><code><span class="k">let</span> test#strategy <span class="p">=</span> <span class="s2">&quot;neovim&quot;</span>
<span class="k">let</span> test#neovim#start_normal <span class="p">=</span> <span class="m">1</span>  <span class="c">&quot; Start in normal mode</span>
</code></pre></div>

<p>Tests run asynchronouslyâ€”you can continue editing while tests execute.</p>
<h2 id="iteration-4-configuring-test-discovery-for-all-ides">Iteration 4: Configuring Test Discovery for All IDEs</h2>
<h3 id="the-problem-ide-cant-find-tests">The Problem: IDE Can't Find Tests</h3>
<p>Your IDE shows "No tests found" even though <code>pytest</code> works from the terminal.</p>
<h3 id="diagnostic-analysis-why-discovery-fails">Diagnostic Analysis: Why Discovery Fails</h3>
<p><strong>Common causes</strong>:
1. <strong>Wrong Python interpreter</strong>: IDE using system Python, not virtual environment
2. <strong>Wrong working directory</strong>: IDE running from wrong location
3. <strong>Missing pytest</strong>: pytest not installed in the IDE's Python environment
4. <strong>Configuration mismatch</strong>: IDE configuration doesn't match pytest.ini</p>
<h3 id="solution-verify-python-interpreter">Solution: Verify Python Interpreter</h3>
<p><strong>VS Code</strong>:
1. Press <code>Ctrl+Shift+P</code>
2. Type "Python: Select Interpreter"
3. Choose the interpreter from your <code>venv/</code> directory</p>
<p><strong>PyCharm</strong>:
1. Open Settings â†’ Project â†’ Python Interpreter
2. Click the gear icon â†’ Add
3. Select "Existing environment"
4. Navigate to <code>venv/bin/python</code></p>
<p><strong>Vim/Neovim</strong>:
Ensure you activate the virtual environment before starting Vim:</p>
<div class="codehilite"><pre><span></span><code><span class="nb">source</span><span class="w"> </span>venv/bin/activate
vim
</code></pre></div>

<h3 id="solution-verify-working-directory">Solution: Verify Working Directory</h3>
<p><strong>VS Code</strong>: Check <code>.vscode/settings.json</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;python.testing.cwd&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;${workspaceFolder}&quot;</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>PyCharm</strong>: Check Run/Debug Configuration:
- Working directory should be project root</p>
<h3 id="solution-install-pytest-in-ide-environment">Solution: Install Pytest in IDE Environment</h3>
<p>From the IDE's terminal:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>pytest
</code></pre></div>

<p>Verify:</p>
<div class="codehilite"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>pytest<span class="w"> </span>--version
</code></pre></div>

<div class="codehilite"><pre><span></span><code>pytest 7.4.3
</code></pre></div>

<h2 id="the-complete-ide-configuration">The Complete IDE Configuration</h2>
<h3 id="vs-code-vscodesettingsjson">VS Code: .vscode/settings.json</h3>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;python.testing.pytestEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;python.testing.unittestEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;python.testing.pytestArgs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="s2">&quot;tests&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="s2">&quot;-v&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="s2">&quot;--tb=short&quot;</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;python.testing.autoTestDiscoverOnSaveEnabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;python.testing.cwd&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;${workspaceFolder}&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;python.defaultInterpreterPath&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;${workspaceFolder}/venv/bin/python&quot;</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="pycharm-rundebug-configuration">PyCharm: Run/Debug Configuration</h3>
<ol>
<li>Edit Configurations â†’ Templates â†’ Python tests â†’ pytest</li>
<li>Set:</li>
<li>Target: Custom</li>
<li>Working directory: Project root</li>
<li>Additional Arguments: <code>-v --tb=short</code></li>
<li>Python interpreter: Project venv</li>
</ol>
<h3 id="vimneovim-vimrc">Vim/Neovim: .vimrc</h3>
<div class="codehilite"><pre><span></span><code><span class="c">&quot; vim-test configuration</span>
<span class="k">let</span> test#strategy <span class="p">=</span> <span class="s2">&quot;neovim&quot;</span>
<span class="k">let</span> test#python#runner <span class="p">=</span> <span class="s1">&#39;pytest&#39;</span>
<span class="k">let</span> test#python#pytest#<span class="k">options</span> <span class="p">=</span> <span class="s1">&#39;-v --tb=short&#39;</span>

<span class="c">&quot; Mappings</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">tn</span> :TestNearest<span class="p">&lt;</span>CR<span class="p">&gt;</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">tf</span> :TestFile<span class="p">&lt;</span>CR<span class="p">&gt;</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">ts</span> :TestSuite<span class="p">&lt;</span>CR<span class="p">&gt;</span>
nmap <span class="p">&lt;</span><span class="k">silent</span><span class="p">&gt;</span> <span class="p">&lt;</span>leader<span class="p">&gt;</span><span class="k">tl</span> :TestLast<span class="p">&lt;</span>CR<span class="p">&gt;</span>
</code></pre></div>

<h2 id="decision-framework-which-ide-features-to-use">Decision Framework: Which IDE Features to Use?</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>When to Use</th>
<th>When to Skip</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inline test results</td>
<td>Always</td>
<td>Neverâ€”essential feedback</td>
</tr>
<tr>
<td>Test tree view</td>
<td>Large test suites</td>
<td>Small projects (&lt;10 tests)</td>
</tr>
<tr>
<td>Debugging integration</td>
<td>Complex failures</td>
<td>Simple assertion failures</td>
</tr>
<tr>
<td>Coverage visualization</td>
<td>Improving coverage</td>
<td>Initial development</td>
</tr>
<tr>
<td>Auto-discovery</td>
<td>Always</td>
<td>Neverâ€”saves time</td>
</tr>
</tbody>
</table>
<h2 id="common-failure-modes_4">Common Failure Modes</h2>
<h3 id="symptom-no-tests-found-in-ide-but-pytest-works-in-terminal">Symptom: "No tests found" in IDE but pytest works in terminal</h3>
<p><strong>Diagnostic clues</strong>:
- Terminal: <code>pytest</code> finds and runs tests
- IDE: Shows "No tests collected"</p>
<p><strong>Root cause</strong>: IDE using different Python interpreter</p>
<p><strong>Solution</strong>: Configure IDE to use project's virtual environment</p>
<h3 id="symptom-tests-run-but-imports-fail-in-ide">Symptom: Tests run but imports fail in IDE</h3>
<p><strong>Error in IDE</strong>:</p>
<div class="codehilite"><pre><span></span><code>ModuleNotFoundError: No module named &#39;payflow&#39;
</code></pre></div>

<p><strong>Root cause</strong>: Package not installed in editable mode</p>
<p><strong>Solution</strong>:</p>
<div class="codehilite"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</code></pre></div>

<h3 id="symptom-ide-runs-tests-from-wrong-directory">Symptom: IDE runs tests from wrong directory</h3>
<p><strong>Pytest output</strong>:</p>
<div class="codehilite"><pre><span></span><code>ERROR: file not found: tests/test_core.py
</code></pre></div>

<p><strong>Root cause</strong>: IDE's working directory is wrong</p>
<p><strong>Solution</strong>: Configure working directory to project root in IDE settings</p>
<h2 id="key-principles_5">Key Principles</h2>
<ol>
<li><strong>Use your IDE's test runner</strong>: Faster than switching to terminal</li>
<li><strong>Configure the virtual environment</strong>: Ensure IDE uses project's Python</li>
<li><strong>Set up keyboard shortcuts</strong>: Minimize mouse usage</li>
<li><strong>Use inline results</strong>: See pass/fail without switching windows</li>
<li><strong>Debug with breakpoints</strong>: More efficient than print statements</li>
<li><strong>Run tests frequently</strong>: IDE integration makes this effortless</li>
</ol>
        </div>
        <div class="footer">
            Generated on 2025-12-03 10:36:58 | Made with â¤ï¸ by GitHub Pages Generator
        </div>
    </div>
    <script>
        // Syntax highlighting for code blocks
        document.addEventListener('DOMContentLoaded', (event) => {
            // Highlight code blocks
            document.querySelectorAll('pre code').forEach((block) => {
                hljs.highlightElement(block);
            });
            
            // Add copy buttons to code blocks
            document.querySelectorAll('pre').forEach((pre) => {
                const button = document.createElement('button');
                button.className = 'copy-btn';
                button.textContent = 'Copy';
                
                button.addEventListener('click', () => {
                    const code = pre.querySelector('code').textContent;
                    navigator.clipboard.writeText(code).then(() => {
                        button.textContent = 'Copied!';
                        button.classList.add('copied');
                        setTimeout(() => {
                            button.textContent = 'Copy';
                            button.classList.remove('copied');
                        }, 2000);
                    }).catch(err => {
                        console.error('Failed to copy:', err);
                        button.textContent = 'Error';
                        setTimeout(() => {
                            button.textContent = 'Copy';
                        }, 2000);
                    });
                });
                
                pre.appendChild(button);
            });
        });
    </script>
</body>
</html>